{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1e3f8f-9c80-4573-a5fd-46d0e17e8f5a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import imageio\n",
    "from collections import deque, namedtuple\n",
    "import time # Added for timing\n",
    "\n",
    "# Assuming til_environment.gridworld and RewardNames are correctly importable\n",
    "from til_environment.gridworld import RewardNames\n",
    "\n",
    "import functools\n",
    "from pettingzoo.utils.env import ActionType, AECEnv, AgentID, ObsType\n",
    "from pettingzoo.utils.wrappers.base import BaseWrapper\n",
    "\n",
    "# --- Configuration ---\n",
    "# Environment specific\n",
    "MAP_SIZE_X = 16\n",
    "MAP_SIZE_Y = 16\n",
    "MAX_STEPS_PER_EPISODE = 100\n",
    "\n",
    "# --- CNNDQN Model Hyperparameters (from your CNNDQN.py) ---\n",
    "VIEWCONE_CHANNELS = 8\n",
    "VIEWCONE_HEIGHT = 7\n",
    "VIEWCONE_WIDTH = 5\n",
    "OTHER_FEATURES_SIZE = 4 + 2 + 1 + 1 # Direction (4) + Location (2) + Scout (1) + Step (1)\n",
    "\n",
    "CNN_OUTPUT_CHANNELS_1 = 16\n",
    "CNN_OUTPUT_CHANNELS_2 = 32\n",
    "KERNEL_SIZE_1 = (3, 3)\n",
    "STRIDE_1 = 1\n",
    "KERNEL_SIZE_2 = (3, 3)\n",
    "STRIDE_2 = 1\n",
    "MLP_HIDDEN_LAYER_1_SIZE = 128\n",
    "MLP_HIDDEN_LAYER_2_SIZE = 128\n",
    "OUTPUT_ACTIONS = 5\n",
    "DROPOUT_RATE = 0.2 # Active during training; model.eval() handles it for inference\n",
    "\n",
    "# Training Hyperparameters\n",
    "BUFFER_SIZE = int(1e5)\n",
    "BATCH_SIZE = 32 # Reduced from 64 due to potentially larger state\n",
    "GAMMA = 0.99\n",
    "LEARNING_RATE = 1e-4\n",
    "TARGET_UPDATE_EVERY = 1000 # Global steps for the agent being trained\n",
    "UPDATE_EVERY = 4 # Agent steps within an episode for the agent being trained\n",
    "\n",
    "# Epsilon-greedy exploration (for guard training)\n",
    "EPSILON_START = 0.5 # Start higher for guards to explore\n",
    "EPSILON_END = 0.05  # End lower but still some exploration\n",
    "EPSILON_DECAY = 0.9995 # Slower decay\n",
    "MIN_EPSILON_FRAMES_GUARD = int(5e3) # Steps before significant decay for guards\n",
    "\n",
    "SCOUT_EPSILON_INFERENCE = 0.01 # Small epsilon for the pre-trained scout\n",
    "\n",
    "# PER Parameters\n",
    "PER_ALPHA = 0.6\n",
    "PER_BETA_START = 0.4\n",
    "PER_BETA_FRAMES = int(1e5)\n",
    "PER_EPSILON = 1e-6\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Reward shaping (ensure this aligns with guard objectives)\n",
    "EXPLORATION_BONUS_REWARD = 0.5 # Reduced bonus\n",
    "CUSTOM_REWARDS_DICT = {\n",
    "    RewardNames.SCOUT_MISSION: 0,\n",
    "    RewardNames.SCOUT_RECON: 0,\n",
    "    RewardNames.WALL_COLLISION: -10.0,\n",
    "    RewardNames.AGENT_COLLIDER: -1.0,\n",
    "    RewardNames.AGENT_COLLIDEE: -1.0,\n",
    "    RewardNames.STATIONARY_PENALTY: -8,\n",
    "    # Guard specific rewards should be positive for them\n",
    "    RewardNames.GUARD_WINS: 50.0,          # Guards win (scout captured or mission failed by scout)\n",
    "    RewardNames.GUARD_CAPTURES: 100.0,     # A guard directly captures the scout\n",
    "    RewardNames.GUARD_TRUNCATION: 20.0,    # Guards successfully prevent scout mission for full duration\n",
    "    RewardNames.GUARD_STEP: -0.05,          # Small step penalty for guards to encourage efficiency\n",
    "    # Scout penalties from guard perspective (implicitly good for guards)\n",
    "    RewardNames.SCOUT_CAPTURED: 100.0,     # If scout gets captured, good for guards\n",
    "}\n",
    "\n",
    "# Model file paths\n",
    "INITIAL_SCOUT_MODEL_PATH = \"my_wargame_cnn_agent_35500.pth\"\n",
    "SCOUT_MODEL_SAVE_PATH = \"scout.pth\" # Scout model will be re-saved but not trained here\n",
    "GUARD_MODEL_SAVE_PATH = \"guard.pth\"\n",
    "\n",
    "\n",
    "class CustomWrapper(BaseWrapper[AgentID, ObsType, ActionType]):\n",
    "    def __init__(self, env: AECEnv[AgentID, ObsType, ActionType]): # Removed unused manhattan_reward_scale\n",
    "        super().__init__(env)\n",
    "    # reset, step, observe, observation_space can be kept as is or removed if not adding custom logic\n",
    "\n",
    "# --- SumTree (Unchanged) ---\n",
    "class SumTree:\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.tree = np.zeros(2 * capacity - 1)\n",
    "        self.data = np.zeros(capacity, dtype=object)\n",
    "        self.data_pointer = 0\n",
    "        self.n_entries = 0\n",
    "    def add(self, priority, data):\n",
    "        tree_idx = self.data_pointer + self.capacity - 1\n",
    "        self.data[self.data_pointer] = data\n",
    "        self.update(tree_idx, priority)\n",
    "        self.data_pointer = (self.data_pointer + 1) % self.capacity\n",
    "        if self.n_entries < self.capacity: self.n_entries += 1\n",
    "    def update(self, tree_idx, priority):\n",
    "        change = priority - self.tree[tree_idx]\n",
    "        self.tree[tree_idx] = priority\n",
    "        while tree_idx != 0:\n",
    "            tree_idx = (tree_idx - 1) // 2\n",
    "            self.tree[tree_idx] += change\n",
    "    def get_leaf(self, value):\n",
    "        parent_idx = 0\n",
    "        while True:\n",
    "            left_child_idx = 2 * parent_idx + 1; right_child_idx = left_child_idx + 1\n",
    "            if left_child_idx >= len(self.tree): leaf_idx = parent_idx; break\n",
    "            else:\n",
    "                if value <= self.tree[left_child_idx]: parent_idx = left_child_idx\n",
    "                else: value -= self.tree[left_child_idx]; parent_idx = right_child_idx\n",
    "        data_idx = leaf_idx - self.capacity + 1\n",
    "        return leaf_idx, self.tree[leaf_idx], self.data[data_idx]\n",
    "    @property\n",
    "    def total_priority(self): return self.tree[0]\n",
    "\n",
    "# --- Prioritized Replay Buffer (Adapted for two-part state) ---\n",
    "Experience = namedtuple(\"Experience\", field_names=[\"state_viewcone\", \"state_other\", \"action\", \"reward\", \"next_state_viewcone\", \"next_state_other\", \"done\"])\n",
    "\n",
    "class PrioritizedReplayBuffer:\n",
    "    def __init__(self, capacity, alpha=PER_ALPHA):\n",
    "        self.tree = SumTree(capacity)\n",
    "        self.alpha = alpha\n",
    "        self.max_priority = 1.0\n",
    "\n",
    "    def add(self, state_viewcone, state_other, action, reward, next_state_viewcone, next_state_other, done):\n",
    "        experience = Experience(state_viewcone, state_other, action, reward, next_state_viewcone, next_state_other, done)\n",
    "        self.tree.add(self.max_priority, experience)\n",
    "\n",
    "    def sample(self, batch_size, beta=PER_BETA_START):\n",
    "        batch_idx, batch_data, weights_list = np.empty(batch_size, dtype=np.int32), np.empty(batch_size, dtype=object), np.empty(batch_size, dtype=np.float32)\n",
    "        priority_segment = self.tree.total_priority / batch_size if self.tree.n_entries > 0 else 0\n",
    "        if self.tree.n_entries == 0: # Handle empty buffer\n",
    "             return (torch.empty(0), torch.empty(0), torch.empty(0), torch.empty(0), torch.empty(0), torch.empty(0), torch.empty(0)), np.array([]), torch.empty(0)\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            a, b = priority_segment * i, priority_segment * (i + 1)\n",
    "            value = np.random.uniform(a, b)\n",
    "            index, priority, data = self.tree.get_leaf(value)\n",
    "            sampling_probabilities = priority / self.tree.total_priority if self.tree.total_priority > 0 else 0\n",
    "            weights_list[i] = np.power(self.tree.n_entries * sampling_probabilities + 1e-8, -beta)\n",
    "            batch_idx[i], batch_data[i] = index, data\n",
    "        \n",
    "        weights_list /= (weights_list.max() if weights_list.max() > 0 else 1.0)\n",
    "\n",
    "        s_vc, s_o, act, r, next_s_vc, next_s_o, d = zip(*[e for e in batch_data if e is not None])\n",
    "        if not s_vc: # Handle empty after filtering\n",
    "            return (torch.empty(0), torch.empty(0), torch.empty(0), torch.empty(0), torch.empty(0), torch.empty(0), torch.empty(0)), np.array([]), torch.empty(0)\n",
    "\n",
    "        states_vc = torch.from_numpy(np.array(s_vc)).float().to(DEVICE)\n",
    "        states_o = torch.from_numpy(np.array(s_o)).float().to(DEVICE)\n",
    "        actions = torch.from_numpy(np.vstack(act)).long().to(DEVICE)\n",
    "        rewards = torch.from_numpy(np.vstack(r)).float().to(DEVICE)\n",
    "        next_states_vc = torch.from_numpy(np.array(next_s_vc)).float().to(DEVICE)\n",
    "        next_states_o = torch.from_numpy(np.array(next_s_o)).float().to(DEVICE)\n",
    "        dones = torch.from_numpy(np.vstack(d).astype(np.uint8)).float().to(DEVICE)\n",
    "        \n",
    "        return (states_vc, states_o, actions, rewards, next_states_vc, next_states_o, dones), batch_idx, torch.from_numpy(weights_list).float().to(DEVICE)\n",
    "\n",
    "    def update_priorities(self, batch_indices, td_errors):\n",
    "        if len(batch_indices) == 0: return\n",
    "        priorities = np.abs(td_errors) + PER_EPSILON\n",
    "        priorities = np.power(priorities, self.alpha)\n",
    "        for idx, priority_val in zip(batch_indices, priorities):\n",
    "            self.tree.update(idx, priority_val)\n",
    "        if priorities.size > 0: self.max_priority = max(self.max_priority, np.max(priorities))\n",
    "    def __len__(self): return self.tree.n_entries\n",
    "\n",
    "# --- CNNDQN Model (from your CNNDQN.py) ---\n",
    "class CNNDQN(nn.Module):\n",
    "    def __init__(self, viewcone_channels, viewcone_height, viewcone_width, other_features_size, mlp_hidden1, mlp_hidden2, num_actions, dropout_rate):\n",
    "        super(CNNDQN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(viewcone_channels, CNN_OUTPUT_CHANNELS_1, kernel_size=KERNEL_SIZE_1, stride=STRIDE_1, padding=1)\n",
    "        self.relu_conv1 = nn.ReLU()\n",
    "        h_out1 = (viewcone_height + 2 * 1 - KERNEL_SIZE_1[0]) // STRIDE_1 + 1\n",
    "        w_out1 = (viewcone_width + 2 * 1 - KERNEL_SIZE_1[1]) // STRIDE_1 + 1\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(CNN_OUTPUT_CHANNELS_1, CNN_OUTPUT_CHANNELS_2, kernel_size=KERNEL_SIZE_2, stride=STRIDE_2, padding=1)\n",
    "        self.relu_conv2 = nn.ReLU()\n",
    "        h_out2 = (h_out1 + 2 * 1 - KERNEL_SIZE_2[0]) // STRIDE_2 + 1\n",
    "        w_out2 = (w_out1 + 2 * 1 - KERNEL_SIZE_2[1]) // STRIDE_2 + 1\n",
    "\n",
    "        self.cnn_output_flat_size = CNN_OUTPUT_CHANNELS_2 * h_out2 * w_out2\n",
    "        self.fc1_mlp = nn.Linear(self.cnn_output_flat_size + other_features_size, mlp_hidden1)\n",
    "        self.relu_fc1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(dropout_rate)\n",
    "        self.fc2_mlp = nn.Linear(mlp_hidden1, mlp_hidden2)\n",
    "        self.relu_fc2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(dropout_rate)\n",
    "        self.fc_output = nn.Linear(mlp_hidden2, num_actions)\n",
    "\n",
    "    def forward(self, viewcone_input, other_features_input):\n",
    "        x_cnn = self.relu_conv1(self.conv1(viewcone_input))\n",
    "        x_cnn = self.relu_conv2(self.conv2(x_cnn))\n",
    "        x_cnn_flat = x_cnn.view(-1, self.cnn_output_flat_size)\n",
    "        combined_features = torch.cat((x_cnn_flat, other_features_input), dim=1)\n",
    "        x = self.relu_fc1(self.fc1_mlp(combined_features))\n",
    "        x = self.dropout1(x)\n",
    "        x = self.relu_fc2(self.fc2_mlp(x))\n",
    "        x = self.dropout2(x)\n",
    "        return self.fc_output(x)\n",
    "\n",
    "# --- Trainable RL Agent (Adapted for CNNDQN) ---\n",
    "class TrainableRLAgent:\n",
    "    def __init__(self, model_load_path=None, model_save_path=\"trained_cnn_dqn_model.pth\", is_learning_agent=True):\n",
    "        self.device = DEVICE\n",
    "        self.is_learning_agent = is_learning_agent\n",
    "        print(f\"Agent ({'Learning' if is_learning_agent else 'Acting'}): Using device: {self.device}\")\n",
    "\n",
    "        self.policy_net = CNNDQN(VIEWCONE_CHANNELS, VIEWCONE_HEIGHT, VIEWCONE_WIDTH, \n",
    "                                 OTHER_FEATURES_SIZE, MLP_HIDDEN_LAYER_1_SIZE, \n",
    "                                 MLP_HIDDEN_LAYER_2_SIZE, OUTPUT_ACTIONS, DROPOUT_RATE).to(self.device)\n",
    "        if self.is_learning_agent:\n",
    "            self.target_net = CNNDQN(VIEWCONE_CHANNELS, VIEWCONE_HEIGHT, VIEWCONE_WIDTH, \n",
    "                                     OTHER_FEATURES_SIZE, MLP_HIDDEN_LAYER_1_SIZE, \n",
    "                                     MLP_HIDDEN_LAYER_2_SIZE, OUTPUT_ACTIONS, DROPOUT_RATE).to(self.device)\n",
    "\n",
    "        if model_load_path and os.path.exists(model_load_path):\n",
    "            try:\n",
    "                self.policy_net.load_state_dict(torch.load(model_load_path, map_location=self.device))\n",
    "                print(f\"Loaded policy_net from {model_load_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading model from {model_load_path}: {e}. Initializing random weights.\")\n",
    "                self.policy_net.apply(self._initialize_weights)\n",
    "        else:\n",
    "            if model_load_path: print(f\"Model path {model_load_path} not found. Initializing random weights.\")\n",
    "            else: print(\"No model_load_path. Initializing random weights.\")\n",
    "            self.policy_net.apply(self._initialize_weights)\n",
    "\n",
    "        if self.is_learning_agent:\n",
    "            self.target_net.load_state_dict(self.policy_net.state_dict())\n",
    "            self.target_net.eval()\n",
    "            self.optimizer = optim.Adam(self.policy_net.parameters(), lr=LEARNING_RATE)\n",
    "            self.memory = PrioritizedReplayBuffer(BUFFER_SIZE, alpha=PER_ALPHA)\n",
    "            self.beta = PER_BETA_START\n",
    "            self.beta_increment_per_sampling = (1.0 - PER_BETA_START) / PER_BETA_FRAMES if PER_BETA_FRAMES > 0 else 0\n",
    "            self.t_step_episode = 0 # For UPDATE_EVERY (agent's own steps)\n",
    "        \n",
    "        self.model_save_path = model_save_path\n",
    "        self.global_steps_for_target_update = 0 # For TARGET_UPDATE_EVERY (shared across agent's training steps)\n",
    "\n",
    "\n",
    "    def _initialize_weights(self, m):\n",
    "        if isinstance(m, (nn.Linear, nn.Conv2d)):\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "            if m.bias is not None: nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def _unpack_viewcone_tile(self, tile_value): # From CNNDQN.py\n",
    "        return [float((tile_value >> i) & 1) for i in range(VIEWCONE_CHANNELS)] \n",
    "\n",
    "    def process_observation(self, observation_dict): # From CNNDQN.py\n",
    "        raw_viewcone = observation_dict.get(\"viewcone\", np.zeros((VIEWCONE_HEIGHT, VIEWCONE_WIDTH), dtype=np.uint8))\n",
    "        if not isinstance(raw_viewcone, np.ndarray): raw_viewcone = np.array(raw_viewcone)\n",
    "        if raw_viewcone.shape != (VIEWCONE_HEIGHT, VIEWCONE_WIDTH):\n",
    "            padded_viewcone = np.zeros((VIEWCONE_HEIGHT, VIEWCONE_WIDTH), dtype=np.uint8)\n",
    "            h, w = raw_viewcone.shape; h_min, w_min = min(h, VIEWCONE_HEIGHT), min(w, VIEWCONE_WIDTH)\n",
    "            padded_viewcone[:h_min, :w_min] = raw_viewcone[:h_min, :w_min]; raw_viewcone = padded_viewcone\n",
    "        processed_vc_data = np.zeros((VIEWCONE_CHANNELS, VIEWCONE_HEIGHT, VIEWCONE_WIDTH), dtype=np.float32)\n",
    "        for r_idx in range(VIEWCONE_HEIGHT):\n",
    "            for c_idx in range(VIEWCONE_WIDTH):\n",
    "                unpacked = self._unpack_viewcone_tile(raw_viewcone[r_idx, c_idx])\n",
    "                for ch_idx in range(VIEWCONE_CHANNELS): processed_vc_data[ch_idx, r_idx, c_idx] = unpacked[ch_idx]\n",
    "        \n",
    "        other_list = []\n",
    "        direction = observation_dict.get(\"direction\", 0); dir_one_hot = [0.0]*4; dir_one_hot[direction%4]=1.0; other_list.extend(dir_one_hot)\n",
    "        loc = observation_dict.get(\"location\", [0,0]); norm_x=loc[0]/MAP_SIZE_X; norm_y=loc[1]/MAP_SIZE_Y; other_list.extend([norm_x, norm_y])\n",
    "        other_list.append(float(observation_dict.get(\"scout\", 0))) # This will be 0 for guards, 1 for scout\n",
    "        other_list.append(observation_dict.get(\"step\", 0)/MAX_STEPS_PER_EPISODE)\n",
    "        state_other_np = np.array(other_list, dtype=np.float32)\n",
    "        \n",
    "        return processed_vc_data, state_other_np\n",
    "\n",
    "    def select_action(self, state_viewcone_np, state_other_np, epsilon=0.0):\n",
    "        if random.random() > epsilon:\n",
    "            vc_tensor = torch.from_numpy(state_viewcone_np).float().unsqueeze(0).to(self.device)\n",
    "            o_tensor = torch.from_numpy(state_other_np).float().unsqueeze(0).to(self.device)\n",
    "            self.policy_net.eval()\n",
    "            with torch.no_grad(): action_values = self.policy_net(vc_tensor, o_tensor)\n",
    "            self.policy_net.train() if self.is_learning_agent else self.policy_net.eval()\n",
    "            return np.argmax(action_values.cpu().data.numpy())\n",
    "        return random.choice(np.arange(OUTPUT_ACTIONS))\n",
    "\n",
    "    def step(self, s_vc, s_o, act, rwd, next_s_vc, next_s_o, dn):\n",
    "        if not self.is_learning_agent: return\n",
    "        self.memory.add(s_vc, s_o, act, rwd, next_s_vc, next_s_o, dn)\n",
    "        self.t_step_episode = (self.t_step_episode + 1) % UPDATE_EVERY\n",
    "        if self.t_step_episode == 0 and len(self.memory) > BATCH_SIZE:\n",
    "            experiences, indices, weights = self.memory.sample(BATCH_SIZE, beta=self.beta)\n",
    "            if experiences[0].nelement() > 0: self.learn(experiences, indices, weights, GAMMA)\n",
    "            self.beta = min(1.0, self.beta + self.beta_increment_per_sampling)\n",
    "            self.global_steps_for_target_update +=1 # Count learning steps for target update\n",
    "            if self.global_steps_for_target_update % TARGET_UPDATE_EVERY == 0:\n",
    "                self.update_target_net()\n",
    "    \n",
    "    def learn(self, experiences, indices, importance_sampling_weights, gamma):\n",
    "        s_vc, s_o, act, rwd, next_s_vc, next_s_o, dn = experiences\n",
    "        if s_vc.nelement() == 0: return\n",
    "\n",
    "        q_next_policy_actions = self.policy_net(next_s_vc, next_s_o).detach().max(1)[1].unsqueeze(1)\n",
    "        q_targets_next = self.target_net(next_s_vc, next_s_o).detach().gather(1, q_next_policy_actions)\n",
    "        q_targets = rwd + (gamma * q_targets_next * (1 - dn))\n",
    "        q_expected = self.policy_net(s_vc, s_o).gather(1, act)\n",
    "        \n",
    "        td_errors = (q_targets - q_expected).abs().cpu().detach().numpy().flatten()\n",
    "        self.memory.update_priorities(indices, td_errors)\n",
    "        loss = (importance_sampling_weights * nn.MSELoss(reduction='none')(q_expected, q_targets)).mean()\n",
    "        \n",
    "        self.optimizer.zero_grad(); loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(self.policy_net.parameters(), 1.0)\n",
    "        self.optimizer.step()\n",
    "\n",
    "    def update_target_net(self):\n",
    "        if not self.is_learning_agent: return\n",
    "        self.target_net.load_state_dict(self.policy_net.state_dict())\n",
    "        print(f\"Guard Target network updated at global step {self.global_steps_for_target_update}.\")\n",
    "\n",
    "    def save_model(self):\n",
    "        if self.model_save_path:\n",
    "            torch.save(self.policy_net.state_dict(), self.model_save_path)\n",
    "            role = \"Guard\" if self.is_learning_agent else \"Scout\"\n",
    "            print(f\"{role} model saved to {self.model_save_path}\")\n",
    "\n",
    "# --- Main Training Loop ---\n",
    "def train_guards_with_scout(env_module, num_episodes=2000, novice_track=False, \n",
    "                           initial_scout_model=INITIAL_SCOUT_MODEL_PATH,\n",
    "                           load_guard_model_from=None, # Optional: path to existing guard.pth\n",
    "                           save_scout_to=SCOUT_MODEL_SAVE_PATH,\n",
    "                           save_guard_to=GUARD_MODEL_SAVE_PATH,\n",
    "                           render_mode=None, video_folder=None):\n",
    "    \n",
    "    env = env_module.env(env_wrappers=[CustomWrapper], render_mode=render_mode, novice=novice_track, rewards_dict=CUSTOM_REWARDS_DICT)\n",
    "    if render_mode == \"rgb_array\" and video_folder: os.makedirs(video_folder, exist_ok=True)\n",
    "\n",
    "    print(f\"Possible agents: {env.possible_agents}\")\n",
    "    # Assuming agent_0 is scout, others are guards. This needs to be robust if agent IDs change.\n",
    "    # The obs['scout'] flag is the primary way to distinguish.\n",
    "    scout_agent_id_example = env.possible_agents[0] # For print statements\n",
    "    guard_agent_id_example = env.possible_agents[1] if len(env.possible_agents) > 1 else env.possible_agents[0]\n",
    "    print(f\"Example Scout ID for obs space check: {scout_agent_id_example}\")\n",
    "    print(f\"Example Guard ID for obs space check: {guard_agent_id_example}\")\n",
    "\n",
    "\n",
    "    # --- Initialize Scout Agent (Not Learning) ---\n",
    "    scout_agent = TrainableRLAgent(model_load_path=initial_scout_model, \n",
    "                                   model_save_path=save_scout_to, \n",
    "                                   is_learning_agent=False)\n",
    "    scout_agent.policy_net.eval() # Scout is purely in evaluation mode\n",
    "\n",
    "    # --- Initialize Guard Agent (Learning) ---\n",
    "    # Load guard model if path provided, else load from initial scout model\n",
    "    guard_initial_load_path = load_guard_model_from\n",
    "    if not guard_initial_load_path or not os.path.exists(guard_initial_load_path):\n",
    "        print(f\"Guard model at '{load_guard_model_from}' not found or not provided. Initializing guards from scout model: '{initial_scout_model}'\")\n",
    "        guard_initial_load_path = initial_scout_model \n",
    "        if not os.path.exists(guard_initial_load_path):\n",
    "             print(f\"CRITICAL WARNING: Initial scout model '{initial_scout_model}' also not found for guard initialization!\")\n",
    "\n",
    "\n",
    "    guard_trainer_agent = TrainableRLAgent(model_load_path=guard_initial_load_path, \n",
    "                                           model_save_path=save_guard_to, \n",
    "                                           is_learning_agent=True)\n",
    "    \n",
    "    scores_deque = deque(maxlen=100) # Tracks guard scores\n",
    "    epsilon_guard = EPSILON_START\n",
    "    \n",
    "    # Stores (state_vc, state_other, action_taken) for guards pending next state/reward\n",
    "    pending_guard_experiences = {} \n",
    "\n",
    "    for i_episode in range(1, num_episodes + 1):\n",
    "        env.reset()\n",
    "        pending_guard_experiences.clear()\n",
    "        current_episode_rewards = {agent_id: 0 for agent_id in env.possible_agents}\n",
    "        visited_guard_locations_episode = set() # For exploration bonus for guards\n",
    "        episode_frames = []\n",
    "        should_record_video = (render_mode == \"rgb_array\" and video_folder and i_episode % 100 == 0)\n",
    "        \n",
    "        # Reset agent specific step counters for learning/target updates if they are per episode\n",
    "        # guard_trainer_agent.t_step_episode = 0 # Already handled by step method logic\n",
    "\n",
    "        for pet_agent_id in env.agent_iter():\n",
    "            observation_raw, reward, termination, truncation, info = env.last()\n",
    "            done = termination or truncation\n",
    "            \n",
    "            # Accumulate reward for the agent whose turn it was previously\n",
    "            # The reward passed to env.last() is for the action that *led* to this current observation_raw\n",
    "            if pet_agent_id in current_episode_rewards: # Check if agent is still active\n",
    "                 current_episode_rewards[pet_agent_id] += reward\n",
    "\n",
    "\n",
    "            if should_record_video:\n",
    "                try: frame = env.render(); episode_frames.append(frame)\n",
    "                except Exception as e: print(f\"Frame render error: {e}\")\n",
    "\n",
    "            # --- 1. Complete pending transition for the current guard agent (if any) ---\n",
    "            if pet_agent_id in pending_guard_experiences:\n",
    "                prev_s_vc, prev_s_o, prev_action = pending_guard_experiences.pop(pet_agent_id)\n",
    "                \n",
    "                exploration_bonus = 0.0\n",
    "                next_s_vc_np, next_s_o_np = None, None\n",
    "\n",
    "                if not done and observation_raw is not None:\n",
    "                    # Ensure obs_dict uses current observation_raw\n",
    "                    obs_dict = {k: v.tolist() if isinstance(v, np.ndarray) else v for k, v in observation_raw.items()}\n",
    "                    next_s_vc_np, next_s_o_np = guard_trainer_agent.process_observation(obs_dict)\n",
    "                    \n",
    "                    # Exploration bonus for guards visiting new locations\n",
    "                    current_loc_tuple = tuple(obs_dict.get(\"location\", [None,None]))\n",
    "                    if current_loc_tuple != (None,None) and current_loc_tuple not in visited_guard_locations_episode:\n",
    "                        visited_guard_locations_episode.add(current_loc_tuple)\n",
    "                        exploration_bonus = EXPLORATION_BONUS_REWARD\n",
    "                else: # Terminal state for this agent\n",
    "                    next_s_vc_np, next_s_o_np = np.zeros_like(prev_s_vc), np.zeros_like(prev_s_o)\n",
    "                \n",
    "                final_reward = reward + exploration_bonus\n",
    "                guard_trainer_agent.step(prev_s_vc, prev_s_o, prev_action, final_reward, next_s_vc_np, next_s_o_np, done)\n",
    "\n",
    "            # --- 2. Agent selects and takes an action ---\n",
    "            action_to_take = None\n",
    "            if done:\n",
    "                action_to_take = None # No action if agent is done\n",
    "            else:\n",
    "                if observation_raw is None: # Should not happen if not done\n",
    "                    action_to_take = env.action_space(pet_agent_id).sample() if env.action_space(pet_agent_id) is not None else None\n",
    "                else:\n",
    "                    obs_dict = {k: v.tolist() if isinstance(v, np.ndarray) else v for k, v in observation_raw.items()}\n",
    "                    is_scout_turn = obs_dict.get(\"scout\", 0) == 1\n",
    "\n",
    "                    if is_scout_turn:\n",
    "                        s_vc, s_o = scout_agent.process_observation(obs_dict)\n",
    "                        action_to_take = scout_agent.select_action(s_vc, s_o, SCOUT_EPSILON_INFERENCE)\n",
    "                    else: # Guard's turn\n",
    "                        s_vc, s_o = guard_trainer_agent.process_observation(obs_dict)\n",
    "                        action_to_take = guard_trainer_agent.select_action(s_vc, s_o, epsilon_guard)\n",
    "                        pending_guard_experiences[pet_agent_id] = (s_vc, s_o, action_to_take)\n",
    "            \n",
    "            env.step(action_to_take)\n",
    "\n",
    "        # --- End of Episode ---\n",
    "        # Calculate total reward for guards this episode for score tracking\n",
    "        total_guard_score_episode = sum(rwd for ag_id, rwd in current_episode_rewards.items() if env.possible_agents.index(ag_id) != 0) # Assuming agent_0 is scout\n",
    "        # Or track a specific guard if IDs are stable: current_episode_rewards.get(guard_agent_id_example, 0)\n",
    "        \n",
    "        scores_deque.append(total_guard_score_episode) # Track average guard score\n",
    "        \n",
    "        if guard_trainer_agent.global_steps_for_target_update > MIN_EPSILON_FRAMES_GUARD : # Decay epsilon for guards\n",
    "            epsilon_guard = max(EPSILON_END, EPSILON_DECAY * epsilon_guard)\n",
    "        \n",
    "        if should_record_video and video_folder and episode_frames:\n",
    "            try: imageio.mimsave(os.path.join(video_folder, f\"ep_{i_episode:04d}.mp4\"), episode_frames, fps=15)\n",
    "            except Exception as e: print(f\"Video save error: {e}\")\n",
    "       \n",
    "        avg_score_str = f\"{np.mean(scores_deque):.2f}\" if scores_deque else \"N/A\"\n",
    "        print(f'\\rEp {i_episode}\\tAvg Guard Score: {avg_score_str}\\tGuard Eps: {epsilon_guard:.3f}\\tGuard Train Steps: {guard_trainer_agent.global_steps_for_target_update}', end=\"\")\n",
    "        if i_episode % 100 == 0:\n",
    "            print(f'\\rEp {i_episode}\\tAvg Guard Score: {avg_score_str}\\tGuard Eps: {epsilon_guard:.3f}\\tGuard Train Steps: {guard_trainer_agent.global_steps_for_target_update}')\n",
    "            guard_trainer_agent.save_model()\n",
    "            scout_agent.save_model() # Re-save scout model (though it's not changing)\n",
    "            \n",
    "    env.close()\n",
    "    print(\"\\nTraining finished.\")\n",
    "    guard_trainer_agent.save_model() # Save final guard model\n",
    "    scout_agent.save_model()       # Save final scout model\n",
    "    return scores_deque # Return guard scores\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    t_start = time.time()\n",
    "    try:\n",
    "        from til_environment import gridworld\n",
    "        print(\"Successfully imported til_environment.gridworld\")\n",
    "        \n",
    "        guard_scores = train_guards_with_scout(\n",
    "            gridworld, \n",
    "            num_episodes=50000, # Adjust\n",
    "            novice_track=False,\n",
    "            initial_scout_model=INITIAL_SCOUT_MODEL_PATH,\n",
    "            load_guard_model_from=GUARD_MODEL_SAVE_PATH, # Try to load existing guard model\n",
    "            save_scout_to=SCOUT_MODEL_SAVE_PATH,\n",
    "            save_guard_to=GUARD_MODEL_SAVE_PATH,\n",
    "            render_mode=\"rgb_array\", # \"human\" or \"rgb_array\" or None\n",
    "            video_folder=\"./rl_renders_guard_vs_scout\"\n",
    "        )\n",
    "        \n",
    "        if guard_scores:\n",
    "            import matplotlib.pyplot as plt\n",
    "            plt.plot(np.arange(len(guard_scores)), guard_scores)\n",
    "            plt.ylabel('Total Guard Score per Episode')\n",
    "            plt.xlabel('Episode #')\n",
    "            plt.title('Guard Training Performance')\n",
    "            plt.savefig(\"guard_training_scores.png\")\n",
    "            plt.show()\n",
    "\n",
    "    except ImportError:\n",
    "        print(\"Could not import 'til_environment.gridworld'. Ensure it's accessible.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "    \n",
    "    t_end = time.time()\n",
    "    print(f\"Total script time: {(t_end - t_start)/60:.2f} minutes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec25015c-6bac-4fff-9801-f61c0b5ed70c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported til_environment.gridworld\n",
      "Agent Role: Scout | Using device: cuda\n",
      "Loaded Scout policy_net from my_wargame_cnn_agent_35500.pth\n",
      "Guard model at 'guard_learning.pth' not found. Initializing guards from scout model: 'my_wargame_cnn_agent_35500.pth'\n",
      "Agent Role: Guard | Using device: cuda\n",
      "Loaded Guard policy_net from my_wargame_cnn_agent_35500.pth\n",
      "Ep 15| Scout AvgS: 398.84 (Eps:0.100 Steps:320) Guard AvgS: 649.19 (Eps:0.500 Steps:976)Guard Target network updated at 1000 learning steps.\n",
      "Ep 29| Scout AvgS: 304.54 (Eps:0.100 Steps:638) Guard AvgS: 422.47 (Eps:0.500 Steps:1931)Guard Target network updated at 2000 learning steps.\n",
      "Ep 44| Scout AvgS: 230.64 (Eps:0.100 Steps:980) Guard AvgS: 408.73 (Eps:0.500 Steps:2957)Guard Target network updated at 3000 learning steps.\n",
      "Scout Target network updated at 1000 learning steps.\n",
      "Ep 59| Scout AvgS: 200.17 (Eps:0.100 Steps:1325) Guard AvgS: 472.61 (Eps:0.500 Steps:3991)Guard Target network updated at 4000 learning steps.\n",
      "Ep 73| Scout AvgS: 221.79 (Eps:0.100 Steps:1659) Guard AvgS: 519.18 (Eps:0.500 Steps:4994)Guard Target network updated at 5000 learning steps.\n",
      "Ep 87| Scout AvgS: 233.47 (Eps:0.100 Steps:1979) Guard AvgS: 554.12 (Eps:0.497 Steps:5953)Guard Target network updated at 6000 learning steps.\n",
      "Ep 88| Scout AvgS: 232.28 (Eps:0.100 Steps:1999) Guard AvgS: 569.18 (Eps:0.496 Steps:6015)Scout Target network updated at 2000 learning steps.\n",
      "Ep 100| Scout AvgS: 227.80 (Eps:0.100 Steps:2264) Guard AvgS: 616.44 (Eps:0.493 Steps:6808)\n",
      "Scout model saved: scout_learning.pth\n",
      "Guard model saved: guard_learning.pth\n",
      "Ep 103| Scout AvgS: 228.79 (Eps:0.100 Steps:2313) Guard AvgS: 612.52 (Eps:0.493 Steps:6955)Guard Target network updated at 7000 learning steps.\n",
      "Ep 118| Scout AvgS: 246.15 (Eps:0.100 Steps:2656) Guard AvgS: 669.93 (Eps:0.489 Steps:7984)Guard Target network updated at 8000 learning steps.\n",
      "Ep 134| Scout AvgS: 262.58 (Eps:0.100 Steps:2986) Guard AvgS: 801.40 (Eps:0.485 Steps:8976)Guard Target network updated at 9000 learning steps.\n",
      "Scout Target network updated at 3000 learning steps.\n",
      "Ep 150| Scout AvgS: 307.54 (Eps:0.099 Steps:3326) Guard AvgS: 927.36 (Eps:0.481 Steps:9994)Guard Target network updated at 10000 learning steps.\n",
      "Ep 165| Scout AvgS: 357.49 (Eps:0.099 Steps:3652) Guard AvgS: 989.28 (Eps:0.478 Steps:10972)Guard Target network updated at 11000 learning steps.\n",
      "Ep 183| Scout AvgS: 358.11 (Eps:0.099 Steps:3993) Guard AvgS: 1081.26 (Eps:0.473 Steps:11995)Guard Target network updated at 12000 learning steps.\n",
      "Scout Target network updated at 4000 learning steps.\n",
      "Ep 200| Scout AvgS: 383.97 (Eps:0.099 Steps:4313) Guard AvgS: 1101.43 (Eps:0.469 Steps:12956)\n",
      "Scout model saved: scout_learning.pth\n",
      "Guard model saved: guard_learning.pth\n",
      "Guard Target network updated at 13000 learning steps.\n",
      "Ep 215| Scout AvgS: 381.99 (Eps:0.099 Steps:4652) Guard AvgS: 1129.36 (Eps:0.466 Steps:13973)Guard Target network updated at 14000 learning steps.\n",
      "Ep 229| Scout AvgS: 423.03 (Eps:0.099 Steps:4978) Guard AvgS: 1163.91 (Eps:0.462 Steps:14950)Guard Target network updated at 15000 learning steps.\n",
      "Scout Target network updated at 5000 learning steps.\n",
      "Ep 248| Scout AvgS: 442.08 (Eps:0.098 Steps:5327) Guard AvgS: 1154.39 (Eps:0.458 Steps:15997)Guard Target network updated at 16000 learning steps.\n",
      "Ep 263| Scout AvgS: 465.30 (Eps:0.098 Steps:5655) Guard AvgS: 1215.13 (Eps:0.455 Steps:16983)Guard Target network updated at 17000 learning steps.\n",
      "Ep 279| Scout AvgS: 466.62 (Eps:0.098 Steps:5975) Guard AvgS: 1179.53 (Eps:0.451 Steps:17941)Guard Target network updated at 18000 learning steps.\n",
      "Scout Target network updated at 6000 learning steps.\n",
      "Ep 297| Scout AvgS: 492.79 (Eps:0.098 Steps:6323) Guard AvgS: 1164.38 (Eps:0.447 Steps:18985)Guard Target network updated at 19000 learning steps.\n",
      "Ep 300| Scout AvgS: 493.25 (Eps:0.098 Steps:6366) Guard AvgS: 1176.48 (Eps:0.446 Steps:19115)\n",
      "Scout model saved: scout_learning.pth\n",
      "Guard model saved: guard_learning.pth\n",
      "Ep 315| Scout AvgS: 458.89 (Eps:0.098 Steps:6652) Guard AvgS: 1205.82 (Eps:0.443 Steps:19972)Guard Target network updated at 20000 learning steps.\n",
      "Ep 332| Scout AvgS: 401.59 (Eps:0.098 Steps:6985) Guard AvgS: 1160.96 (Eps:0.439 Steps:20973)Guard Target network updated at 21000 learning steps.\n",
      "Scout Target network updated at 7000 learning steps.\n",
      "Ep 350| Scout AvgS: 361.14 (Eps:0.097 Steps:7315) Guard AvgS: 1164.87 (Eps:0.435 Steps:21961)Guard Target network updated at 22000 learning steps.\n",
      "Ep 368| Scout AvgS: 319.61 (Eps:0.097 Steps:7644) Guard AvgS: 1113.56 (Eps:0.431 Steps:22950)Guard Target network updated at 23000 learning steps.\n",
      "Ep 386| Scout AvgS: 342.29 (Eps:0.097 Steps:7985) Guard AvgS: 1139.54 (Eps:0.428 Steps:23972)Guard Target network updated at 24000 learning steps.\n",
      "Scout Target network updated at 8000 learning steps.\n",
      "Ep 400| Scout AvgS: 327.63 (Eps:0.097 Steps:8273) Guard AvgS: 1165.27 (Eps:0.425 Steps:24835)\n",
      "Scout model saved: scout_learning.pth\n",
      "Guard model saved: guard_learning.pth\n",
      "Ep 402| Scout AvgS: 343.30 (Eps:0.097 Steps:8323) Guard AvgS: 1162.68 (Eps:0.424 Steps:24985)Guard Target network updated at 25000 learning steps.\n",
      "Ep 421| Scout AvgS: 376.91 (Eps:0.097 Steps:8651) Guard AvgS: 1136.48 (Eps:0.420 Steps:25969)Guard Target network updated at 26000 learning steps.\n",
      "Ep 442| Scout AvgS: 362.85 (Eps:0.097 Steps:8987) Guard AvgS: 1121.84 (Eps:0.416 Steps:26978)Guard Target network updated at 27000 learning steps.\n",
      "Ep 443| Scout AvgS: 362.60 (Eps:0.097 Steps:8999) Guard AvgS: 1121.05 (Eps:0.416 Steps:27015)Scout Target network updated at 9000 learning steps.\n",
      "Ep 457| Scout AvgS: 372.22 (Eps:0.096 Steps:9325) Guard AvgS: 1085.06 (Eps:0.413 Steps:27992)Guard Target network updated at 28000 learning steps.\n",
      "Ep 471| Scout AvgS: 387.91 (Eps:0.096 Steps:9660) Guard AvgS: 1128.71 (Eps:0.410 Steps:28996)Guard Target network updated at 29000 learning steps.\n",
      "Ep 487| Scout AvgS: 367.93 (Eps:0.096 Steps:9979) Guard AvgS: 1141.64 (Eps:0.406 Steps:29953)Guard Target network updated at 30000 learning steps.\n",
      "Scout Target network updated at 10000 learning steps.\n",
      "Ep 500| Scout AvgS: 353.20 (Eps:0.096 Steps:10253) Guard AvgS: 1097.20 (Eps:0.404 Steps:30775)\n",
      "Scout model saved: scout_learning.pth\n",
      "Guard model saved: guard_learning.pth\n",
      "Ep 505| Scout AvgS: 346.57 (Eps:0.096 Steps:10327) Guard AvgS: 1095.78 (Eps:0.403 Steps:30998)Guard Target network updated at 31000 learning steps.\n",
      "Ep 521| Scout AvgS: 352.76 (Eps:0.096 Steps:10639) Guard AvgS: 1133.40 (Eps:0.400 Steps:31934)Guard Target network updated at 32000 learning steps.\n",
      "Ep 537| Scout AvgS: 375.72 (Eps:0.096 Steps:10976) Guard AvgS: 1093.82 (Eps:0.396 Steps:32944)Guard Target network updated at 33000 learning steps.\n",
      "Scout Target network updated at 11000 learning steps.\n",
      "Ep 553| Scout AvgS: 404.54 (Eps:0.095 Steps:11303) Guard AvgS: 1151.58 (Eps:0.393 Steps:33927)Guard Target network updated at 34000 learning steps.\n",
      "Ep 572| Scout AvgS: 399.92 (Eps:0.095 Steps:11655) Guard AvgS: 1087.46 (Eps:0.390 Steps:34983)Guard Target network updated at 35000 learning steps.\n",
      "Ep 587| Scout AvgS: 429.38 (Eps:0.095 Steps:11992) Guard AvgS: 1137.86 (Eps:0.387 Steps:35993)Guard Target network updated at 36000 learning steps.\n",
      "Scout Target network updated at 12000 learning steps.\n",
      "Ep 600| Scout AvgS: 450.84 (Eps:0.095 Steps:12255) Guard AvgS: 1193.23 (Eps:0.384 Steps:36782)\n",
      "Scout model saved: scout_learning.pth\n",
      "Guard model saved: guard_learning.pth\n",
      "Ep 603| Scout AvgS: 454.33 (Eps:0.095 Steps:12315) Guard AvgS: 1187.00 (Eps:0.384 Steps:36961)Guard Target network updated at 37000 learning steps.\n",
      "Ep 622| Scout AvgS: 433.15 (Eps:0.095 Steps:12636) Guard AvgS: 1162.92 (Eps:0.380 Steps:37925)Guard Target network updated at 38000 learning steps.\n",
      "Ep 641| Scout AvgS: 392.92 (Eps:0.095 Steps:12991) Guard AvgS: 1240.59 (Eps:0.376 Steps:38989)Guard Target network updated at 39000 learning steps.\n",
      "Scout Target network updated at 13000 learning steps.\n",
      "Ep 656| Scout AvgS: 364.34 (Eps:0.094 Steps:13314) Guard AvgS: 1281.41 (Eps:0.374 Steps:39959)Guard Target network updated at 40000 learning steps.\n",
      "Ep 676| Scout AvgS: 375.17 (Eps:0.094 Steps:13661) Guard AvgS: 1259.91 (Eps:0.370 Steps:40999)Guard Target network updated at 41000 learning steps.\n",
      "Ep 692| Scout AvgS: 355.69 (Eps:0.094 Steps:13991) Guard AvgS: 1220.19 (Eps:0.367 Steps:41989)Guard Target network updated at 42000 learning steps.\n",
      "Scout Target network updated at 14000 learning steps.\n",
      "Ep 700| Scout AvgS: 325.68 (Eps:0.094 Steps:14092) Guard AvgS: 1185.97 (Eps:0.365 Steps:42293)\n",
      "Scout model saved: scout_learning.pth\n",
      "Guard model saved: guard_learning.pth\n",
      "Ep 711| Scout AvgS: 309.98 (Eps:0.094 Steps:14318) Guard AvgS: 1226.37 (Eps:0.363 Steps:42970)Guard Target network updated at 43000 learning steps.\n",
      "Ep 726| Scout AvgS: 346.05 (Eps:0.094 Steps:14654) Guard AvgS: 1212.13 (Eps:0.361 Steps:43978)Guard Target network updated at 44000 learning steps.\n",
      "Ep 744| Scout AvgS: 379.67 (Eps:0.094 Steps:14990) Guard AvgS: 1174.62 (Eps:0.357 Steps:44986)Guard Target network updated at 45000 learning steps.\n",
      "Scout Target network updated at 15000 learning steps.\n",
      "Ep 759| Scout AvgS: 371.24 (Eps:0.094 Steps:15315) Guard AvgS: 1185.02 (Eps:0.355 Steps:45961)Guard Target network updated at 46000 learning steps.\n",
      "Ep 776| Scout AvgS: 340.71 (Eps:0.093 Steps:15658) Guard AvgS: 1187.76 (Eps:0.352 Steps:46991)Guard Target network updated at 47000 learning steps.\n",
      "Ep 796| Scout AvgS: 336.62 (Eps:0.093 Steps:15985) Guard AvgS: 1142.61 (Eps:0.348 Steps:47971)Guard Target network updated at 48000 learning steps.\n",
      "Scout Target network updated at 16000 learning steps.\n",
      "Ep 800| Scout AvgS: 361.59 (Eps:0.093 Steps:16065) Guard AvgS: 1169.77 (Eps:0.348 Steps:48211)\n",
      "Scout model saved: scout_learning.pth\n",
      "Guard model saved: guard_learning.pth\n",
      "Ep 815| Scout AvgS: 375.41 (Eps:0.093 Steps:16327) Guard AvgS: 1132.06 (Eps:0.345 Steps:48997)Guard Target network updated at 49000 learning steps.\n",
      "Ep 830| Scout AvgS: 377.08 (Eps:0.093 Steps:16638) Guard AvgS: 1119.95 (Eps:0.342 Steps:49931)Guard Target network updated at 50000 learning steps.\n",
      "Ep 847| Scout AvgS: 371.73 (Eps:0.093 Steps:16981) Guard AvgS: 1130.98 (Eps:0.340 Steps:50961)Guard Target network updated at 51000 learning steps.\n",
      "Ep 848| Scout AvgS: 371.00 (Eps:0.093 Steps:16996) Guard AvgS: 1126.37 (Eps:0.339 Steps:51006)Scout Target network updated at 17000 learning steps.\n",
      "Ep 865| Scout AvgS: 381.91 (Eps:0.093 Steps:17319) Guard AvgS: 1086.11 (Eps:0.336 Steps:51975)Guard Target network updated at 52000 learning steps.\n",
      "Ep 883| Scout AvgS: 404.42 (Eps:0.092 Steps:17643) Guard AvgS: 1118.21 (Eps:0.333 Steps:52946)Guard Target network updated at 53000 learning steps.\n",
      "Ep 900| Scout AvgS: 391.48 (Eps:0.092 Steps:17961) Guard AvgS: 1106.80 (Eps:0.331 Steps:53900)\n",
      "Scout model saved: scout_learning.pth\n",
      "Guard model saved: guard_learning.pth\n",
      "Ep 901| Scout AvgS: 375.71 (Eps:0.092 Steps:17979) Guard AvgS: 1108.47 (Eps:0.330 Steps:53954)Guard Target network updated at 54000 learning steps.\n",
      "Scout Target network updated at 18000 learning steps.\n",
      "Ep 916| Scout AvgS: 404.44 (Eps:0.092 Steps:18309) Guard AvgS: 1144.91 (Eps:0.328 Steps:54945)Guard Target network updated at 55000 learning steps.\n",
      "Ep 935| Scout AvgS: 401.17 (Eps:0.092 Steps:18660) Guard AvgS: 1120.57 (Eps:0.325 Steps:55997)Guard Target network updated at 56000 learning steps.\n",
      "Ep 954| Scout AvgS: 399.99 (Eps:0.092 Steps:18990) Guard AvgS: 1071.74 (Eps:0.322 Steps:56988)Guard Target network updated at 57000 learning steps.\n",
      "Scout Target network updated at 19000 learning steps.\n",
      "Ep 969| Scout AvgS: 438.19 (Eps:0.092 Steps:19320) Guard AvgS: 1145.25 (Eps:0.319 Steps:57976)Guard Target network updated at 58000 learning steps.\n",
      "Ep 986| Scout AvgS: 421.32 (Eps:0.091 Steps:19637) Guard AvgS: 1136.36 (Eps:0.317 Steps:58928)Guard Target network updated at 59000 learning steps.\n",
      "Ep 1000| Scout AvgS: 427.73 (Eps:0.091 Steps:19959) Guard AvgS: 1164.99 (Eps:0.315 Steps:59894)\n",
      "Scout model saved: scout_learning.pth\n",
      "Guard model saved: guard_learning.pth\n",
      "Ep 1002| Scout AvgS: 421.63 (Eps:0.091 Steps:19988) Guard AvgS: 1150.49 (Eps:0.314 Steps:59981)Guard Target network updated at 60000 learning steps.\n",
      "Scout Target network updated at 20000 learning steps.\n",
      "Ep 1020| Scout AvgS: 429.32 (Eps:0.091 Steps:20314) Guard AvgS: 1107.07 (Eps:0.311 Steps:60958)Guard Target network updated at 61000 learning steps.\n",
      "Ep 1036| Scout AvgS: 434.05 (Eps:0.091 Steps:20650) Guard AvgS: 1206.11 (Eps:0.309 Steps:61966)Guard Target network updated at 62000 learning steps.\n",
      "Ep 1052| Scout AvgS: 426.89 (Eps:0.091 Steps:20974) Guard AvgS: 1215.14 (Eps:0.306 Steps:62938)Guard Target network updated at 63000 learning steps.\n",
      "Ep 1053| Scout AvgS: 431.75 (Eps:0.091 Steps:20999) Guard AvgS: 1213.75 (Eps:0.306 Steps:63013)Scout Target network updated at 21000 learning steps.\n",
      "Ep 1070| Scout AvgS: 410.61 (Eps:0.091 Steps:21322) Guard AvgS: 1171.99 (Eps:0.304 Steps:63983)Guard Target network updated at 64000 learning steps.\n",
      "Ep 1089| Scout AvgS: 413.56 (Eps:0.090 Steps:21657) Guard AvgS: 1146.96 (Eps:0.301 Steps:64987)Guard Target network updated at 65000 learning steps.\n",
      "Ep 1100| Scout AvgS: 407.06 (Eps:0.090 Steps:21845) Guard AvgS: 1142.48 (Eps:0.299 Steps:65551)\n",
      "Scout model saved: scout_learning.pth\n",
      "Guard model saved: guard_learning.pth\n",
      "Ep 1109| Scout AvgS: 390.84 (Eps:0.090 Steps:21980) Guard AvgS: 1162.12 (Eps:0.298 Steps:65956)Guard Target network updated at 66000 learning steps.\n",
      "Scout Target network updated at 22000 learning steps.\n",
      "Ep 1125| Scout AvgS: 358.93 (Eps:0.090 Steps:22325) Guard AvgS: 1184.36 (Eps:0.295 Steps:66992)Guard Target network updated at 67000 learning steps.\n",
      "Ep 1142| Scout AvgS: 387.12 (Eps:0.090 Steps:22656) Guard AvgS: 1130.25 (Eps:0.293 Steps:67986)Guard Target network updated at 68000 learning steps.\n",
      "Ep 1157| Scout AvgS: 374.93 (Eps:0.090 Steps:22977) Guard AvgS: 1173.77 (Eps:0.291 Steps:68948)Guard Target network updated at 69000 learning steps.\n",
      "Scout Target network updated at 23000 learning steps.\n",
      "Ep 1179| Scout AvgS: 327.56 (Eps:0.090 Steps:23314) Guard AvgS: 1175.07 (Eps:0.288 Steps:69958)Guard Target network updated at 70000 learning steps.\n",
      "Ep 1197| Scout AvgS: 345.96 (Eps:0.090 Steps:23659) Guard AvgS: 1157.59 (Eps:0.285 Steps:70994)Guard Target network updated at 71000 learning steps.\n",
      "Ep 1200| Scout AvgS: 345.94 (Eps:0.089 Steps:23696) Guard AvgS: 1144.23 (Eps:0.285 Steps:71104)\n",
      "Scout model saved: scout_learning.pth\n",
      "Guard model saved: guard_learning.pth\n",
      "Ep 1214| Scout AvgS: 350.60 (Eps:0.089 Steps:23970) Guard AvgS: 1134.35 (Eps:0.283 Steps:71928)Guard Target network updated at 72000 learning steps.\n",
      "Ep 1215| Scout AvgS: 350.90 (Eps:0.089 Steps:23995) Guard AvgS: 1141.30 (Eps:0.282 Steps:72003)Scout Target network updated at 24000 learning steps.\n",
      "Ep 1232| Scout AvgS: 330.80 (Eps:0.089 Steps:24321) Guard AvgS: 1148.61 (Eps:0.280 Steps:72980)Guard Target network updated at 73000 learning steps.\n",
      "Ep 1249| Scout AvgS: 327.93 (Eps:0.089 Steps:24647) Guard AvgS: 1168.13 (Eps:0.278 Steps:73959)Guard Target network updated at 74000 learning steps.\n",
      "Ep 1269| Scout AvgS: 365.13 (Eps:0.089 Steps:24982) Guard AvgS: 1077.40 (Eps:0.275 Steps:74962)Guard Target network updated at 75000 learning steps.\n",
      "Scout Target network updated at 25000 learning steps.\n",
      "Ep 1289| Scout AvgS: 375.67 (Eps:0.089 Steps:25327) Guard AvgS: 1132.40 (Eps:0.272 Steps:75997)Guard Target network updated at 76000 learning steps.\n",
      "Ep 1300| Scout AvgS: 389.07 (Eps:0.089 Steps:25550) Guard AvgS: 1185.00 (Eps:0.271 Steps:76666)\n",
      "Scout model saved: scout_learning.pth\n",
      "Guard model saved: guard_learning.pth\n",
      "Ep 1305| Scout AvgS: 382.00 (Eps:0.089 Steps:25658) Guard AvgS: 1194.03 (Eps:0.270 Steps:76991)Guard Target network updated at 77000 learning steps.\n",
      "Ep 1322| Scout AvgS: 375.80 (Eps:0.088 Steps:25977) Guard AvgS: 1191.29 (Eps:0.268 Steps:77947)Guard Target network updated at 78000 learning steps.\n",
      "Ep 1323| Scout AvgS: 376.01 (Eps:0.088 Steps:25996) Guard AvgS: 1184.47 (Eps:0.268 Steps:78005)Scout Target network updated at 26000 learning steps.\n",
      "Ep 1341| Scout AvgS: 404.72 (Eps:0.088 Steps:26320) Guard AvgS: 1147.28 (Eps:0.265 Steps:78976)Guard Target network updated at 79000 learning steps.\n",
      "Ep 1365| Scout AvgS: 373.99 (Eps:0.088 Steps:26650) Guard AvgS: 1140.62 (Eps:0.262 Steps:79966)Guard Target network updated at 80000 learning steps.\n",
      "Ep 1381| Scout AvgS: 366.09 (Eps:0.088 Steps:26972) Guard AvgS: 1106.32 (Eps:0.260 Steps:80932)Guard Target network updated at 81000 learning steps.\n",
      "Ep 1382| Scout AvgS: 365.65 (Eps:0.088 Steps:26997) Guard AvgS: 1108.87 (Eps:0.260 Steps:81007)Scout Target network updated at 27000 learning steps.\n",
      "Ep 1400| Scout AvgS: 355.29 (Eps:0.088 Steps:27294) Guard AvgS: 1066.18 (Eps:0.257 Steps:81898)\n",
      "Scout model saved: scout_learning.pth\n",
      "Guard model saved: guard_learning.pth\n",
      "Ep 1402| Scout AvgS: 349.17 (Eps:0.088 Steps:27310) Guard AvgS: 1064.05 (Eps:0.257 Steps:81947)Guard Target network updated at 82000 learning steps.\n",
      "Ep 1419| Scout AvgS: 383.42 (Eps:0.088 Steps:27641) Guard AvgS: 1085.37 (Eps:0.255 Steps:82940)Guard Target network updated at 83000 learning steps.\n",
      "Ep 1437| Scout AvgS: 370.83 (Eps:0.087 Steps:27994) Guard AvgS: 1113.55 (Eps:0.253 Steps:83998)Guard Target network updated at 84000 learning steps.\n",
      "Scout Target network updated at 28000 learning steps.\n",
      "Ep 1453| Scout AvgS: 379.83 (Eps:0.087 Steps:28309) Guard AvgS: 1178.70 (Eps:0.251 Steps:84945)Guard Target network updated at 85000 learning steps.\n",
      "Ep 1470| Scout AvgS: 392.65 (Eps:0.087 Steps:28657) Guard AvgS: 1245.35 (Eps:0.249 Steps:85987)Guard Target network updated at 86000 learning steps.\n",
      "Ep 1489| Scout AvgS: 408.34 (Eps:0.087 Steps:28993) Guard AvgS: 1231.02 (Eps:0.246 Steps:86997)Guard Target network updated at 87000 learning steps.\n",
      "Scout Target network updated at 29000 learning steps.\n",
      "Ep 1500| Scout AvgS: 385.23 (Eps:0.087 Steps:29198) Guard AvgS: 1230.69 (Eps:0.245 Steps:87610)\n",
      "Scout model saved: scout_learning.pth\n",
      "Guard model saved: guard_learning.pth\n",
      "Ep 1507| Scout AvgS: 385.56 (Eps:0.087 Steps:29318) Guard AvgS: 1223.96 (Eps:0.244 Steps:87972)Guard Target network updated at 88000 learning steps.\n",
      "Ep 1525| Scout AvgS: 378.84 (Eps:0.087 Steps:29655) Guard AvgS: 1209.47 (Eps:0.242 Steps:88983)Guard Target network updated at 89000 learning steps.\n",
      "Ep 1540| Scout AvgS: 363.96 (Eps:0.086 Steps:29970) Guard AvgS: 1168.77 (Eps:0.240 Steps:89928)Guard Target network updated at 90000 learning steps.\n",
      "Ep 1541| Scout AvgS: 381.90 (Eps:0.086 Steps:29995) Guard AvgS: 1166.33 (Eps:0.240 Steps:90003)Scout Target network updated at 30000 learning steps.\n",
      "Ep 1560| Scout AvgS: 374.46 (Eps:0.086 Steps:30322) Guard AvgS: 1141.13 (Eps:0.238 Steps:90982)Guard Target network updated at 91000 learning steps.\n",
      "Ep 1582| Scout AvgS: 338.97 (Eps:0.086 Steps:30661) Guard AvgS: 1135.38 (Eps:0.235 Steps:91999)Guard Target network updated at 92000 learning steps.\n",
      "Ep 1597| Scout AvgS: 372.97 (Eps:0.086 Steps:30972) Guard AvgS: 1100.57 (Eps:0.233 Steps:92932)Guard Target network updated at 93000 learning steps.\n",
      "Ep 1598| Scout AvgS: 374.14 (Eps:0.086 Steps:30996) Guard AvgS: 1104.58 (Eps:0.233 Steps:93006)Scout Target network updated at 31000 learning steps.\n",
      "Ep 1600| Scout AvgS: 374.80 (Eps:0.086 Steps:31027) Guard AvgS: 1098.13 (Eps:0.233 Steps:93099)\n",
      "Scout model saved: scout_learning.pth\n",
      "Guard model saved: guard_learning.pth\n",
      "Ep 1621| Scout AvgS: 360.86 (Eps:0.086 Steps:31325) Guard AvgS: 1064.25 (Eps:0.231 Steps:93991)Guard Target network updated at 94000 learning steps.\n",
      "Ep 1638| Scout AvgS: 383.60 (Eps:0.086 Steps:31640) Guard AvgS: 1050.50 (Eps:0.229 Steps:94936)Guard Target network updated at 95000 learning steps.\n",
      "Ep 1655| Scout AvgS: 377.92 (Eps:0.085 Steps:31970) Guard AvgS: 986.11 (Eps:0.227 Steps:95926))Guard Target network updated at 96000 learning steps.\n",
      "Ep 1656| Scout AvgS: 377.60 (Eps:0.085 Steps:31995) Guard AvgS: 986.51 (Eps:0.227 Steps:96001)Scout Target network updated at 32000 learning steps.\n",
      "Ep 1671| Scout AvgS: 397.35 (Eps:0.085 Steps:32306) Guard AvgS: 1043.59 (Eps:0.225 Steps:96934)Guard Target network updated at 97000 learning steps.\n",
      "Ep 1694| Scout AvgS: 402.03 (Eps:0.085 Steps:32640) Guard AvgS: 1026.70 (Eps:0.222 Steps:97938)Guard Target network updated at 98000 learning steps.\n",
      "Ep 1700| Scout AvgS: 399.15 (Eps:0.085 Steps:32760) Guard AvgS: 1036.07 (Eps:0.222 Steps:98296)\n",
      "Scout model saved: scout_learning.pth\n",
      "Guard model saved: guard_learning.pth\n",
      "Ep 1713| Scout AvgS: 423.14 (Eps:0.085 Steps:32981) Guard AvgS: 1023.39 (Eps:0.220 Steps:98960)Guard Target network updated at 99000 learning steps.\n",
      "Scout Target network updated at 33000 learning steps.\n",
      "Ep 1732| Scout AvgS: 389.73 (Eps:0.085 Steps:33325) Guard AvgS: 1005.52 (Eps:0.218 Steps:99993)Guard Target network updated at 100000 learning steps.\n",
      "Ep 1751| Scout AvgS: 386.51 (Eps:0.085 Steps:33638) Guard AvgS: 1043.56 (Eps:0.216 Steps:100931)Guard Target network updated at 101000 learning steps.\n",
      "Ep 1769| Scout AvgS: 368.34 (Eps:0.085 Steps:33969) Guard AvgS: 1068.61 (Eps:0.214 Steps:101925)Guard Target network updated at 102000 learning steps.\n",
      "Ep 1770| Scout AvgS: 367.80 (Eps:0.085 Steps:33994) Guard AvgS: 1084.56 (Eps:0.214 Steps:102000)Scout Target network updated at 34000 learning steps.\n",
      "Ep 1785| Scout AvgS: 396.38 (Eps:0.084 Steps:34307) Guard AvgS: 1149.23 (Eps:0.212 Steps:102937)Guard Target network updated at 103000 learning steps.\n",
      "Ep 1800| Scout AvgS: 387.49 (Eps:0.084 Steps:34590) Guard AvgS: 1184.79 (Eps:0.211 Steps:103786)\n",
      "Scout model saved: scout_learning.pth\n",
      "Guard model saved: guard_learning.pth\n",
      "Ep 1803| Scout AvgS: 383.82 (Eps:0.084 Steps:34661) Guard AvgS: 1197.85 (Eps:0.210 Steps:103999)Guard Target network updated at 104000 learning steps.\n",
      "Ep 1819| Scout AvgS: 388.12 (Eps:0.084 Steps:34977) Guard AvgS: 1161.04 (Eps:0.209 Steps:104947)Guard Target network updated at 105000 learning steps.\n",
      "Scout Target network updated at 35000 learning steps.\n",
      "Ep 1836| Scout AvgS: 410.67 (Eps:0.084 Steps:35306) Guard AvgS: 1193.07 (Eps:0.207 Steps:105934)Guard Target network updated at 106000 learning steps.\n",
      "Ep 1854| Scout AvgS: 422.41 (Eps:0.084 Steps:35661) Guard AvgS: 1227.34 (Eps:0.205 Steps:106999)Guard Target network updated at 107000 learning steps.\n",
      "Ep 1870| Scout AvgS: 443.98 (Eps:0.084 Steps:35972) Guard AvgS: 1202.04 (Eps:0.204 Steps:107933)Guard Target network updated at 108000 learning steps.\n",
      "Ep 1871| Scout AvgS: 444.77 (Eps:0.084 Steps:35997) Guard AvgS: 1204.31 (Eps:0.203 Steps:108008)Scout Target network updated at 36000 learning steps.\n",
      "Ep 1888| Scout AvgS: 428.94 (Eps:0.084 Steps:36318) Guard AvgS: 1163.14 (Eps:0.202 Steps:108970)Guard Target network updated at 109000 learning steps.\n",
      "Ep 1900| Scout AvgS: 441.81 (Eps:0.083 Steps:36509) Guard AvgS: 1126.73 (Eps:0.201 Steps:109545)\n",
      "Scout model saved: scout_learning.pth\n",
      "Guard model saved: guard_learning.pth\n",
      "Ep 1907| Scout AvgS: 429.58 (Eps:0.083 Steps:36637) Guard AvgS: 1147.41 (Eps:0.200 Steps:109927)Guard Target network updated at 110000 learning steps.\n",
      "Ep 1926| Scout AvgS: 447.87 (Eps:0.083 Steps:36984) Guard AvgS: 1108.89 (Eps:0.198 Steps:110970)Guard Target network updated at 111000 learning steps.\n",
      "Scout Target network updated at 37000 learning steps.\n",
      "Ep 1943| Scout AvgS: 479.93 (Eps:0.083 Steps:37322) Guard AvgS: 1103.42 (Eps:0.196 Steps:111982)Guard Target network updated at 112000 learning steps.\n",
      "Ep 1961| Scout AvgS: 449.05 (Eps:0.083 Steps:37653) Guard AvgS: 1088.17 (Eps:0.194 Steps:112975)Guard Target network updated at 113000 learning steps.\n",
      "Ep 1980| Scout AvgS: 408.79 (Eps:0.083 Steps:37994) Guard AvgS: 1041.21 (Eps:0.193 Steps:113999)Guard Target network updated at 114000 learning steps.\n",
      "Scout Target network updated at 38000 learning steps.\n",
      "Ep 1998| Scout AvgS: 414.96 (Eps:0.083 Steps:38319) Guard AvgS: 1027.57 (Eps:0.191 Steps:114975)Guard Target network updated at 115000 learning steps.\n",
      "Ep 2000| Scout AvgS: 415.04 (Eps:0.083 Steps:38363) Guard AvgS: 1031.68 (Eps:0.191 Steps:115105)\n",
      "Scout model saved: scout_learning.pth\n",
      "Guard model saved: guard_learning.pth\n",
      "Ep 2020| Scout AvgS: 393.99 (Eps:0.082 Steps:38660) Guard AvgS: 965.92 (Eps:0.189 Steps:115996)Guard Target network updated at 116000 learning steps.\n",
      "Ep 2036| Scout AvgS: 353.91 (Eps:0.082 Steps:38969) Guard AvgS: 990.39 (Eps:0.187 Steps:116925))Guard Target network updated at 117000 learning steps.\n",
      "Ep 2037| Scout AvgS: 353.48 (Eps:0.082 Steps:38994) Guard AvgS: 988.75 (Eps:0.187 Steps:117000)Scout Target network updated at 39000 learning steps.\n",
      "Ep 2059| Scout AvgS: 365.38 (Eps:0.082 Steps:39311) Guard AvgS: 971.13 (Eps:0.185 Steps:117949)Guard Target network updated at 118000 learning steps.\n",
      "Ep 2078| Scout AvgS: 363.87 (Eps:0.082 Steps:39650) Guard AvgS: 1014.95 (Eps:0.183 Steps:118966)Guard Target network updated at 119000 learning steps.\n",
      "Ep 2097| Scout AvgS: 321.85 (Eps:0.082 Steps:39988) Guard AvgS: 1093.73 (Eps:0.182 Steps:119980)Guard Target network updated at 120000 learning steps.\n",
      "Scout Target network updated at 40000 learning steps.\n",
      "Ep 2100| Scout AvgS: 320.93 (Eps:0.082 Steps:40063) Guard AvgS: 1087.06 (Eps:0.181 Steps:120205)\n",
      "Scout model saved: scout_learning.pth\n",
      "Guard model saved: guard_learning.pth\n",
      "Ep 2112| Scout AvgS: 346.79 (Eps:0.082 Steps:40326) Guard AvgS: 1133.67 (Eps:0.180 Steps:120994)Guard Target network updated at 121000 learning steps.\n",
      "Ep 2132| Scout AvgS: 360.01 (Eps:0.082 Steps:40639) Guard AvgS: 1053.27 (Eps:0.179 Steps:121933)Guard Target network updated at 122000 learning steps.\n",
      "Ep 2154| Scout AvgS: 338.15 (Eps:0.081 Steps:40991) Guard AvgS: 1049.87 (Eps:0.177 Steps:122991)Guard Target network updated at 123000 learning steps.\n",
      "Scout Target network updated at 41000 learning steps.\n",
      "Ep 2170| Scout AvgS: 358.96 (Eps:0.081 Steps:41324) Guard AvgS: 997.28 (Eps:0.175 Steps:123990))Guard Target network updated at 124000 learning steps.\n",
      "Ep 2187| Scout AvgS: 367.26 (Eps:0.081 Steps:41644) Guard AvgS: 989.36 (Eps:0.174 Steps:124949))Guard Target network updated at 125000 learning steps.\n",
      "Ep 2200| Scout AvgS: 380.21 (Eps:0.081 Steps:41883) Guard AvgS: 947.79 (Eps:0.173 Steps:125667))\n",
      "Scout model saved: scout_learning.pth\n",
      "Guard model saved: guard_learning.pth\n",
      "Ep 2209| Scout AvgS: 350.03 (Eps:0.081 Steps:41989) Guard AvgS: 935.48 (Eps:0.172 Steps:125985)Guard Target network updated at 126000 learning steps.\n",
      "Scout Target network updated at 42000 learning steps.\n",
      "Ep 2224| Scout AvgS: 348.72 (Eps:0.081 Steps:42316) Guard AvgS: 1081.79 (Eps:0.171 Steps:126964)Guard Target network updated at 127000 learning steps.\n",
      "Ep 2242| Scout AvgS: 330.09 (Eps:0.081 Steps:42644) Guard AvgS: 1060.36 (Eps:0.169 Steps:127948)Guard Target network updated at 128000 learning steps.\n",
      "Ep 2261| Scout AvgS: 333.37 (Eps:0.080 Steps:42986) Guard AvgS: 1093.24 (Eps:0.167 Steps:128974)Guard Target network updated at 129000 learning steps.\n",
      "Scout Target network updated at 43000 learning steps.\n",
      "Ep 2283| Scout AvgS: 346.96 (Eps:0.080 Steps:43318) Guard AvgS: 1007.41 (Eps:0.166 Steps:129971)Guard Target network updated at 130000 learning steps.\n",
      "Ep 2300| Scout AvgS: 374.25 (Eps:0.080 Steps:43619) Guard AvgS: 1074.25 (Eps:0.164 Steps:130873)\n",
      "Scout model saved: scout_learning.pth\n",
      "Guard model saved: guard_learning.pth\n",
      "Ep 2301| Scout AvgS: 385.55 (Eps:0.080 Steps:43644) Guard AvgS: 1072.05 (Eps:0.164 Steps:130948)Guard Target network updated at 131000 learning steps.\n",
      "Ep 2319| Scout AvgS: 382.73 (Eps:0.080 Steps:43993) Guard AvgS: 1049.96 (Eps:0.163 Steps:131997)Guard Target network updated at 132000 learning steps.\n",
      "Scout Target network updated at 44000 learning steps.\n",
      "Ep 2335| Scout AvgS: 411.50 (Eps:0.080 Steps:44322) Guard AvgS: 1062.53 (Eps:0.161 Steps:132982)Guard Target network updated at 133000 learning steps.\n",
      "Ep 2356| Scout AvgS: 413.10 (Eps:0.080 Steps:44650) Guard AvgS: 1039.44 (Eps:0.160 Steps:133967)Guard Target network updated at 134000 learning steps.\n",
      "Ep 2373| Scout AvgS: 405.16 (Eps:0.080 Steps:44990) Guard AvgS: 1040.64 (Eps:0.158 Steps:134988)Guard Target network updated at 135000 learning steps.\n",
      "Ep 2374| Scout AvgS: 405.19 (Eps:0.080 Steps:44996) Guard AvgS: 1027.66 (Eps:0.158 Steps:135004)Scout Target network updated at 45000 learning steps.\n",
      "Ep 2399| Scout AvgS: 358.13 (Eps:0.079 Steps:45320) Guard AvgS: 962.54 (Eps:0.156 Steps:135976))Guard Target network updated at 136000 learning steps.\n",
      "Ep 2400| Scout AvgS: 358.48 (Eps:0.079 Steps:45328) Guard AvgS: 949.39 (Eps:0.156 Steps:136001)\n",
      "Scout model saved: scout_learning.pth\n",
      "Guard model saved: guard_learning.pth\n",
      "Ep 2416| Scout AvgS: 349.57 (Eps:0.079 Steps:45648) Guard AvgS: 997.39 (Eps:0.155 Steps:136961))Guard Target network updated at 137000 learning steps.\n",
      "Ep 2437| Scout AvgS: 303.69 (Eps:0.079 Steps:45987) Guard AvgS: 932.27 (Eps:0.153 Steps:137979)Guard Target network updated at 138000 learning steps.\n",
      "Scout Target network updated at 46000 learning steps.\n",
      "Ep 2452| Scout AvgS: 324.28 (Eps:0.079 Steps:46308) Guard AvgS: 967.96 (Eps:0.152 Steps:138942)Guard Target network updated at 139000 learning steps.\n",
      "Ep 2471| Scout AvgS: 351.05 (Eps:0.079 Steps:46659) Guard AvgS: 1015.35 (Eps:0.151 Steps:139995)Guard Target network updated at 140000 learning steps.\n",
      "Ep 2489| Scout AvgS: 363.50 (Eps:0.079 Steps:46990) Guard AvgS: 1061.03 (Eps:0.149 Steps:140986)Guard Target network updated at 141000 learning steps.\n",
      "Scout Target network updated at 47000 learning steps.\n",
      "Ep 2500| Scout AvgS: 361.56 (Eps:0.079 Steps:47235) Guard AvgS: 1130.28 (Eps:0.149 Steps:141721)\n",
      "Scout model saved: scout_learning.pth\n",
      "Guard model saved: guard_learning.pth\n",
      "Ep 2505| Scout AvgS: 362.51 (Eps:0.079 Steps:47320) Guard AvgS: 1110.28 (Eps:0.148 Steps:141977)Guard Target network updated at 142000 learning steps.\n",
      "Ep 2520| Scout AvgS: 373.69 (Eps:0.078 Steps:47642) Guard AvgS: 1107.46 (Eps:0.147 Steps:142942)Guard Target network updated at 143000 learning steps.\n",
      "Ep 2541| Scout AvgS: 413.89 (Eps:0.078 Steps:47988) Guard AvgS: 1127.89 (Eps:0.146 Steps:143980)Guard Target network updated at 144000 learning steps.\n",
      "Ep 2542| Scout AvgS: 414.35 (Eps:0.078 Steps:47999) Guard AvgS: 1126.29 (Eps:0.145 Steps:144013)Scout Target network updated at 48000 learning steps.\n",
      "Ep 2561| Scout AvgS: 386.34 (Eps:0.078 Steps:48321) Guard AvgS: 1085.25 (Eps:0.144 Steps:144981)Guard Target network updated at 145000 learning steps.\n",
      "Ep 2579| Scout AvgS: 375.42 (Eps:0.078 Steps:48659) Guard AvgS: 1158.60 (Eps:0.143 Steps:145994)Guard Target network updated at 146000 learning steps.\n",
      "Ep 2594| Scout AvgS: 385.56 (Eps:0.078 Steps:48972) Guard AvgS: 1122.42 (Eps:0.142 Steps:146932)Guard Target network updated at 147000 learning steps.\n",
      "Ep 2595| Scout AvgS: 385.77 (Eps:0.078 Steps:48997) Guard AvgS: 1127.42 (Eps:0.142 Steps:147007)Scout Target network updated at 49000 learning steps.\n",
      "Ep 2600| Scout AvgS: 388.63 (Eps:0.078 Steps:49094) Guard AvgS: 1113.59 (Eps:0.141 Steps:147300)\n",
      "Scout model saved: scout_learning.pth\n",
      "Guard model saved: guard_learning.pth\n",
      "Ep 2614| Scout AvgS: 376.29 (Eps:0.078 Steps:49309) Guard AvgS: 1083.24 (Eps:0.140 Steps:147943)Guard Target network updated at 148000 learning steps.\n",
      "Ep 2628| Scout AvgS: 367.56 (Eps:0.078 Steps:49643) Guard AvgS: 1124.58 (Eps:0.139 Steps:148946)Guard Target network updated at 149000 learning steps.\n",
      "Ep 2646| Scout AvgS: 374.01 (Eps:0.077 Steps:49989) Guard AvgS: 1156.58 (Eps:0.138 Steps:149983)Guard Target network updated at 150000 learning steps.\n",
      "Scout Target network updated at 50000 learning steps.\n",
      "Ep 2663| Scout AvgS: 387.79 (Eps:0.077 Steps:50312) Guard AvgS: 1203.68 (Eps:0.137 Steps:150954)Guard Target network updated at 151000 learning steps.\n",
      "Ep 2685| Scout AvgS: 407.94 (Eps:0.077 Steps:50658) Guard AvgS: 1147.98 (Eps:0.135 Steps:151990)Guard Target network updated at 152000 learning steps.\n",
      "Ep 2700| Scout AvgS: 377.96 (Eps:0.077 Steps:50910) Guard AvgS: 1162.66 (Eps:0.134 Steps:152747)\n",
      "Scout model saved: scout_learning.pth\n",
      "Guard model saved: guard_learning.pth\n",
      "Ep 2703| Scout AvgS: 379.91 (Eps:0.077 Steps:50976) Guard AvgS: 1177.22 (Eps:0.134 Steps:152946)Guard Target network updated at 153000 learning steps.\n",
      "Scout Target network updated at 51000 learning steps.\n",
      "Ep 2725| Scout AvgS: 369.48 (Eps:0.077 Steps:51326) Guard AvgS: 1139.00 (Eps:0.133 Steps:153996)Guard Target network updated at 154000 learning steps.\n",
      "Ep 2747| Scout AvgS: 348.34 (Eps:0.077 Steps:51657) Guard AvgS: 1084.77 (Eps:0.131 Steps:154987)Guard Target network updated at 155000 learning steps.\n",
      "Ep 2766| Scout AvgS: 321.57 (Eps:0.077 Steps:51993) Guard AvgS: 1071.57 (Eps:0.130 Steps:155995)Guard Target network updated at 156000 learning steps.\n",
      "Scout Target network updated at 52000 learning steps.\n",
      "Ep 2786| Scout AvgS: 321.07 (Eps:0.076 Steps:52303) Guard AvgS: 1085.78 (Eps:0.129 Steps:156925)Guard Target network updated at 157000 learning steps.\n",
      "Ep 2800| Scout AvgS: 346.95 (Eps:0.076 Steps:52608) Guard AvgS: 1077.70 (Eps:0.128 Steps:157842)\n",
      "Scout model saved: scout_learning.pth\n",
      "Guard model saved: guard_learning.pth\n",
      "Ep 2805| Scout AvgS: 327.18 (Eps:0.076 Steps:52655) Guard AvgS: 1038.58 (Eps:0.128 Steps:157982)Guard Target network updated at 158000 learning steps.\n",
      "Ep 2821| Scout AvgS: 344.13 (Eps:0.076 Steps:52978) Guard AvgS: 1045.04 (Eps:0.127 Steps:158950)Guard Target network updated at 159000 learning steps.\n",
      "Scout Target network updated at 53000 learning steps.\n",
      "Ep 2843| Scout AvgS: 358.71 (Eps:0.076 Steps:53323) Guard AvgS: 1069.14 (Eps:0.125 Steps:159987)Guard Target network updated at 160000 learning steps.\n",
      "Ep 2860| Scout AvgS: 369.23 (Eps:0.076 Steps:53659) Guard AvgS: 1072.50 (Eps:0.124 Steps:160994)Guard Target network updated at 161000 learning steps.\n",
      "Ep 2876| Scout AvgS: 395.21 (Eps:0.076 Steps:53988) Guard AvgS: 1089.62 (Eps:0.123 Steps:161980)Guard Target network updated at 162000 learning steps.\n",
      "Ep 2877| Scout AvgS: 396.07 (Eps:0.076 Steps:53999) Guard AvgS: 1089.48 (Eps:0.123 Steps:162014)Scout Target network updated at 54000 learning steps.\n",
      "Ep 2896| Scout AvgS: 363.47 (Eps:0.076 Steps:54321) Guard AvgS: 1064.75 (Eps:0.122 Steps:162979)Guard Target network updated at 163000 learning steps.\n",
      "Ep 2900| Scout AvgS: 374.16 (Eps:0.075 Steps:54421) Guard AvgS: 1103.59 (Eps:0.122 Steps:163279)\n",
      "Scout model saved: scout_learning.pth\n",
      "Guard model saved: guard_learning.pth\n",
      "Ep 2910| Scout AvgS: 393.98 (Eps:0.075 Steps:54646) Guard AvgS: 1191.50 (Eps:0.121 Steps:163954)Guard Target network updated at 164000 learning steps.\n",
      "Ep 2926| Scout AvgS: 404.18 (Eps:0.075 Steps:54991) Guard AvgS: 1269.95 (Eps:0.120 Steps:164989)Guard Target network updated at 165000 learning steps.\n",
      "Scout Target network updated at 55000 learning steps.\n",
      "Ep 2944| Scout AvgS: 401.73 (Eps:0.075 Steps:55321) Guard AvgS: 1304.82 (Eps:0.119 Steps:165979)Guard Target network updated at 166000 learning steps.\n",
      "Ep 2962| Scout AvgS: 381.28 (Eps:0.075 Steps:55658) Guard AvgS: 1284.64 (Eps:0.118 Steps:166991)Guard Target network updated at 167000 learning steps.\n",
      "Ep 2980| Scout AvgS: 392.94 (Eps:0.075 Steps:55981) Guard AvgS: 1286.08 (Eps:0.117 Steps:167961)Guard Target network updated at 168000 learning steps.\n",
      "Ep 2982| Scout AvgS: 398.06 (Eps:0.075 Steps:55999) Guard AvgS: 1265.16 (Eps:0.117 Steps:168015)Scout Target network updated at 56000 learning steps.\n",
      "Ep 3000| Scout AvgS: 377.84 (Eps:0.075 Steps:56269) Guard AvgS: 1212.38 (Eps:0.116 Steps:168824)\n",
      "Scout model saved: scout_learning.pth\n",
      "Guard model saved: guard_learning.pth\n",
      "Ep 3004| Scout AvgS: 379.63 (Eps:0.075 Steps:56317) Guard AvgS: 1178.19 (Eps:0.115 Steps:168969)Guard Target network updated at 169000 learning steps.\n",
      "Ep 3025| Scout AvgS: 333.42 (Eps:0.075 Steps:56660) Guard AvgS: 1047.31 (Eps:0.114 Steps:169998)Guard Target network updated at 170000 learning steps.\n",
      "Ep 3046| Scout AvgS: 315.37 (Eps:0.074 Steps:56987) Guard AvgS: 975.89 (Eps:0.113 Steps:170979))Guard Target network updated at 171000 learning steps.\n",
      "Scout Target network updated at 57000 learning steps.\n",
      "Ep 3066| Scout AvgS: 318.89 (Eps:0.074 Steps:57323) Guard AvgS: 927.47 (Eps:0.112 Steps:171986)Guard Target network updated at 172000 learning steps.\n",
      "Ep 3083| Scout AvgS: 327.13 (Eps:0.074 Steps:57647) Guard AvgS: 946.01 (Eps:0.111 Steps:172959)Guard Target network updated at 173000 learning steps.\n",
      "Ep 3100| Scout AvgS: 348.75 (Eps:0.074 Steps:57944) Guard AvgS: 983.38 (Eps:0.110 Steps:173850))\n",
      "Scout model saved: scout_learning.pth\n",
      "Guard model saved: guard_learning.pth\n",
      "Ep 3103| Scout AvgS: 329.74 (Eps:0.074 Steps:57970) Guard AvgS: 984.64 (Eps:0.110 Steps:173928)Guard Target network updated at 174000 learning steps.\n",
      "Ep 3104| Scout AvgS: 329.30 (Eps:0.074 Steps:57995) Guard AvgS: 996.64 (Eps:0.110 Steps:174003)Scout Target network updated at 58000 learning steps.\n",
      "Ep 3124| Scout AvgS: 360.80 (Eps:0.074 Steps:58313) Guard AvgS: 1002.52 (Eps:0.109 Steps:174955)Guard Target network updated at 175000 learning steps.\n",
      "Ep 3148| Scout AvgS: 405.94 (Eps:0.074 Steps:58638) Guard AvgS: 989.52 (Eps:0.107 Steps:175931))Guard Target network updated at 176000 learning steps.\n",
      "Ep 3166| Scout AvgS: 375.75 (Eps:0.074 Steps:58981) Guard AvgS: 998.98 (Eps:0.106 Steps:176960))Guard Target network updated at 177000 learning steps.\n",
      "Scout Target network updated at 59000 learning steps.\n",
      "Ep 3180| Scout AvgS: 369.63 (Eps:0.073 Steps:59322) Guard AvgS: 1032.72 (Eps:0.106 Steps:177982)Guard Target network updated at 178000 learning steps.\n",
      "Ep 3200| Scout AvgS: 329.30 (Eps:0.073 Steps:59658) Guard AvgS: 1038.27 (Eps:0.105 Steps:178990)\n",
      "Scout model saved: scout_learning.pth\n",
      "Guard model saved: guard_learning.pth\n",
      "Guard Target network updated at 179000 learning steps.\n",
      "Ep 3220| Scout AvgS: 305.15 (Eps:0.073 Steps:59992) Guard AvgS: 1067.04 (Eps:0.104 Steps:179992)Guard Target network updated at 180000 learning steps.\n",
      "Scout Target network updated at 60000 learning steps.\n",
      "Ep 3237| Scout AvgS: 315.12 (Eps:0.073 Steps:60316) Guard AvgS: 1107.89 (Eps:0.103 Steps:180964)Guard Target network updated at 181000 learning steps.\n",
      "Ep 3256| Scout AvgS: 315.09 (Eps:0.073 Steps:60657) Guard AvgS: 1107.96 (Eps:0.102 Steps:181987)Guard Target network updated at 182000 learning steps.\n",
      "Ep 3279| Scout AvgS: 330.19 (Eps:0.073 Steps:60983) Guard AvgS: 1044.04 (Eps:0.101 Steps:182965)Guard Target network updated at 183000 learning steps.\n",
      "Scout Target network updated at 61000 learning steps.\n",
      "Ep 3299| Scout AvgS: 332.25 (Eps:0.073 Steps:61322) Guard AvgS: 1059.06 (Eps:0.100 Steps:183982)Guard Target network updated at 184000 learning steps.\n",
      "Ep 3300| Scout AvgS: 333.42 (Eps:0.073 Steps:61331) Guard AvgS: 1051.92 (Eps:0.100 Steps:184010)\n",
      "Scout model saved: scout_learning.pth\n",
      "Guard model saved: guard_learning.pth\n",
      "Ep 3323| Scout AvgS: 300.76 (Eps:0.072 Steps:61646) Guard AvgS: 1005.67 (Eps:0.098 Steps:184956)Guard Target network updated at 185000 learning steps.\n",
      "Ep 3340| Scout AvgS: 309.20 (Eps:0.072 Steps:61984) Guard AvgS: 1020.43 (Eps:0.098 Steps:185968)Guard Target network updated at 186000 learning steps.\n",
      "Scout Target network updated at 62000 learning steps.\n",
      "Ep 3356| Scout AvgS: 329.45 (Eps:0.072 Steps:62312) Guard AvgS: 1079.50 (Eps:0.097 Steps:186952)Guard Target network updated at 187000 learning steps.\n",
      "Ep 3382| Scout AvgS: 310.35 (Eps:0.072 Steps:62660) Guard AvgS: 1060.90 (Eps:0.096 Steps:187996)Guard Target network updated at 188000 learning steps.\n",
      "Ep 3397| Scout AvgS: 323.58 (Eps:0.072 Steps:62977) Guard AvgS: 1026.71 (Eps:0.095 Steps:188948)Guard Target network updated at 189000 learning steps.\n",
      "Scout Target network updated at 63000 learning steps.\n",
      "Ep 3400| Scout AvgS: 320.53 (Eps:0.072 Steps:63052) Guard AvgS: 1025.52 (Eps:0.095 Steps:189173)\n",
      "Scout model saved: scout_learning.pth\n",
      "Guard model saved: guard_learning.pth\n",
      "Ep 3412| Scout AvgS: 360.47 (Eps:0.072 Steps:63321) Guard AvgS: 1128.75 (Eps:0.094 Steps:189979)Guard Target network updated at 190000 learning steps.\n",
      "Ep 3428| Scout AvgS: 385.94 (Eps:0.072 Steps:63644) Guard AvgS: 1150.76 (Eps:0.093 Steps:190948)Guard Target network updated at 191000 learning steps.\n",
      "Ep 3448| Scout AvgS: 361.09 (Eps:0.071 Steps:63984) Guard AvgS: 1101.83 (Eps:0.092 Steps:191968)Guard Target network updated at 192000 learning steps.\n",
      "Scout Target network updated at 64000 learning steps.\n",
      "Ep 3466| Scout AvgS: 405.40 (Eps:0.071 Steps:64314) Guard AvgS: 1151.65 (Eps:0.092 Steps:192960)Guard Target network updated at 193000 learning steps.\n",
      "Ep 3482| Scout AvgS: 408.74 (Eps:0.071 Steps:64646) Guard AvgS: 1181.58 (Eps:0.091 Steps:193954)Guard Target network updated at 194000 learning steps.\n",
      "Ep 3498| Scout AvgS: 446.68 (Eps:0.071 Steps:64973) Guard AvgS: 1227.54 (Eps:0.090 Steps:194937)Guard Target network updated at 195000 learning steps.\n",
      "Ep 3499| Scout AvgS: 446.52 (Eps:0.071 Steps:64998) Guard AvgS: 1245.38 (Eps:0.090 Steps:195012)Scout Target network updated at 65000 learning steps.\n",
      "Ep 3500| Scout AvgS: 446.97 (Eps:0.071 Steps:65006) Guard AvgS: 1243.11 (Eps:0.090 Steps:195035)\n",
      "Scout model saved: scout_learning.pth\n",
      "Guard model saved: guard_learning.pth\n",
      "Ep 3524| Scout AvgS: 405.31 (Eps:0.071 Steps:65322) Guard AvgS: 1063.08 (Eps:0.089 Steps:195982)Guard Target network updated at 196000 learning steps.\n",
      "Ep 3543| Scout AvgS: 408.08 (Eps:0.071 Steps:65643) Guard AvgS: 1049.78 (Eps:0.088 Steps:196946)Guard Target network updated at 197000 learning steps.\n",
      "Ep 3568| Scout AvgS: 392.53 (Eps:0.071 Steps:65992) Guard AvgS: 987.55 (Eps:0.087 Steps:197993)Guard Target network updated at 198000 learning steps.\n",
      "Scout Target network updated at 66000 learning steps.\n",
      "Ep 3583| Scout AvgS: 402.66 (Eps:0.071 Steps:66306) Guard AvgS: 1045.60 (Eps:0.086 Steps:198936)Guard Target network updated at 199000 learning steps.\n",
      "Ep 3600| Scout AvgS: 353.43 (Eps:0.070 Steps:66626) Guard AvgS: 1021.62 (Eps:0.086 Steps:199896)\n",
      "Scout model saved: scout_learning.pth\n",
      "Guard model saved: guard_learning.pth\n",
      "Ep 3603| Scout AvgS: 339.19 (Eps:0.070 Steps:66656) Guard AvgS: 1017.47 (Eps:0.086 Steps:199985)Guard Target network updated at 200000 learning steps.\n",
      "Ep 3619| Scout AvgS: 357.84 (Eps:0.070 Steps:66982) Guard AvgS: 1137.09 (Eps:0.085 Steps:200963)Guard Target network updated at 201000 learning steps.\n",
      "Scout Target network updated at 67000 learning steps.\n",
      "Ep 3636| Scout AvgS: 374.52 (Eps:0.070 Steps:67322) Guard AvgS: 1144.93 (Eps:0.084 Steps:201982)Guard Target network updated at 202000 learning steps.\n",
      "Ep 3651| Scout AvgS: 363.95 (Eps:0.070 Steps:67652) Guard AvgS: 1226.74 (Eps:0.084 Steps:202972)Guard Target network updated at 203000 learning steps.\n",
      "Ep 3673| Scout AvgS: 331.51 (Eps:0.070 Steps:67992) Guard AvgS: 1223.55 (Eps:0.083 Steps:203992)Guard Target network updated at 204000 learning steps.\n",
      "Scout Target network updated at 68000 learning steps.\n",
      "Ep 3696| Scout AvgS: 335.38 (Eps:0.070 Steps:68314) Guard AvgS: 1135.66 (Eps:0.082 Steps:204959)Guard Target network updated at 205000 learning steps.\n",
      "Ep 3700| Scout AvgS: 348.07 (Eps:0.070 Steps:68412) Guard AvgS: 1142.47 (Eps:0.082 Steps:205252)\n",
      "Scout model saved: scout_learning.pth\n",
      "Guard model saved: guard_learning.pth\n",
      "Ep 3712| Scout AvgS: 334.88 (Eps:0.070 Steps:68655) Guard AvgS: 1134.20 (Eps:0.081 Steps:205981)Guard Target network updated at 206000 learning steps.\n",
      "Ep 3732| Scout AvgS: 331.27 (Eps:0.069 Steps:68979) Guard AvgS: 1069.27 (Eps:0.080 Steps:206953)Guard Target network updated at 207000 learning steps.\n",
      "Scout Target network updated at 69000 learning steps.\n",
      "Ep 3747| Scout AvgS: 338.38 (Eps:0.069 Steps:69322) Guard AvgS: 1098.37 (Eps:0.080 Steps:207984)Guard Target network updated at 208000 learning steps.\n",
      "Ep 3763| Scout AvgS: 377.47 (Eps:0.069 Steps:69661) Guard AvgS: 1107.97 (Eps:0.079 Steps:208999)Guard Target network updated at 209000 learning steps.\n",
      "Ep 3783| Scout AvgS: 403.00 (Eps:0.069 Steps:69970) Guard AvgS: 1062.51 (Eps:0.078 Steps:209928)Guard Target network updated at 210000 learning steps.\n",
      "Ep 3784| Scout AvgS: 401.61 (Eps:0.069 Steps:69995) Guard AvgS: 1065.22 (Eps:0.078 Steps:210003)Scout Target network updated at 70000 learning steps.\n",
      "Ep 3799| Scout AvgS: 427.19 (Eps:0.069 Steps:70318) Guard AvgS: 1078.94 (Eps:0.078 Steps:210972)Guard Target network updated at 211000 learning steps.\n",
      "Ep 3800| Scout AvgS: 427.18 (Eps:0.069 Steps:70343) Guard AvgS: 1076.16 (Eps:0.078 Steps:211047)\n",
      "Scout model saved: scout_learning.pth\n",
      "Guard model saved: guard_learning.pth\n",
      "Ep 3819| Scout AvgS: 444.11 (Eps:0.069 Steps:70653) Guard AvgS: 1033.16 (Eps:0.077 Steps:211976)Guard Target network updated at 212000 learning steps.\n",
      "Ep 3841| Scout AvgS: 464.26 (Eps:0.069 Steps:70990) Guard AvgS: 1039.49 (Eps:0.076 Steps:212988)Guard Target network updated at 213000 learning steps.\n",
      "Scout Target network updated at 71000 learning steps.\n",
      "Ep 3859| Scout AvgS: 453.69 (Eps:0.069 Steps:71320) Guard AvgS: 1050.47 (Eps:0.075 Steps:213976)Guard Target network updated at 214000 learning steps.\n",
      "Ep 3879| Scout AvgS: 408.97 (Eps:0.068 Steps:71654) Guard AvgS: 1109.84 (Eps:0.075 Steps:214978)Guard Target network updated at 215000 learning steps.\n",
      "Ep 3895| Scout AvgS: 412.37 (Eps:0.068 Steps:71986) Guard AvgS: 1129.96 (Eps:0.074 Steps:215974)Guard Target network updated at 216000 learning steps.\n",
      "Scout Target network updated at 72000 learning steps.\n",
      "Ep 3900| Scout AvgS: 414.78 (Eps:0.068 Steps:72060) Guard AvgS: 1126.31 (Eps:0.074 Steps:216196)\n",
      "Scout model saved: scout_learning.pth\n",
      "Guard model saved: guard_learning.pth\n",
      "Ep 3912| Scout AvgS: 427.35 (Eps:0.068 Steps:72305) Guard AvgS: 1138.24 (Eps:0.073 Steps:216931)Guard Target network updated at 217000 learning steps.\n",
      "Ep 3935| Scout AvgS: 386.17 (Eps:0.068 Steps:72643) Guard AvgS: 1120.85 (Eps:0.072 Steps:217945)Guard Target network updated at 218000 learning steps.\n",
      "Ep 3957| Scout AvgS: 365.49 (Eps:0.068 Steps:72983) Guard AvgS: 1122.40 (Eps:0.072 Steps:218965)Guard Target network updated at 219000 learning steps.\n",
      "Scout Target network updated at 73000 learning steps.\n",
      "Ep 3975| Scout AvgS: 388.35 (Eps:0.068 Steps:73307) Guard AvgS: 1114.97 (Eps:0.071 Steps:219937)Guard Target network updated at 220000 learning steps.\n",
      "Ep 3994| Scout AvgS: 367.89 (Eps:0.068 Steps:73646) Guard AvgS: 1095.88 (Eps:0.070 Steps:220954)Guard Target network updated at 221000 learning steps.\n",
      "Ep 4000| Scout AvgS: 355.26 (Eps:0.068 Steps:73704) Guard AvgS: 1069.09 (Eps:0.070 Steps:221129)\n",
      "Scout model saved: scout_learning.pth\n",
      "Guard model saved: guard_learning.pth\n",
      "Ep 4012| Scout AvgS: 368.34 (Eps:0.068 Steps:73974) Guard AvgS: 1097.33 (Eps:0.070 Steps:221938)Guard Target network updated at 222000 learning steps.\n",
      "Ep 4013| Scout AvgS: 356.64 (Eps:0.068 Steps:73999) Guard AvgS: 1097.47 (Eps:0.070 Steps:222013)Scout Target network updated at 74000 learning steps.\n",
      "Ep 4033| Scout AvgS: 372.12 (Eps:0.067 Steps:74319) Guard AvgS: 1084.34 (Eps:0.069 Steps:222973)Guard Target network updated at 223000 learning steps.\n",
      "Ep 4053| Scout AvgS: 404.38 (Eps:0.067 Steps:74649) Guard AvgS: 1085.61 (Eps:0.068 Steps:223963)Guard Target network updated at 224000 learning steps.\n",
      "Ep 4072| Scout AvgS: 411.33 (Eps:0.067 Steps:74987) Guard AvgS: 1100.59 (Eps:0.068 Steps:224977)Guard Target network updated at 225000 learning steps.\n",
      "Scout Target network updated at 75000 learning steps.\n",
      "Ep 4090| Scout AvgS: 443.15 (Eps:0.067 Steps:75319) Guard AvgS: 1098.50 (Eps:0.067 Steps:225973)Guard Target network updated at 226000 learning steps.\n",
      "Ep 4100| Scout AvgS: 450.10 (Eps:0.067 Steps:75479) Guard AvgS: 1142.16 (Eps:0.067 Steps:226453)\n",
      "Scout model saved: scout_learning.pth\n",
      "Guard model saved: guard_learning.pth\n",
      "Ep 4107| Scout AvgS: 438.35 (Eps:0.067 Steps:75653) Guard AvgS: 1157.05 (Eps:0.066 Steps:226975)Guard Target network updated at 227000 learning steps.\n",
      "Ep 4125| Scout AvgS: 404.45 (Eps:0.067 Steps:75982) Guard AvgS: 1186.81 (Eps:0.066 Steps:227964)Guard Target network updated at 228000 learning steps.\n",
      "Scout Target network updated at 76000 learning steps.\n",
      "Ep 4143| Scout AvgS: 385.95 (Eps:0.067 Steps:76312) Guard AvgS: 1225.92 (Eps:0.065 Steps:228953)Guard Target network updated at 229000 learning steps.\n",
      "Ep 4161| Scout AvgS: 351.25 (Eps:0.067 Steps:76650) Guard AvgS: 1217.30 (Eps:0.065 Steps:229966)Guard Target network updated at 230000 learning steps.\n",
      "Ep 4180| Scout AvgS: 355.26 (Eps:0.066 Steps:76988) Guard AvgS: 1166.70 (Eps:0.064 Steps:230982)Guard Target network updated at 231000 learning steps.\n",
      "Ep 4181| Scout AvgS: 348.13 (Eps:0.066 Steps:76995) Guard AvgS: 1168.88 (Eps:0.064 Steps:231001)Scout Target network updated at 77000 learning steps.\n",
      "Ep 4199| Scout AvgS: 348.38 (Eps:0.066 Steps:77304) Guard AvgS: 1195.33 (Eps:0.064 Steps:231930)Guard Target network updated at 232000 learning steps.\n",
      "Ep 4200| Scout AvgS: 348.38 (Eps:0.066 Steps:77329) Guard AvgS: 1186.52 (Eps:0.063 Steps:232005)\n",
      "Scout model saved: scout_learning.pth\n",
      "Guard model saved: guard_learning.pth\n",
      "Ep 4218| Scout AvgS: 349.81 (Eps:0.066 Steps:77656) Guard AvgS: 1077.40 (Eps:0.063 Steps:232986)Guard Target network updated at 233000 learning steps.\n",
      "Ep 4235| Scout AvgS: 389.78 (Eps:0.066 Steps:77978) Guard AvgS: 1097.15 (Eps:0.062 Steps:233952)Guard Target network updated at 234000 learning steps.\n",
      "Ep 4236| Scout AvgS: 390.50 (Eps:0.066 Steps:77997) Guard AvgS: 1096.96 (Eps:0.062 Steps:234009)Scout Target network updated at 78000 learning steps.\n",
      "Ep 4256| Scout AvgS: 397.54 (Eps:0.066 Steps:78323) Guard AvgS: 1076.05 (Eps:0.062 Steps:234985)Guard Target network updated at 235000 learning steps.\n",
      "Ep 4275| Scout AvgS: 396.90 (Eps:0.066 Steps:78659) Guard AvgS: 1139.64 (Eps:0.061 Steps:235993)Guard Target network updated at 236000 learning steps.\n",
      "Ep 4294| Scout AvgS: 414.19 (Eps:0.066 Steps:78985) Guard AvgS: 1084.49 (Eps:0.061 Steps:236972)Guard Target network updated at 237000 learning steps.\n",
      "Ep 4295| Scout AvgS: 415.48 (Eps:0.066 Steps:78999) Guard AvgS: 1090.98 (Eps:0.061 Steps:237014)Scout Target network updated at 79000 learning steps.\n",
      "Ep 4300| Scout AvgS: 421.89 (Eps:0.066 Steps:79083) Guard AvgS: 1084.51 (Eps:0.060 Steps:237265)\n",
      "Scout model saved: scout_learning.pth\n",
      "Guard model saved: guard_learning.pth\n",
      "Ep 4314| Scout AvgS: 415.94 (Eps:0.066 Steps:79323) Guard AvgS: 1099.24 (Eps:0.060 Steps:237986)Guard Target network updated at 238000 learning steps.\n",
      "Ep 4337| Scout AvgS: 396.71 (Eps:0.065 Steps:79636) Guard AvgS: 1075.42 (Eps:0.059 Steps:238926)Guard Target network updated at 239000 learning steps.\n",
      "Ep 4357| Scout AvgS: 391.30 (Eps:0.065 Steps:79980) Guard AvgS: 1116.58 (Eps:0.059 Steps:239956)Guard Target network updated at 240000 learning steps.\n",
      "Scout Target network updated at 80000 learning steps.\n",
      "Ep 4379| Scout AvgS: 357.96 (Eps:0.065 Steps:80326) Guard AvgS: 1071.81 (Eps:0.058 Steps:240995)Guard Target network updated at 241000 learning steps.\n",
      "Ep 4398| Scout AvgS: 328.72 (Eps:0.065 Steps:80656) Guard AvgS: 1075.63 (Eps:0.057 Steps:241985)Guard Target network updated at 242000 learning steps.\n",
      "Ep 4400| Scout AvgS: 328.39 (Eps:0.065 Steps:80706) Guard AvgS: 1078.89 (Eps:0.057 Steps:242135)\n",
      "Scout model saved: scout_learning.pth\n",
      "Guard model saved: guard_learning.pth\n",
      "Ep 4417| Scout AvgS: 321.68 (Eps:0.065 Steps:80976) Guard AvgS: 1050.33 (Eps:0.057 Steps:242944)Guard Target network updated at 243000 learning steps.\n",
      "Scout Target network updated at 81000 learning steps.\n",
      "Ep 4436| Scout AvgS: 364.45 (Eps:0.065 Steps:81308) Guard AvgS: 1095.52 (Eps:0.056 Steps:243942)Guard Target network updated at 244000 learning steps.\n",
      "Ep 4460| Scout AvgS: 335.61 (Eps:0.065 Steps:81656) Guard AvgS: 1044.69 (Eps:0.056 Steps:244984)Guard Target network updated at 245000 learning steps.\n",
      "Ep 4482| Scout AvgS: 353.63 (Eps:0.064 Steps:81992) Guard AvgS: 1088.25 (Eps:0.055 Steps:245992)Guard Target network updated at 246000 learning steps.\n",
      "Scout Target network updated at 82000 learning steps.\n",
      "Ep 4500| Scout AvgS: 372.73 (Eps:0.064 Steps:82286) Guard AvgS: 1099.00 (Eps:0.055 Steps:246876)\n",
      "Scout model saved: scout_learning.pth\n",
      "Guard model saved: guard_learning.pth\n",
      "Ep 4505| Scout AvgS: 370.68 (Eps:0.064 Steps:82326) Guard AvgS: 1110.13 (Eps:0.054 Steps:246994)Guard Target network updated at 247000 learning steps.\n",
      "Ep 4524| Scout AvgS: 391.68 (Eps:0.064 Steps:82656) Guard AvgS: 1124.91 (Eps:0.054 Steps:247984)Guard Target network updated at 248000 learning steps.\n",
      "Ep 4549| Scout AvgS: 342.09 (Eps:0.064 Steps:82989) Guard AvgS: 1009.36 (Eps:0.053 Steps:248983)Guard Target network updated at 249000 learning steps.\n",
      "Scout Target network updated at 83000 learning steps.\n",
      "Ep 4567| Scout AvgS: 358.09 (Eps:0.064 Steps:83327) Guard AvgS: 1024.53 (Eps:0.053 Steps:249997)Guard Target network updated at 250000 learning steps.\n",
      "Ep 4590| Scout AvgS: 343.81 (Eps:0.064 Steps:83656) Guard AvgS: 979.04 (Eps:0.052 Steps:250986))Guard Target network updated at 251000 learning steps.\n",
      "Ep 4600| Scout AvgS: 338.34 (Eps:0.064 Steps:83854) Guard AvgS: 956.94 (Eps:0.052 Steps:251578)\n",
      "Scout model saved: scout_learning.pth\n",
      "Guard model saved: guard_learning.pth\n",
      "Ep 4608| Scout AvgS: 346.95 (Eps:0.064 Steps:83978) Guard AvgS: 961.57 (Eps:0.052 Steps:251951)Guard Target network updated at 252000 learning steps.\n",
      "Scout Target network updated at 84000 learning steps.\n",
      "Ep 4628| Scout AvgS: 346.41 (Eps:0.064 Steps:84308) Guard AvgS: 980.38 (Eps:0.051 Steps:252940)Guard Target network updated at 253000 learning steps.\n",
      "Ep 4648| Scout AvgS: 378.50 (Eps:0.063 Steps:84659) Guard AvgS: 1115.35 (Eps:0.051 Steps:253993)Guard Target network updated at 254000 learning steps.\n",
      "Ep 4665| Scout AvgS: 381.97 (Eps:0.063 Steps:84990) Guard AvgS: 1145.77 (Eps:0.050 Steps:254987)Guard Target network updated at 255000 learning steps.\n",
      "Scout Target network updated at 85000 learning steps.\n",
      "Ep 4681| Scout AvgS: 394.44 (Eps:0.063 Steps:85325) Guard AvgS: 1191.37 (Eps:0.050 Steps:255991)Guard Target network updated at 256000 learning steps.\n",
      "Ep 4698| Scout AvgS: 381.56 (Eps:0.063 Steps:85642) Guard AvgS: 1212.25 (Eps:0.050 Steps:256944)Guard Target network updated at 257000 learning steps.\n",
      "Ep 4700| Scout AvgS: 381.13 (Eps:0.063 Steps:85692) Guard AvgS: 1223.15 (Eps:0.050 Steps:257094)\n",
      "Scout model saved: scout_learning.pth\n",
      "Guard model saved: guard_learning.pth\n",
      "Ep 4716| Scout AvgS: 381.93 (Eps:0.063 Steps:85991) Guard AvgS: 1208.76 (Eps:0.050 Steps:257989)Guard Target network updated at 258000 learning steps.\n",
      "Scout Target network updated at 86000 learning steps.\n",
      "Ep 4734| Scout AvgS: 371.76 (Eps:0.063 Steps:86321) Guard AvgS: 1200.12 (Eps:0.050 Steps:258980)Guard Target network updated at 259000 learning steps.\n",
      "Ep 4756| Scout AvgS: 371.61 (Eps:0.063 Steps:86660) Guard AvgS: 1130.89 (Eps:0.050 Steps:259998)Guard Target network updated at 260000 learning steps.\n",
      "Ep 4775| Scout AvgS: 384.81 (Eps:0.063 Steps:86990) Guard AvgS: 1113.51 (Eps:0.050 Steps:260988)Guard Target network updated at 261000 learning steps.\n",
      "Scout Target network updated at 87000 learning steps.\n",
      "Ep 4794| Scout AvgS: 365.06 (Eps:0.062 Steps:87327) Guard AvgS: 1121.64 (Eps:0.050 Steps:261999)Guard Target network updated at 262000 learning steps.\n",
      "Ep 4800| Scout AvgS: 371.17 (Eps:0.062 Steps:87424) Guard AvgS: 1120.64 (Eps:0.050 Steps:262288)\n",
      "Scout model saved: scout_learning.pth\n",
      "Guard model saved: guard_learning.pth\n",
      "Ep 4813| Scout AvgS: 358.37 (Eps:0.062 Steps:87652) Guard AvgS: 1110.20 (Eps:0.050 Steps:262972)Guard Target network updated at 263000 learning steps.\n",
      "Ep 4835| Scout AvgS: 348.00 (Eps:0.062 Steps:87974) Guard AvgS: 1128.52 (Eps:0.050 Steps:263940)Guard Target network updated at 264000 learning steps.\n",
      "Ep 4836| Scout AvgS: 346.93 (Eps:0.062 Steps:87996) Guard AvgS: 1112.53 (Eps:0.050 Steps:264004)Scout Target network updated at 88000 learning steps.\n",
      "Ep 4858| Scout AvgS: 347.37 (Eps:0.062 Steps:88316) Guard AvgS: 1102.25 (Eps:0.050 Steps:264966)Guard Target network updated at 265000 learning steps.\n",
      "Ep 4881| Scout AvgS: 334.76 (Eps:0.062 Steps:88654) Guard AvgS: 1094.80 (Eps:0.050 Steps:265978)Guard Target network updated at 266000 learning steps.\n",
      "Ep 4900| Scout AvgS: 340.92 (Eps:0.062 Steps:88930) Guard AvgS: 1069.24 (Eps:0.050 Steps:266806)\n",
      "Scout model saved: scout_learning.pth\n",
      "Guard model saved: guard_learning.pth\n",
      "Ep 4904| Scout AvgS: 350.20 (Eps:0.062 Steps:88971) Guard AvgS: 1076.14 (Eps:0.050 Steps:266931)Guard Target network updated at 267000 learning steps.\n",
      "Ep 4905| Scout AvgS: 347.49 (Eps:0.062 Steps:88996) Guard AvgS: 1074.10 (Eps:0.050 Steps:267006)Scout Target network updated at 89000 learning steps.\n",
      "Ep 4924| Scout AvgS: 333.21 (Eps:0.062 Steps:89320) Guard AvgS: 1067.88 (Eps:0.050 Steps:267978)Guard Target network updated at 268000 learning steps.\n",
      "Ep 4943| Scout AvgS: 335.43 (Eps:0.062 Steps:89641) Guard AvgS: 1036.74 (Eps:0.050 Steps:268940)Guard Target network updated at 269000 learning steps.\n",
      "Ep 4962| Scout AvgS: 380.84 (Eps:0.061 Steps:89985) Guard AvgS: 1027.00 (Eps:0.050 Steps:269973)Guard Target network updated at 270000 learning steps.\n",
      "Scout Target network updated at 90000 learning steps.\n",
      "Ep 4980| Scout AvgS: 397.76 (Eps:0.061 Steps:90313) Guard AvgS: 1030.44 (Eps:0.050 Steps:270955)Guard Target network updated at 271000 learning steps.\n",
      "Ep 5000| Scout AvgS: 396.42 (Eps:0.061 Steps:90601) Guard AvgS: 1040.70 (Eps:0.050 Steps:271819)\n",
      "Scout model saved: scout_learning.pth\n",
      "Guard model saved: guard_learning.pth\n",
      "Ep 5003| Scout AvgS: 406.36 (Eps:0.061 Steps:90644) Guard AvgS: 1032.40 (Eps:0.050 Steps:271948)Guard Target network updated at 272000 learning steps.\n",
      "Ep 5020| Scout AvgS: 420.94 (Eps:0.061 Steps:90991) Guard AvgS: 1111.00 (Eps:0.050 Steps:272989)Guard Target network updated at 273000 learning steps.\n",
      "Scout Target network updated at 91000 learning steps.\n",
      "Ep 5038| Scout AvgS: 455.01 (Eps:0.061 Steps:91318) Guard AvgS: 1122.82 (Eps:0.050 Steps:273970)Guard Target network updated at 274000 learning steps.\n",
      "Ep 5054| Scout AvgS: 444.32 (Eps:0.061 Steps:91639) Guard AvgS: 1093.09 (Eps:0.050 Steps:274934)Guard Target network updated at 275000 learning steps.\n",
      "Ep 5073| Scout AvgS: 408.41 (Eps:0.061 Steps:91975) Guard AvgS: 1105.00 (Eps:0.050 Steps:275943)Guard Target network updated at 276000 learning steps.\n",
      "Scout Target network updated at 92000 learning steps.\n",
      "Ep 5090| Scout AvgS: 398.53 (Eps:0.061 Steps:92307) Guard AvgS: 1077.89 (Eps:0.050 Steps:276937)Guard Target network updated at 277000 learning steps.\n",
      "Ep 5100| Scout AvgS: 390.51 (Eps:0.061 Steps:92517) Guard AvgS: 1089.97 (Eps:0.050 Steps:277567)\n",
      "Scout model saved: scout_learning.pth\n",
      "Guard model saved: guard_learning.pth\n",
      "Ep 5109| Scout AvgS: 377.53 (Eps:0.061 Steps:92643) Guard AvgS: 1072.48 (Eps:0.050 Steps:277945)Guard Target network updated at 278000 learning steps.\n",
      "Ep 5129| Scout AvgS: 370.62 (Eps:0.060 Steps:92975) Guard AvgS: 1045.55 (Eps:0.050 Steps:278942)Guard Target network updated at 279000 learning steps.\n",
      "Scout Target network updated at 93000 learning steps.\n",
      "Ep 5144| Scout AvgS: 361.46 (Eps:0.060 Steps:93309) Guard AvgS: 1102.32 (Eps:0.050 Steps:279943)Guard Target network updated at 280000 learning steps.\n",
      "Ep 5165| Scout AvgS: 374.03 (Eps:0.060 Steps:93657) Guard AvgS: 1163.85 (Eps:0.050 Steps:280988)Guard Target network updated at 281000 learning steps.\n",
      "Ep 5185| Scout AvgS: 365.72 (Eps:0.060 Steps:93988) Guard AvgS: 1097.04 (Eps:0.050 Steps:281980)Guard Target network updated at 282000 learning steps.\n",
      "Scout Target network updated at 94000 learning steps.\n",
      "Ep 5200| Scout AvgS: 390.10 (Eps:0.060 Steps:94243) Guard AvgS: 1109.76 (Eps:0.050 Steps:282745)\n",
      "Scout model saved: scout_learning.pth\n",
      "Guard model saved: guard_learning.pth\n",
      "Ep 5205| Scout AvgS: 403.10 (Eps:0.060 Steps:94321) Guard AvgS: 1096.28 (Eps:0.050 Steps:282979)Guard Target network updated at 283000 learning steps.\n",
      "Ep 5221| Scout AvgS: 410.93 (Eps:0.060 Steps:94638) Guard AvgS: 1093.47 (Eps:0.050 Steps:283932)Guard Target network updated at 284000 learning steps.\n",
      "Ep 5239| Scout AvgS: 405.55 (Eps:0.060 Steps:94986) Guard AvgS: 1112.36 (Eps:0.050 Steps:284974)Guard Target network updated at 285000 learning steps.\n",
      "Ep 5240| Scout AvgS: 405.54 (Eps:0.060 Steps:94997) Guard AvgS: 1114.42 (Eps:0.050 Steps:285008)Scout Target network updated at 95000 learning steps.\n",
      "Ep 5259| Scout AvgS: 387.17 (Eps:0.060 Steps:95315) Guard AvgS: 1075.12 (Eps:0.050 Steps:285961)Guard Target network updated at 286000 learning steps.\n",
      "Ep 5284| Scout AvgS: 380.17 (Eps:0.059 Steps:95653) Guard AvgS: 1076.18 (Eps:0.050 Steps:286976)Guard Target network updated at 287000 learning steps.\n",
      "Ep 5300| Scout AvgS: 353.23 (Eps:0.059 Steps:95866) Guard AvgS: 1039.43 (Eps:0.050 Steps:287616)\n",
      "Scout model saved: scout_learning.pth\n",
      "Guard model saved: guard_learning.pth\n",
      "Ep 5305| Scout AvgS: 343.64 (Eps:0.059 Steps:95977) Guard AvgS: 1071.82 (Eps:0.050 Steps:287948)Guard Target network updated at 288000 learning steps.\n",
      "Scout Target network updated at 96000 learning steps.\n",
      "Ep 5324| Scout AvgS: 353.24 (Eps:0.059 Steps:96315) Guard AvgS: 1031.89 (Eps:0.050 Steps:288963)Guard Target network updated at 289000 learning steps.\n",
      "Ep 5339| Scout AvgS: 357.62 (Eps:0.059 Steps:96657) Guard AvgS: 1038.30 (Eps:0.050 Steps:289987)Guard Target network updated at 290000 learning steps.\n",
      "Ep 5355| Scout AvgS: 353.24 (Eps:0.059 Steps:96976) Guard AvgS: 1068.52 (Eps:0.050 Steps:290944)Guard Target network updated at 291000 learning steps.\n",
      "Scout Target network updated at 97000 learning steps.\n",
      "Ep 5373| Scout AvgS: 355.11 (Eps:0.059 Steps:97311) Guard AvgS: 1112.72 (Eps:0.050 Steps:291949)Guard Target network updated at 292000 learning steps.\n",
      "Ep 5391| Scout AvgS: 404.47 (Eps:0.059 Steps:97657) Guard AvgS: 1126.12 (Eps:0.050 Steps:292987)Guard Target network updated at 293000 learning steps.\n",
      "Ep 5400| Scout AvgS: 428.79 (Eps:0.059 Steps:97773) Guard AvgS: 1121.63 (Eps:0.050 Steps:293337)\n",
      "Scout model saved: scout_learning.pth\n",
      "Guard model saved: guard_learning.pth\n",
      "Ep 5410| Scout AvgS: 439.43 (Eps:0.059 Steps:97984) Guard AvgS: 1121.17 (Eps:0.050 Steps:293968)Guard Target network updated at 294000 learning steps.\n",
      "Scout Target network updated at 98000 learning steps.\n",
      "Ep 5430| Scout AvgS: 412.23 (Eps:0.059 Steps:98319) Guard AvgS: 1172.10 (Eps:0.050 Steps:294974)Guard Target network updated at 295000 learning steps.\n",
      "Ep 5450| Scout AvgS: 413.24 (Eps:0.058 Steps:98655) Guard AvgS: 1200.30 (Eps:0.050 Steps:295983)Guard Target network updated at 296000 learning steps.\n",
      "Ep 5469| Scout AvgS: 410.28 (Eps:0.058 Steps:98973) Guard AvgS: 1202.38 (Eps:0.050 Steps:296935)Guard Target network updated at 297000 learning steps.\n",
      "Ep 5470| Scout AvgS: 410.25 (Eps:0.058 Steps:98998) Guard AvgS: 1206.27 (Eps:0.050 Steps:297010)Scout Target network updated at 99000 learning steps.\n",
      "Ep 5490| Scout AvgS: 390.69 (Eps:0.058 Steps:99324) Guard AvgS: 1194.46 (Eps:0.050 Steps:297988)Guard Target network updated at 298000 learning steps.\n",
      "Ep 5500| Scout AvgS: 393.23 (Eps:0.058 Steps:99504) Guard AvgS: 1187.83 (Eps:0.050 Steps:298528)\n",
      "Scout model saved: scout_learning.pth\n",
      "Guard model saved: guard_learning.pth\n",
      "Ep 5508| Scout AvgS: 370.40 (Eps:0.058 Steps:99645) Guard AvgS: 1190.00 (Eps:0.050 Steps:298952)Guard Target network updated at 299000 learning steps.\n",
      "Ep 5523| Scout AvgS: 386.75 (Eps:0.058 Steps:99981) Guard AvgS: 1178.76 (Eps:0.050 Steps:299961)Guard Target network updated at 300000 learning steps.\n",
      "Scout Target network updated at 100000 learning steps.\n",
      "Ep 5540| Scout AvgS: 383.16 (Eps:0.058 Steps:100319) Guard AvgS: 1167.18 (Eps:0.050 Steps:300974)Guard Target network updated at 301000 learning steps.\n",
      "Ep 5560| Scout AvgS: 402.67 (Eps:0.058 Steps:100652) Guard AvgS: 1138.15 (Eps:0.050 Steps:301974)Guard Target network updated at 302000 learning steps.\n",
      "Ep 5581| Scout AvgS: 398.70 (Eps:0.058 Steps:100994) Guard AvgS: 1132.38 (Eps:0.050 Steps:302999)Guard Target network updated at 303000 learning steps.\n",
      "Scout Target network updated at 101000 learning steps.\n",
      "Ep 5599| Scout AvgS: 402.41 (Eps:0.058 Steps:101307) Guard AvgS: 1171.90 (Eps:0.050 Steps:303939)Guard Target network updated at 304000 learning steps.\n",
      "Ep 5600| Scout AvgS: 401.42 (Eps:0.058 Steps:101328) Guard AvgS: 1177.14 (Eps:0.050 Steps:304000)\n",
      "Scout model saved: scout_learning.pth\n",
      "Guard model saved: guard_learning.pth\n",
      "Ep 5617| Scout AvgS: 418.48 (Eps:0.058 Steps:101638) Guard AvgS: 1142.87 (Eps:0.050 Steps:304930)Guard Target network updated at 305000 learning steps.\n",
      "Ep 5638| Scout AvgS: 416.87 (Eps:0.057 Steps:101987) Guard AvgS: 1046.21 (Eps:0.050 Steps:305977)Guard Target network updated at 306000 learning steps.\n",
      "Scout Target network updated at 102000 learning steps.\n",
      "Ep 5655| Scout AvgS: 390.89 (Eps:0.057 Steps:102314) Guard AvgS: 1084.00 (Eps:0.050 Steps:306960)Guard Target network updated at 307000 learning steps.\n",
      "Ep 5673| Scout AvgS: 375.71 (Eps:0.057 Steps:102656) Guard AvgS: 1132.45 (Eps:0.050 Steps:307984)Guard Target network updated at 308000 learning steps.\n",
      "Ep 5693| Scout AvgS: 378.91 (Eps:0.057 Steps:102994) Guard AvgS: 1106.27 (Eps:0.050 Steps:308998)Guard Target network updated at 309000 learning steps.\n",
      "Scout Target network updated at 103000 learning steps.\n",
      "Ep 5700| Scout AvgS: 366.70 (Eps:0.057 Steps:103143) Guard AvgS: 1131.70 (Eps:0.050 Steps:309447)\n",
      "Scout model saved: scout_learning.pth\n",
      "Guard model saved: guard_learning.pth\n",
      "Ep 5708| Scout AvgS: 387.72 (Eps:0.057 Steps:103310) Guard AvgS: 1131.98 (Eps:0.050 Steps:309948)Guard Target network updated at 310000 learning steps.\n",
      "Ep 5726| Scout AvgS: 366.13 (Eps:0.057 Steps:103644) Guard AvgS: 1249.56 (Eps:0.050 Steps:310950)Guard Target network updated at 311000 learning steps.\n",
      "Ep 5744| Scout AvgS: 380.77 (Eps:0.057 Steps:103978) Guard AvgS: 1275.02 (Eps:0.050 Steps:311951)Guard Target network updated at 312000 learning steps.\n",
      "Scout Target network updated at 104000 learning steps.\n",
      "Ep 5763| Scout AvgS: 421.25 (Eps:0.057 Steps:104318) Guard AvgS: 1257.49 (Eps:0.050 Steps:312970)Guard Target network updated at 313000 learning steps.\n",
      "Ep 5781| Scout AvgS: 421.28 (Eps:0.057 Steps:104653) Guard AvgS: 1251.18 (Eps:0.050 Steps:313975)Guard Target network updated at 314000 learning steps.\n",
      "Ep 5800| Scout AvgS: 391.71 (Eps:0.056 Steps:104917) Guard AvgS: 1190.15 (Eps:0.050 Steps:314768)\n",
      "Scout model saved: scout_learning.pth\n",
      "Guard model saved: guard_learning.pth\n",
      "Ep 5803| Scout AvgS: 399.79 (Eps:0.056 Steps:104987) Guard AvgS: 1180.94 (Eps:0.050 Steps:314979)Guard Target network updated at 315000 learning steps.\n",
      "Scout Target network updated at 105000 learning steps.\n",
      "Ep 5820| Scout AvgS: 403.91 (Eps:0.056 Steps:105324) Guard AvgS: 1153.68 (Eps:0.050 Steps:315988)Guard Target network updated at 316000 learning steps.\n",
      "Ep 5837| Scout AvgS: 408.65 (Eps:0.056 Steps:105648) Guard AvgS: 1140.38 (Eps:0.050 Steps:316961)Guard Target network updated at 317000 learning steps.\n",
      "Ep 5855| Scout AvgS: 390.60 (Eps:0.056 Steps:105972) Guard AvgS: 1228.64 (Eps:0.050 Steps:317934)Guard Target network updated at 318000 learning steps.\n",
      "Ep 5856| Scout AvgS: 390.27 (Eps:0.056 Steps:105997) Guard AvgS: 1251.69 (Eps:0.050 Steps:318009)Scout Target network updated at 106000 learning steps.\n",
      "Ep 5873| Scout AvgS: 347.72 (Eps:0.056 Steps:106323) Guard AvgS: 1229.61 (Eps:0.050 Steps:318985)Guard Target network updated at 319000 learning steps.\n",
      "Ep 5890| Scout AvgS: 377.64 (Eps:0.056 Steps:106658) Guard AvgS: 1265.56 (Eps:0.050 Steps:319992)Guard Target network updated at 320000 learning steps.\n",
      "Ep 5900| Scout AvgS: 390.05 (Eps:0.056 Steps:106797) Guard AvgS: 1281.51 (Eps:0.050 Steps:320407)\n",
      "Scout model saved: scout_learning.pth\n",
      "Guard model saved: guard_learning.pth\n",
      "Ep 5908| Scout AvgS: 388.86 (Eps:0.056 Steps:106973) Guard AvgS: 1262.97 (Eps:0.050 Steps:320935)Guard Target network updated at 321000 learning steps.\n",
      "Ep 5909| Scout AvgS: 394.15 (Eps:0.056 Steps:106998) Guard AvgS: 1262.81 (Eps:0.050 Steps:321010)Scout Target network updated at 107000 learning steps.\n",
      "Ep 5926| Scout AvgS: 382.47 (Eps:0.056 Steps:107322) Guard AvgS: 1264.12 (Eps:0.050 Steps:321983)Guard Target network updated at 322000 learning steps.\n",
      "Ep 5949| Scout AvgS: 361.46 (Eps:0.056 Steps:107642) Guard AvgS: 1174.36 (Eps:0.050 Steps:322944)Guard Target network updated at 323000 learning steps.\n",
      "Ep 5967| Scout AvgS: 364.71 (Eps:0.056 Steps:107987) Guard AvgS: 1078.57 (Eps:0.050 Steps:323977)Guard Target network updated at 324000 learning steps.\n",
      "Scout Target network updated at 108000 learning steps.\n",
      "Ep 5985| Scout AvgS: 394.60 (Eps:0.055 Steps:108323) Guard AvgS: 1005.71 (Eps:0.050 Steps:324986)Guard Target network updated at 325000 learning steps.\n",
      "Ep 6000| Scout AvgS: 367.66 (Eps:0.055 Steps:108586) Guard AvgS: 992.27 (Eps:0.050 Steps:325774))\n",
      "Scout model saved: scout_learning.pth\n",
      "Guard model saved: guard_learning.pth\n",
      "Ep 6004| Scout AvgS: 387.91 (Eps:0.055 Steps:108656) Guard AvgS: 997.78 (Eps:0.050 Steps:325985))Guard Target network updated at 326000 learning steps.\n",
      "Ep 6022| Scout AvgS: 350.48 (Eps:0.055 Steps:108986) Guard AvgS: 968.99 (Eps:0.050 Steps:326976))Guard Target network updated at 327000 learning steps.\n",
      "Scout Target network updated at 109000 learning steps.\n",
      "Ep 6046| Scout AvgS: 404.25 (Eps:0.055 Steps:109320) Guard AvgS: 982.15 (Eps:0.050 Steps:327978)Guard Target network updated at 328000 learning steps.\n",
      "Ep 6065| Scout AvgS: 417.32 (Eps:0.055 Steps:109652) Guard AvgS: 1008.60 (Eps:0.050 Steps:328972)Guard Target network updated at 329000 learning steps.\n",
      "Ep 6085| Scout AvgS: 389.37 (Eps:0.055 Steps:109986) Guard AvgS: 1087.74 (Eps:0.050 Steps:329974)Guard Target network updated at 330000 learning steps.\n",
      "Ep 6086| Scout AvgS: 390.78 (Eps:0.055 Steps:109997) Guard AvgS: 1082.64 (Eps:0.050 Steps:330008)Scout Target network updated at 110000 learning steps.\n",
      "Ep 6100| Scout AvgS: 418.08 (Eps:0.055 Steps:110289) Guard AvgS: 1179.84 (Eps:0.050 Steps:330885)\n",
      "Scout model saved: scout_learning.pth\n",
      "Guard model saved: guard_learning.pth\n",
      "Ep 6103| Scout AvgS: 401.10 (Eps:0.055 Steps:110326) Guard AvgS: 1176.68 (Eps:0.050 Steps:330995)Guard Target network updated at 331000 learning steps.\n",
      "Ep 6123| Scout AvgS: 415.87 (Eps:0.055 Steps:110647) Guard AvgS: 1170.13 (Eps:0.050 Steps:331957)Guard Target network updated at 332000 learning steps.\n",
      "Ep 6140| Scout AvgS: 432.48 (Eps:0.055 Steps:110984) Guard AvgS: 1270.11 (Eps:0.050 Steps:332968)Guard Target network updated at 333000 learning steps.\n",
      "Scout Target network updated at 111000 learning steps.\n",
      "Ep 6158| Scout AvgS: 426.90 (Eps:0.054 Steps:111319) Guard AvgS: 1256.10 (Eps:0.050 Steps:333974)Guard Target network updated at 334000 learning steps.\n",
      "Ep 6176| Scout AvgS: 464.62 (Eps:0.054 Steps:111647) Guard AvgS: 1282.45 (Eps:0.050 Steps:334957)Guard Target network updated at 335000 learning steps.\n",
      "Ep 6191| Scout AvgS: 478.37 (Eps:0.054 Steps:111970) Guard AvgS: 1268.09 (Eps:0.050 Steps:335926)Guard Target network updated at 336000 learning steps.\n",
      "Ep 6192| Scout AvgS: 478.37 (Eps:0.054 Steps:111995) Guard AvgS: 1265.69 (Eps:0.050 Steps:336001)Scout Target network updated at 112000 learning steps.\n",
      "Ep 6200| Scout AvgS: 473.08 (Eps:0.054 Steps:112138) Guard AvgS: 1218.77 (Eps:0.050 Steps:336430)\n",
      "Scout model saved: scout_learning.pth\n",
      "Guard model saved: guard_learning.pth\n",
      "Ep 6207| Scout AvgS: 499.39 (Eps:0.054 Steps:112310) Guard AvgS: 1250.68 (Eps:0.050 Steps:336947)Guard Target network updated at 337000 learning steps.\n",
      "Ep 6224| Scout AvgS: 501.60 (Eps:0.054 Steps:112650) Guard AvgS: 1249.10 (Eps:0.050 Steps:337967)Guard Target network updated at 338000 learning steps.\n",
      "Ep 6244| Scout AvgS: 452.28 (Eps:0.054 Steps:112991) Guard AvgS: 1252.68 (Eps:0.050 Steps:338990)Guard Target network updated at 339000 learning steps.\n",
      "Ep 6245| Scout AvgS: 436.73 (Eps:0.054 Steps:112999) Guard AvgS: 1254.93 (Eps:0.050 Steps:339015)Scout Target network updated at 113000 learning steps.\n",
      "Ep 6262| Scout AvgS: 403.00 (Eps:0.054 Steps:113304) Guard AvgS: 1255.35 (Eps:0.050 Steps:339929)Guard Target network updated at 340000 learning steps.\n",
      "Ep 6281| Scout AvgS: 370.76 (Eps:0.054 Steps:113655) Guard AvgS: 1213.65 (Eps:0.050 Steps:340981)Guard Target network updated at 341000 learning steps.\n",
      "Ep 6299| Scout AvgS: 323.59 (Eps:0.054 Steps:113990) Guard AvgS: 1214.46 (Eps:0.050 Steps:341986)Guard Target network updated at 342000 learning steps.\n",
      "Scout Target network updated at 114000 learning steps.\n",
      "Ep 6300| Scout AvgS: 323.60 (Eps:0.054 Steps:114015) Guard AvgS: 1215.27 (Eps:0.050 Steps:342061)\n",
      "Scout model saved: scout_learning.pth\n",
      "Guard model saved: guard_learning.pth\n",
      "Ep 6316| Scout AvgS: 311.37 (Eps:0.054 Steps:114307) Guard AvgS: 1184.70 (Eps:0.050 Steps:342937)Guard Target network updated at 343000 learning steps.\n",
      "Ep 6335| Scout AvgS: 329.70 (Eps:0.054 Steps:114643) Guard AvgS: 1200.62 (Eps:0.050 Steps:343945)Guard Target network updated at 344000 learning steps.\n",
      "Ep 6353| Scout AvgS: 360.10 (Eps:0.053 Steps:114978) Guard AvgS: 1175.32 (Eps:0.050 Steps:344950)Guard Target network updated at 345000 learning steps.\n",
      "Scout Target network updated at 115000 learning steps.\n",
      "Ep 6373| Scout AvgS: 392.89 (Eps:0.053 Steps:115314) Guard AvgS: 1155.48 (Eps:0.050 Steps:345958)Guard Target network updated at 346000 learning steps.\n",
      "Ep 6388| Scout AvgS: 420.43 (Eps:0.053 Steps:115643) Guard AvgS: 1197.18 (Eps:0.050 Steps:346945)Guard Target network updated at 347000 learning steps.\n",
      "Ep 6400| Scout AvgS: 446.25 (Eps:0.053 Steps:115884) Guard AvgS: 1198.29 (Eps:0.050 Steps:347670)\n",
      "Scout model saved: scout_learning.pth\n",
      "Guard model saved: guard_learning.pth\n",
      "Ep 6408| Scout AvgS: 437.05 (Eps:0.053 Steps:115989) Guard AvgS: 1186.65 (Eps:0.050 Steps:347984)Guard Target network updated at 348000 learning steps.\n",
      "Ep 6409| Scout AvgS: 419.80 (Eps:0.053 Steps:115997) Guard AvgS: 1188.74 (Eps:0.050 Steps:348007)Scout Target network updated at 116000 learning steps.\n",
      "Ep 6427| Scout AvgS: 402.49 (Eps:0.053 Steps:116323) Guard AvgS: 1157.10 (Eps:0.050 Steps:348986)Guard Target network updated at 349000 learning steps.\n",
      "Ep 6444| Scout AvgS: 410.86 (Eps:0.053 Steps:116639) Guard AvgS: 1135.34 (Eps:0.050 Steps:349933)Guard Target network updated at 350000 learning steps.\n",
      "Ep 6461| Scout AvgS: 389.07 (Eps:0.053 Steps:116984) Guard AvgS: 1155.33 (Eps:0.050 Steps:350969)Guard Target network updated at 351000 learning steps.\n",
      "Ep 6462| Scout AvgS: 387.99 (Eps:0.053 Steps:116998) Guard AvgS: 1146.60 (Eps:0.050 Steps:351010)Scout Target network updated at 117000 learning steps.\n",
      "Ep 6480| Scout AvgS: 365.02 (Eps:0.053 Steps:117321) Guard AvgS: 1160.62 (Eps:0.050 Steps:351981)Guard Target network updated at 352000 learning steps.\n",
      "Ep 6497| Scout AvgS: 361.33 (Eps:0.053 Steps:117652) Guard AvgS: 1138.77 (Eps:0.050 Steps:352972)Guard Target network updated at 353000 learning steps.\n",
      "Ep 6500| Scout AvgS: 364.95 (Eps:0.053 Steps:117683) Guard AvgS: 1115.98 (Eps:0.050 Steps:353067)\n",
      "Scout model saved: scout_learning.pth\n",
      "Guard model saved: guard_learning.pth\n",
      "Ep 6520| Scout AvgS: 394.24 (Eps:0.053 Steps:117992) Guard AvgS: 1148.68 (Eps:0.050 Steps:353994)Guard Target network updated at 354000 learning steps.\n",
      "Scout Target network updated at 118000 learning steps.\n",
      "Ep 6536| Scout AvgS: 395.26 (Eps:0.052 Steps:118322) Guard AvgS: 1167.19 (Eps:0.050 Steps:354983)Guard Target network updated at 355000 learning steps.\n",
      "Ep 6553| Scout AvgS: 403.03 (Eps:0.052 Steps:118656) Guard AvgS: 1146.02 (Eps:0.050 Steps:355985)Guard Target network updated at 356000 learning steps.\n",
      "Ep 6571| Scout AvgS: 436.91 (Eps:0.052 Steps:118986) Guard AvgS: 1183.31 (Eps:0.050 Steps:356974)Guard Target network updated at 357000 learning steps.\n",
      "Scout Target network updated at 119000 learning steps.\n",
      "Ep 6587| Scout AvgS: 463.06 (Eps:0.052 Steps:119325) Guard AvgS: 1209.93 (Eps:0.050 Steps:357991)Guard Target network updated at 358000 learning steps.\n",
      "Ep 6600| Scout AvgS: 473.78 (Eps:0.052 Steps:119645) Guard AvgS: 1292.27 (Eps:0.050 Steps:358952)\n",
      "Scout model saved: scout_learning.pth\n",
      "Guard model saved: guard_learning.pth\n",
      "Guard Target network updated at 359000 learning steps.\n",
      "Ep 6620| Scout AvgS: 488.57 (Eps:0.052 Steps:119992) Guard AvgS: 1269.67 (Eps:0.050 Steps:359992)Guard Target network updated at 360000 learning steps.\n",
      "Scout Target network updated at 120000 learning steps.\n",
      "Ep 6641| Scout AvgS: 454.67 (Eps:0.052 Steps:120311) Guard AvgS: 1267.19 (Eps:0.050 Steps:360950)Guard Target network updated at 361000 learning steps.\n",
      "Ep 6659| Scout AvgS: 456.57 (Eps:0.052 Steps:120653) Guard AvgS: 1243.40 (Eps:0.050 Steps:361977)Guard Target network updated at 362000 learning steps.\n",
      "Ep 6682| Scout AvgS: 417.53 (Eps:0.052 Steps:120979) Guard AvgS: 1158.20 (Eps:0.050 Steps:362955)Guard Target network updated at 363000 learning steps.\n",
      "Scout Target network updated at 121000 learning steps.\n",
      "Ep 6699| Scout AvgS: 367.31 (Eps:0.052 Steps:121318) Guard AvgS: 1117.74 (Eps:0.050 Steps:363970)Guard Target network updated at 364000 learning steps.\n",
      "Ep 6700| Scout AvgS: 367.50 (Eps:0.052 Steps:121343) Guard AvgS: 1118.52 (Eps:0.050 Steps:364045)\n",
      "Scout model saved: scout_learning.pth\n",
      "Guard model saved: guard_learning.pth\n",
      "Ep 6713| Scout AvgS: 356.30 (Eps:0.052 Steps:121636) Guard AvgS: 1156.33 (Eps:0.050 Steps:364926)Guard Target network updated at 365000 learning steps.\n",
      "Ep 6729| Scout AvgS: 356.10 (Eps:0.051 Steps:121987) Guard AvgS: 1185.64 (Eps:0.050 Steps:365977)Guard Target network updated at 366000 learning steps.\n",
      "Ep 6730| Scout AvgS: 356.99 (Eps:0.051 Steps:121998) Guard AvgS: 1188.06 (Eps:0.050 Steps:366010)Scout Target network updated at 122000 learning steps.\n",
      "Ep 6748| Scout AvgS: 355.45 (Eps:0.051 Steps:122320) Guard AvgS: 1156.23 (Eps:0.050 Steps:366977)Guard Target network updated at 367000 learning steps.\n",
      "Ep 6763| Scout AvgS: 388.22 (Eps:0.051 Steps:122653) Guard AvgS: 1228.26 (Eps:0.050 Steps:367977)Guard Target network updated at 368000 learning steps.\n",
      "Ep 6780| Scout AvgS: 372.16 (Eps:0.051 Steps:122973) Guard AvgS: 1286.12 (Eps:0.050 Steps:368935)Guard Target network updated at 369000 learning steps.\n",
      "Ep 6781| Scout AvgS: 370.17 (Eps:0.051 Steps:122998) Guard AvgS: 1285.91 (Eps:0.050 Steps:369010)Scout Target network updated at 123000 learning steps.\n",
      "Ep 6799| Scout AvgS: 370.83 (Eps:0.051 Steps:123327) Guard AvgS: 1230.99 (Eps:0.050 Steps:369997)Guard Target network updated at 370000 learning steps.\n",
      "Ep 6800| Scout AvgS: 372.14 (Eps:0.051 Steps:123334) Guard AvgS: 1215.02 (Eps:0.050 Steps:370018)\n",
      "Scout model saved: scout_learning.pth\n",
      "Guard model saved: guard_learning.pth\n",
      "Ep 6814| Scout AvgS: 406.57 (Eps:0.051 Steps:123637) Guard AvgS: 1225.28 (Eps:0.050 Steps:370929)Guard Target network updated at 371000 learning steps.\n",
      "Ep 6830| Scout AvgS: 425.94 (Eps:0.051 Steps:123984) Guard AvgS: 1243.27 (Eps:0.050 Steps:371969)Guard Target network updated at 372000 learning steps.\n",
      "Ep 6831| Scout AvgS: 425.93 (Eps:0.051 Steps:123999) Guard AvgS: 1248.75 (Eps:0.050 Steps:372013)Scout Target network updated at 124000 learning steps.\n",
      "Ep 6852| Scout AvgS: 435.08 (Eps:0.051 Steps:124315) Guard AvgS: 1226.32 (Eps:0.050 Steps:372963)Guard Target network updated at 373000 learning steps.\n",
      "Ep 6870| Scout AvgS: 454.08 (Eps:0.051 Steps:124645) Guard AvgS: 1183.68 (Eps:0.050 Steps:373952)Guard Target network updated at 374000 learning steps.\n",
      "Ep 6887| Scout AvgS: 448.14 (Eps:0.051 Steps:124991) Guard AvgS: 1177.74 (Eps:0.050 Steps:374991)Guard Target network updated at 375000 learning steps.\n",
      "Scout Target network updated at 125000 learning steps.\n",
      "Ep 6900| Scout AvgS: 480.15 (Eps:0.051 Steps:125219) Guard AvgS: 1199.98 (Eps:0.050 Steps:375673)\n",
      "Scout model saved: scout_learning.pth\n",
      "Guard model saved: guard_learning.pth\n",
      "Ep 6905| Scout AvgS: 450.43 (Eps:0.051 Steps:125322) Guard AvgS: 1181.59 (Eps:0.050 Steps:375984)Guard Target network updated at 376000 learning steps.\n",
      "Ep 6924| Scout AvgS: 416.57 (Eps:0.050 Steps:125659) Guard AvgS: 1093.09 (Eps:0.050 Steps:376995)Guard Target network updated at 377000 learning steps.\n",
      "Ep 6943| Scout AvgS: 407.36 (Eps:0.050 Steps:125982) Guard AvgS: 1069.92 (Eps:0.050 Steps:377962)Guard Target network updated at 378000 learning steps.\n",
      "Scout Target network updated at 126000 learning steps.\n",
      "Ep 6958| Scout AvgS: 375.12 (Eps:0.050 Steps:126310) Guard AvgS: 1151.32 (Eps:0.050 Steps:378946)Guard Target network updated at 379000 learning steps.\n",
      "Ep 6980| Scout AvgS: 370.96 (Eps:0.050 Steps:126659) Guard AvgS: 1071.21 (Eps:0.050 Steps:379994)Guard Target network updated at 380000 learning steps.\n",
      "Ep 6996| Scout AvgS: 401.69 (Eps:0.050 Steps:126987) Guard AvgS: 1181.83 (Eps:0.050 Steps:380977)Guard Target network updated at 381000 learning steps.\n",
      "Scout Target network updated at 127000 learning steps.\n",
      "Ep 7000| Scout AvgS: 399.26 (Eps:0.050 Steps:127052) Guard AvgS: 1176.69 (Eps:0.050 Steps:381172)\n",
      "Scout model saved: scout_learning.pth\n",
      "Guard model saved: guard_learning.pth\n",
      "Ep 7015| Scout AvgS: 406.18 (Eps:0.050 Steps:127322) Guard AvgS: 1154.99 (Eps:0.050 Steps:381982)Guard Target network updated at 382000 learning steps.\n",
      "Ep 7031| Scout AvgS: 416.41 (Eps:0.050 Steps:127652) Guard AvgS: 1168.11 (Eps:0.050 Steps:382974)Guard Target network updated at 383000 learning steps.\n",
      "Ep 7047| Scout AvgS: 415.65 (Eps:0.050 Steps:127989) Guard AvgS: 1208.79 (Eps:0.050 Steps:383983)Guard Target network updated at 384000 learning steps.\n",
      "Ep 7048| Scout AvgS: 415.67 (Eps:0.050 Steps:127997) Guard AvgS: 1201.33 (Eps:0.050 Steps:384007)Scout Target network updated at 128000 learning steps.\n",
      "Ep 7066| Scout AvgS: 436.70 (Eps:0.050 Steps:128325) Guard AvgS: 1162.78 (Eps:0.050 Steps:384991)Guard Target network updated at 385000 learning steps.\n",
      "Ep 7083| Scout AvgS: 426.22 (Eps:0.050 Steps:128654) Guard AvgS: 1223.73 (Eps:0.050 Steps:385978)Guard Target network updated at 386000 learning steps.\n",
      "Ep 7100| Scout AvgS: 410.71 (Eps:0.050 Steps:128874) Guard AvgS: 1140.30 (Eps:0.050 Steps:386640)\n",
      "Scout model saved: scout_learning.pth\n",
      "Guard model saved: guard_learning.pth\n",
      "Ep 7107| Scout AvgS: 412.32 (Eps:0.050 Steps:128993) Guard AvgS: 1132.79 (Eps:0.050 Steps:386995)Guard Target network updated at 387000 learning steps.\n",
      "Scout Target network updated at 129000 learning steps.\n",
      "Ep 7123| Scout AvgS: 447.39 (Eps:0.049 Steps:129318) Guard AvgS: 1169.55 (Eps:0.050 Steps:387970)Guard Target network updated at 388000 learning steps.\n",
      "Ep 7141| Scout AvgS: 445.72 (Eps:0.049 Steps:129659) Guard AvgS: 1169.16 (Eps:0.050 Steps:388993)Guard Target network updated at 389000 learning steps.\n",
      "Ep 7157| Scout AvgS: 470.59 (Eps:0.049 Steps:129981) Guard AvgS: 1220.30 (Eps:0.050 Steps:389960)Guard Target network updated at 390000 learning steps.\n",
      "Scout Target network updated at 130000 learning steps.\n",
      "Ep 7173| Scout AvgS: 469.44 (Eps:0.049 Steps:130324) Guard AvgS: 1182.92 (Eps:0.050 Steps:390990)Guard Target network updated at 391000 learning steps.\n",
      "Ep 7188| Scout AvgS: 473.21 (Eps:0.049 Steps:130643) Guard AvgS: 1213.10 (Eps:0.050 Steps:391945)Guard Target network updated at 392000 learning steps.\n",
      "Ep 7200| Scout AvgS: 485.07 (Eps:0.049 Steps:130932) Guard AvgS: 1314.75 (Eps:0.050 Steps:392812)\n",
      "Scout model saved: scout_learning.pth\n",
      "Guard model saved: guard_learning.pth\n",
      "Ep 7202| Scout AvgS: 464.79 (Eps:0.049 Steps:130977) Guard AvgS: 1315.64 (Eps:0.050 Steps:392948)Guard Target network updated at 393000 learning steps.\n",
      "Scout Target network updated at 131000 learning steps.\n",
      "Ep 7223| Scout AvgS: 428.60 (Eps:0.049 Steps:131311) Guard AvgS: 1306.49 (Eps:0.050 Steps:393949)Guard Target network updated at 394000 learning steps.\n",
      "Ep 7243| Scout AvgS: 407.63 (Eps:0.049 Steps:131655) Guard AvgS: 1320.64 (Eps:0.050 Steps:394982)Guard Target network updated at 395000 learning steps.\n",
      "Ep 7259| Scout AvgS: 407.50 (Eps:0.049 Steps:131989) Guard AvgS: 1308.82 (Eps:0.050 Steps:395983)Guard Target network updated at 396000 learning steps.\n",
      "Ep 7260| Scout AvgS: 407.84 (Eps:0.049 Steps:131997) Guard AvgS: 1296.04 (Eps:0.050 Steps:396007)Scout Target network updated at 132000 learning steps.\n",
      "Ep 7276| Scout AvgS: 390.92 (Eps:0.049 Steps:132325) Guard AvgS: 1339.29 (Eps:0.050 Steps:396993)Guard Target network updated at 397000 learning steps.\n",
      "Ep 7292| Scout AvgS: 391.42 (Eps:0.049 Steps:132647) Guard AvgS: 1295.71 (Eps:0.050 Steps:397957)Guard Target network updated at 398000 learning steps.\n",
      "Ep 7300| Scout AvgS: 391.83 (Eps:0.049 Steps:132796) Guard AvgS: 1265.34 (Eps:0.050 Steps:398404)\n",
      "Scout model saved: scout_learning.pth\n",
      "Guard model saved: guard_learning.pth\n",
      "Ep 7309| Scout AvgS: 427.56 (Eps:0.049 Steps:132991) Guard AvgS: 1297.14 (Eps:0.050 Steps:398991)Guard Target network updated at 399000 learning steps.\n",
      "Ep 7310| Scout AvgS: 428.11 (Eps:0.049 Steps:132995) Guard AvgS: 1280.08 (Eps:0.050 Steps:399002)Scout Target network updated at 133000 learning steps.\n",
      "Ep 7326| Scout AvgS: 429.19 (Eps:0.048 Steps:133314) Guard AvgS: 1238.91 (Eps:0.050 Steps:399958)Guard Target network updated at 400000 learning steps.\n",
      "Ep 7345| Scout AvgS: 417.23 (Eps:0.048 Steps:133641) Guard AvgS: 1195.19 (Eps:0.050 Steps:400941)Guard Target network updated at 401000 learning steps.\n",
      "Ep 7365| Scout AvgS: 422.47 (Eps:0.048 Steps:133983) Guard AvgS: 1147.46 (Eps:0.050 Steps:401967)Guard Target network updated at 402000 learning steps.\n",
      "Scout Target network updated at 134000 learning steps.\n",
      "Ep 7386| Scout AvgS: 394.06 (Eps:0.048 Steps:134315) Guard AvgS: 1072.94 (Eps:0.050 Steps:402963)Guard Target network updated at 403000 learning steps.\n",
      "Ep 7400| Scout AvgS: 384.35 (Eps:0.048 Steps:134612) Guard AvgS: 1120.36 (Eps:0.050 Steps:403854)\n",
      "Scout model saved: scout_learning.pth\n",
      "Guard model saved: guard_learning.pth\n",
      "Ep 7401| Scout AvgS: 403.39 (Eps:0.048 Steps:134637) Guard AvgS: 1118.28 (Eps:0.050 Steps:403929)Guard Target network updated at 404000 learning steps.\n",
      "Ep 7419| Scout AvgS: 367.51 (Eps:0.048 Steps:134992) Guard AvgS: 1142.25 (Eps:0.050 Steps:404992)Guard Target network updated at 405000 learning steps.\n",
      "Scout Target network updated at 135000 learning steps.\n",
      "Ep 7434| Scout AvgS: 392.84 (Eps:0.048 Steps:135327) Guard AvgS: 1249.63 (Eps:0.050 Steps:405997)Guard Target network updated at 406000 learning steps.\n",
      "Ep 7453| Scout AvgS: 396.79 (Eps:0.048 Steps:135655) Guard AvgS: 1256.92 (Eps:0.050 Steps:406983)Guard Target network updated at 407000 learning steps.\n",
      "Ep 7473| Scout AvgS: 400.94 (Eps:0.048 Steps:135989) Guard AvgS: 1319.02 (Eps:0.050 Steps:407984)Guard Target network updated at 408000 learning steps.\n",
      "Ep 7474| Scout AvgS: 400.96 (Eps:0.048 Steps:135998) Guard AvgS: 1315.30 (Eps:0.050 Steps:408010)Scout Target network updated at 136000 learning steps.\n",
      "Ep 7495| Scout AvgS: 396.16 (Eps:0.048 Steps:136316) Guard AvgS: 1293.17 (Eps:0.050 Steps:408966)Guard Target network updated at 409000 learning steps.\n",
      "Ep 7500| Scout AvgS: 399.54 (Eps:0.048 Steps:136429) Guard AvgS: 1284.11 (Eps:0.050 Steps:409305)\n",
      "Scout model saved: scout_learning.pth\n",
      "Guard model saved: guard_learning.pth\n",
      "Ep 7514| Scout AvgS: 379.32 (Eps:0.048 Steps:136655) Guard AvgS: 1202.89 (Eps:0.050 Steps:409983)Guard Target network updated at 410000 learning steps.\n",
      "Ep 7533| Scout AvgS: 356.83 (Eps:0.047 Steps:136972) Guard AvgS: 1138.94 (Eps:0.050 Steps:410934)Guard Target network updated at 411000 learning steps.\n",
      "Ep 7534| Scout AvgS: 356.83 (Eps:0.047 Steps:136997) Guard AvgS: 1137.75 (Eps:0.050 Steps:411009)Scout Target network updated at 137000 learning steps.\n",
      "Ep 7550| Scout AvgS: 365.79 (Eps:0.047 Steps:137325) Guard AvgS: 1139.94 (Eps:0.050 Steps:411991)Guard Target network updated at 412000 learning steps.\n",
      "Ep 7566| Scout AvgS: 370.40 (Eps:0.047 Steps:137647) Guard AvgS: 1133.28 (Eps:0.050 Steps:412958)Guard Target network updated at 413000 learning steps.\n",
      "Ep 7584| Scout AvgS: 398.02 (Eps:0.047 Steps:137976) Guard AvgS: 1208.99 (Eps:0.050 Steps:413944)Guard Target network updated at 414000 learning steps.\n",
      "Scout Target network updated at 138000 learning steps.\n",
      "Ep 7599| Scout AvgS: 414.49 (Eps:0.047 Steps:138320) Guard AvgS: 1209.90 (Eps:0.050 Steps:414977)Guard Target network updated at 415000 learning steps.\n",
      "Ep 7600| Scout AvgS: 414.48 (Eps:0.047 Steps:138345) Guard AvgS: 1208.33 (Eps:0.050 Steps:415052)\n",
      "Scout model saved: scout_learning.pth\n",
      "Guard model saved: guard_learning.pth\n",
      "Ep 7617| Scout AvgS: 434.19 (Eps:0.047 Steps:138648) Guard AvgS: 1167.55 (Eps:0.050 Steps:415960)Guard Target network updated at 416000 learning steps.\n",
      "Ep 7632| Scout AvgS: 444.50 (Eps:0.047 Steps:138987) Guard AvgS: 1224.29 (Eps:0.050 Steps:416977)Guard Target network updated at 417000 learning steps.\n",
      "Scout Target network updated at 139000 learning steps.\n",
      "Ep 7650| Scout AvgS: 460.47 (Eps:0.047 Steps:139317) Guard AvgS: 1257.03 (Eps:0.050 Steps:417967)Guard Target network updated at 418000 learning steps.\n",
      "Ep 7667| Scout AvgS: 471.63 (Eps:0.047 Steps:139651) Guard AvgS: 1236.81 (Eps:0.050 Steps:418971)Guard Target network updated at 419000 learning steps.\n",
      "Ep 7683| Scout AvgS: 450.48 (Eps:0.047 Steps:139989) Guard AvgS: 1280.02 (Eps:0.050 Steps:419983)Guard Target network updated at 420000 learning steps.\n",
      "Scout Target network updated at 140000 learning steps.\n",
      "Ep 7700| Scout AvgS: 433.85 (Eps:0.047 Steps:140285) Guard AvgS: 1232.37 (Eps:0.050 Steps:420873)\n",
      "Scout model saved: scout_learning.pth\n",
      "Guard model saved: guard_learning.pth\n",
      "Ep 7703| Scout AvgS: 453.44 (Eps:0.047 Steps:140319) Guard AvgS: 1227.94 (Eps:0.050 Steps:420975)Guard Target network updated at 421000 learning steps.\n",
      "Ep 7721| Scout AvgS: 421.84 (Eps:0.047 Steps:140659) Guard AvgS: 1286.28 (Eps:0.050 Steps:421993)Guard Target network updated at 422000 learning steps.\n",
      "Ep 7740| Scout AvgS: 405.84 (Eps:0.047 Steps:140989) Guard AvgS: 1237.21 (Eps:0.050 Steps:422983)Guard Target network updated at 423000 learning steps.\n",
      "Scout Target network updated at 141000 learning steps.\n",
      "Ep 7756| Scout AvgS: 396.15 (Eps:0.046 Steps:141319) Guard AvgS: 1251.79 (Eps:0.050 Steps:423974)Guard Target network updated at 424000 learning steps.\n",
      "Ep 7774| Scout AvgS: 389.28 (Eps:0.046 Steps:141660) Guard AvgS: 1219.13 (Eps:0.050 Steps:424996)Guard Target network updated at 425000 learning steps.\n",
      "Ep 7790| Scout AvgS: 367.88 (Eps:0.046 Steps:141984) Guard AvgS: 1187.57 (Eps:0.050 Steps:425968)Guard Target network updated at 426000 learning steps.\n",
      "Scout Target network updated at 142000 learning steps.\n",
      "Ep 7800| Scout AvgS: 367.53 (Eps:0.046 Steps:142181) Guard AvgS: 1216.12 (Eps:0.050 Steps:426559)\n",
      "Scout model saved: scout_learning.pth\n",
      "Guard model saved: guard_learning.pth\n",
      "Ep 7807| Scout AvgS: 376.71 (Eps:0.046 Steps:142322) Guard AvgS: 1248.31 (Eps:0.050 Steps:426984)Guard Target network updated at 427000 learning steps.\n",
      "Ep 7823| Scout AvgS: 405.48 (Eps:0.046 Steps:142651) Guard AvgS: 1295.17 (Eps:0.050 Steps:427971)Guard Target network updated at 428000 learning steps.\n",
      "Ep 7846| Scout AvgS: 441.95 (Eps:0.046 Steps:142989) Guard AvgS: 1190.70 (Eps:0.050 Steps:428984)Guard Target network updated at 429000 learning steps.\n",
      "Scout Target network updated at 143000 learning steps.\n",
      "Ep 7864| Scout AvgS: 434.73 (Eps:0.046 Steps:143305) Guard AvgS: 1189.47 (Eps:0.050 Steps:429933)Guard Target network updated at 430000 learning steps.\n",
      "Ep 7886| Scout AvgS: 401.91 (Eps:0.046 Steps:143659) Guard AvgS: 1202.72 (Eps:0.050 Steps:430993)Guard Target network updated at 431000 learning steps.\n",
      "Ep 7900| Scout AvgS: 406.73 (Eps:0.046 Steps:143878) Guard AvgS: 1181.86 (Eps:0.050 Steps:431650)\n",
      "Scout model saved: scout_learning.pth\n",
      "Guard model saved: guard_learning.pth\n",
      "Ep 7905| Scout AvgS: 399.72 (Eps:0.046 Steps:143993) Guard AvgS: 1182.64 (Eps:0.050 Steps:431996)Guard Target network updated at 432000 learning steps.\n",
      "Scout Target network updated at 144000 learning steps.\n",
      "Ep 7919| Scout AvgS: 390.23 (Eps:0.046 Steps:144318) Guard AvgS: 1179.86 (Eps:0.050 Steps:432972)Guard Target network updated at 433000 learning steps.\n",
      "Ep 7937| Scout AvgS: 381.04 (Eps:0.046 Steps:144651) Guard AvgS: 1194.32 (Eps:0.050 Steps:433969)Guard Target network updated at 434000 learning steps.\n",
      "Ep 7952| Scout AvgS: 354.02 (Eps:0.046 Steps:144971) Guard AvgS: 1255.65 (Eps:0.050 Steps:434931)Guard Target network updated at 435000 learning steps.\n",
      "Ep 7953| Scout AvgS: 361.89 (Eps:0.046 Steps:144996) Guard AvgS: 1253.58 (Eps:0.050 Steps:435006)Scout Target network updated at 145000 learning steps.\n",
      "Ep 7967| Scout AvgS: 395.12 (Eps:0.045 Steps:145321) Guard AvgS: 1295.56 (Eps:0.050 Steps:435979)Guard Target network updated at 436000 learning steps.\n",
      "Ep 7985| Scout AvgS: 419.19 (Eps:0.045 Steps:145642) Guard AvgS: 1320.47 (Eps:0.050 Steps:436942)Guard Target network updated at 437000 learning steps.\n",
      "Ep 8000| Scout AvgS: 428.81 (Eps:0.045 Steps:145938) Guard AvgS: 1311.04 (Eps:0.050 Steps:437830)\n",
      "Scout model saved: scout_learning.pth\n",
      "Guard model saved: guard_learning.pth\n",
      "Ep 8002| Scout AvgS: 424.72 (Eps:0.045 Steps:145974) Guard AvgS: 1321.67 (Eps:0.050 Steps:437938)Guard Target network updated at 438000 learning steps.\n",
      "Ep 8003| Scout AvgS: 424.61 (Eps:0.045 Steps:145999) Guard AvgS: 1322.18 (Eps:0.050 Steps:438013)Scout Target network updated at 146000 learning steps.\n",
      "Ep 8019| Scout AvgS: 430.33 (Eps:0.045 Steps:146312) Guard AvgS: 1352.30 (Eps:0.050 Steps:438953)Guard Target network updated at 439000 learning steps.\n",
      "Ep 8037| Scout AvgS: 397.56 (Eps:0.045 Steps:146654) Guard AvgS: 1362.92 (Eps:0.050 Steps:439978)Guard Target network updated at 440000 learning steps.\n",
      "Ep 8053| Scout AvgS: 383.54 (Eps:0.045 Steps:146973) Guard AvgS: 1284.82 (Eps:0.050 Steps:440937)Guard Target network updated at 441000 learning steps.\n",
      "Ep 8054| Scout AvgS: 382.57 (Eps:0.045 Steps:146996) Guard AvgS: 1293.43 (Eps:0.050 Steps:441004)Scout Target network updated at 147000 learning steps.\n",
      "Ep 8071| Scout AvgS: 379.38 (Eps:0.045 Steps:147310) Guard AvgS: 1272.35 (Eps:0.050 Steps:441948)Guard Target network updated at 442000 learning steps.\n",
      "Ep 8087| Scout AvgS: 365.47 (Eps:0.045 Steps:147636) Guard AvgS: 1307.89 (Eps:0.050 Steps:442926)Guard Target network updated at 443000 learning steps.\n",
      "Ep 8100| Scout AvgS: 388.34 (Eps:0.045 Steps:147902) Guard AvgS: 1322.33 (Eps:0.050 Steps:443722)\n",
      "Scout model saved: scout_learning.pth\n",
      "Guard model saved: guard_learning.pth\n",
      "Ep 8104| Scout AvgS: 403.64 (Eps:0.045 Steps:147983) Guard AvgS: 1295.13 (Eps:0.050 Steps:443966)Guard Target network updated at 444000 learning steps.\n",
      "Scout Target network updated at 148000 learning steps.\n",
      "Ep 8120| Scout AvgS: 412.21 (Eps:0.045 Steps:148318) Guard AvgS: 1273.25 (Eps:0.050 Steps:444971)Guard Target network updated at 445000 learning steps.\n",
      "Ep 8140| Scout AvgS: 475.36 (Eps:0.045 Steps:148657) Guard AvgS: 1299.34 (Eps:0.050 Steps:445988)Guard Target network updated at 446000 learning steps.\n",
      "Ep 8159| Scout AvgS: 469.49 (Eps:0.045 Steps:148991) Guard AvgS: 1275.10 (Eps:0.050 Steps:446991)Guard Target network updated at 447000 learning steps.\n",
      "Scout Target network updated at 149000 learning steps.\n",
      "Ep 8173| Scout AvgS: 440.58 (Eps:0.045 Steps:149320) Guard AvgS: 1304.79 (Eps:0.050 Steps:447976)Guard Target network updated at 448000 learning steps.\n",
      "Ep 8189| Scout AvgS: 465.37 (Eps:0.044 Steps:149660) Guard AvgS: 1314.09 (Eps:0.050 Steps:448997)Guard Target network updated at 449000 learning steps.\n",
      "Ep 8200| Scout AvgS: 443.18 (Eps:0.044 Steps:149834) Guard AvgS: 1281.10 (Eps:0.050 Steps:449519)\n",
      "Scout model saved: scout_learning.pth\n",
      "Guard model saved: guard_learning.pth\n",
      "Ep 8209| Scout AvgS: 420.55 (Eps:0.044 Steps:149993) Guard AvgS: 1250.75 (Eps:0.050 Steps:449995)Guard Target network updated at 450000 learning steps.\n",
      "Scout Target network updated at 150000 learning steps.\n",
      "Ep 8224| Scout AvgS: 411.01 (Eps:0.044 Steps:150311) Guard AvgS: 1266.09 (Eps:0.050 Steps:450949)Guard Target network updated at 451000 learning steps.\n",
      "Ep 8239| Scout AvgS: 411.07 (Eps:0.044 Steps:150656) Guard AvgS: 1298.10 (Eps:0.050 Steps:451985)Guard Target network updated at 452000 learning steps.\n",
      "Ep 8255| Scout AvgS: 419.68 (Eps:0.044 Steps:150980) Guard AvgS: 1349.58 (Eps:0.050 Steps:452956)Guard Target network updated at 453000 learning steps.\n",
      "Scout Target network updated at 151000 learning steps.\n",
      "Ep 8274| Scout AvgS: 450.42 (Eps:0.044 Steps:151324) Guard AvgS: 1306.44 (Eps:0.050 Steps:453988)Guard Target network updated at 454000 learning steps.\n",
      "Ep 8293| Scout AvgS: 452.30 (Eps:0.044 Steps:151642) Guard AvgS: 1271.76 (Eps:0.050 Steps:454942)Guard Target network updated at 455000 learning steps.\n",
      "Ep 8300| Scout AvgS: 443.03 (Eps:0.044 Steps:151759) Guard AvgS: 1303.43 (Eps:0.050 Steps:455295)\n",
      "Scout model saved: scout_learning.pth\n",
      "Guard model saved: guard_learning.pth\n",
      "Ep 8313| Scout AvgS: 434.13 (Eps:0.044 Steps:151981) Guard AvgS: 1295.17 (Eps:0.050 Steps:455959)Guard Target network updated at 456000 learning steps.\n",
      "Scout Target network updated at 152000 learning steps.\n",
      "Ep 8330| Scout AvgS: 432.82 (Eps:0.044 Steps:152303) Guard AvgS: 1303.63 (Eps:0.050 Steps:456927)Guard Target network updated at 457000 learning steps.\n",
      "Ep 8346| Scout AvgS: 423.41 (Eps:0.044 Steps:152650) Guard AvgS: 1234.59 (Eps:0.050 Steps:457966)Guard Target network updated at 458000 learning steps.\n",
      "Ep 8366| Scout AvgS: 419.37 (Eps:0.044 Steps:152976) Guard AvgS: 1150.19 (Eps:0.050 Steps:458944)Guard Target network updated at 459000 learning steps.\n",
      "Scout Target network updated at 153000 learning steps.\n",
      "Ep 8382| Scout AvgS: 439.04 (Eps:0.044 Steps:153313) Guard AvgS: 1235.45 (Eps:0.050 Steps:459955)Guard Target network updated at 460000 learning steps.\n",
      "Ep 8398| Scout AvgS: 453.25 (Eps:0.044 Steps:153648) Guard AvgS: 1281.36 (Eps:0.050 Steps:460961)Guard Target network updated at 461000 learning steps.\n",
      "Ep 8400| Scout AvgS: 452.69 (Eps:0.044 Steps:153684) Guard AvgS: 1295.33 (Eps:0.050 Steps:461070)\n",
      "Scout model saved: scout_learning.pth\n",
      "Guard model saved: guard_learning.pth\n",
      "Ep 8414| Scout AvgS: 472.45 (Eps:0.043 Steps:153977) Guard AvgS: 1314.57 (Eps:0.050 Steps:461947)Guard Target network updated at 462000 learning steps.\n",
      "Scout Target network updated at 154000 learning steps.\n",
      "Ep 8433| Scout AvgS: 459.35 (Eps:0.043 Steps:154309) Guard AvgS: 1305.38 (Eps:0.050 Steps:462944)Guard Target network updated at 463000 learning steps.\n",
      "Ep 8449| Scout AvgS: 433.93 (Eps:0.043 Steps:154653) Guard AvgS: 1314.76 (Eps:0.050 Steps:463977)Guard Target network updated at 464000 learning steps.\n",
      "Ep 8466| Scout AvgS: 449.47 (Eps:0.043 Steps:154991) Guard AvgS: 1346.23 (Eps:0.050 Steps:464990)Guard Target network updated at 465000 learning steps.\n",
      "Ep 8467| Scout AvgS: 449.91 (Eps:0.043 Steps:154999) Guard AvgS: 1336.00 (Eps:0.050 Steps:465013)Scout Target network updated at 155000 learning steps.\n",
      "Ep 8482| Scout AvgS: 433.89 (Eps:0.043 Steps:155322) Guard AvgS: 1354.07 (Eps:0.050 Steps:465982)Guard Target network updated at 466000 learning steps.\n",
      "Ep 8498| Scout AvgS: 432.69 (Eps:0.043 Steps:155656) Guard AvgS: 1296.78 (Eps:0.050 Steps:466984)Guard Target network updated at 467000 learning steps.\n",
      "Ep 8500| Scout AvgS: 433.73 (Eps:0.043 Steps:155687) Guard AvgS: 1277.77 (Eps:0.050 Steps:467077)\n",
      "Scout model saved: scout_learning.pth\n",
      "Guard model saved: guard_learning.pth\n",
      "Ep 8514| Scout AvgS: 436.81 (Eps:0.043 Steps:155975) Guard AvgS: 1301.63 (Eps:0.050 Steps:467942)Guard Target network updated at 468000 learning steps.\n",
      "Scout Target network updated at 156000 learning steps.\n",
      "Ep 8532| Scout AvgS: 461.80 (Eps:0.043 Steps:156309) Guard AvgS: 1320.74 (Eps:0.050 Steps:468944)Guard Target network updated at 469000 learning steps.\n",
      "Ep 8550| Scout AvgS: 505.28 (Eps:0.043 Steps:156642) Guard AvgS: 1256.67 (Eps:0.050 Steps:469944)Guard Target network updated at 470000 learning steps.\n",
      "Ep 8565| Scout AvgS: 488.77 (Eps:0.043 Steps:156977) Guard AvgS: 1290.51 (Eps:0.050 Steps:470947)Guard Target network updated at 471000 learning steps.\n",
      "Scout Target network updated at 157000 learning steps.\n",
      "Ep 8583| Scout AvgS: 505.77 (Eps:0.043 Steps:157320) Guard AvgS: 1241.77 (Eps:0.050 Steps:471976)Guard Target network updated at 472000 learning steps.\n",
      "Ep 8600| Scout AvgS: 506.66 (Eps:0.043 Steps:157656) Guard AvgS: 1258.93 (Eps:0.050 Steps:472986)\n",
      "Scout model saved: scout_learning.pth\n",
      "Guard model saved: guard_learning.pth\n",
      "Guard Target network updated at 473000 learning steps.\n",
      "Ep 8619| Scout AvgS: 494.27 (Eps:0.043 Steps:157977) Guard AvgS: 1188.98 (Eps:0.050 Steps:473949)Guard Target network updated at 474000 learning steps.\n",
      "Scout Target network updated at 158000 learning steps.\n",
      "Ep 8635| Scout AvgS: 476.50 (Eps:0.043 Steps:158303) Guard AvgS: 1212.24 (Eps:0.050 Steps:474926)Guard Target network updated at 475000 learning steps.\n",
      "Ep 8655| Scout AvgS: 488.42 (Eps:0.042 Steps:158652) Guard AvgS: 1280.16 (Eps:0.050 Steps:475972)Guard Target network updated at 476000 learning steps.\n",
      "Ep 8673| Scout AvgS: 510.79 (Eps:0.042 Steps:158988) Guard AvgS: 1251.85 (Eps:0.050 Steps:476982)Guard Target network updated at 477000 learning steps.\n",
      "Scout Target network updated at 159000 learning steps.\n",
      "Ep 8690| Scout AvgS: 484.32 (Eps:0.042 Steps:159313) Guard AvgS: 1264.06 (Eps:0.050 Steps:477956)Guard Target network updated at 478000 learning steps.\n",
      "Ep 8700| Scout AvgS: 482.79 (Eps:0.042 Steps:159536) Guard AvgS: 1263.79 (Eps:0.050 Steps:478625)\n",
      "Scout model saved: scout_learning.pth\n",
      "Guard model saved: guard_learning.pth\n",
      "Ep 8704| Scout AvgS: 485.23 (Eps:0.042 Steps:159636) Guard AvgS: 1250.71 (Eps:0.050 Steps:478925)Guard Target network updated at 479000 learning steps.\n",
      "Ep 8721| Scout AvgS: 485.49 (Eps:0.042 Steps:159992) Guard AvgS: 1302.15 (Eps:0.050 Steps:479993)Guard Target network updated at 480000 learning steps.\n",
      "Scout Target network updated at 160000 learning steps.\n",
      "Ep 8740| Scout AvgS: 468.06 (Eps:0.042 Steps:160303) Guard AvgS: 1236.20 (Eps:0.050 Steps:480925)Guard Target network updated at 481000 learning steps.\n",
      "Ep 8760| Scout AvgS: 457.71 (Eps:0.042 Steps:160659) Guard AvgS: 1269.41 (Eps:0.050 Steps:481993)Guard Target network updated at 482000 learning steps.\n",
      "Ep 8778| Scout AvgS: 452.00 (Eps:0.042 Steps:160977) Guard AvgS: 1269.94 (Eps:0.050 Steps:482949)Guard Target network updated at 483000 learning steps.\n",
      "Scout Target network updated at 161000 learning steps.\n",
      "Ep 8796| Scout AvgS: 474.51 (Eps:0.042 Steps:161323) Guard AvgS: 1280.03 (Eps:0.050 Steps:483985)Guard Target network updated at 484000 learning steps.\n",
      "Ep 8800| Scout AvgS: 470.52 (Eps:0.042 Steps:161387) Guard AvgS: 1263.65 (Eps:0.050 Steps:484177)\n",
      "Scout model saved: scout_learning.pth\n",
      "Guard model saved: guard_learning.pth\n",
      "Ep 8814| Scout AvgS: 450.54 (Eps:0.042 Steps:161656) Guard AvgS: 1212.97 (Eps:0.050 Steps:484986)Guard Target network updated at 485000 learning steps.\n",
      "Ep 8829| Scout AvgS: 423.07 (Eps:0.042 Steps:161976) Guard AvgS: 1213.55 (Eps:0.050 Steps:485944)Guard Target network updated at 486000 learning steps.\n",
      "Scout Target network updated at 162000 learning steps.\n",
      "Ep 8847| Scout AvgS: 411.91 (Eps:0.042 Steps:162327) Guard AvgS: 1205.19 (Eps:0.050 Steps:486997)Guard Target network updated at 487000 learning steps.\n",
      "Ep 8864| Scout AvgS: 432.15 (Eps:0.042 Steps:162658) Guard AvgS: 1184.84 (Eps:0.050 Steps:487990)Guard Target network updated at 488000 learning steps.\n",
      "Ep 8883| Scout AvgS: 407.00 (Eps:0.041 Steps:162984) Guard AvgS: 1152.85 (Eps:0.050 Steps:488969)Guard Target network updated at 489000 learning steps.\n",
      "Scout Target network updated at 163000 learning steps.\n",
      "Ep 8899| Scout AvgS: 383.78 (Eps:0.041 Steps:163319) Guard AvgS: 1210.31 (Eps:0.050 Steps:489973)Guard Target network updated at 490000 learning steps.\n",
      "Ep 8900| Scout AvgS: 383.78 (Eps:0.041 Steps:163330) Guard AvgS: 1210.18 (Eps:0.050 Steps:490006)\n",
      "Scout model saved: scout_learning.pth\n",
      "Guard model saved: guard_learning.pth\n",
      "Ep 8915| Scout AvgS: 399.21 (Eps:0.041 Steps:163648) Guard AvgS: 1277.48 (Eps:0.050 Steps:490960)Guard Target network updated at 491000 learning steps.\n",
      "Ep 8932| Scout AvgS: 415.77 (Eps:0.041 Steps:163994) Guard AvgS: 1338.58 (Eps:0.050 Steps:491998)Guard Target network updated at 492000 learning steps.\n",
      "Scout Target network updated at 164000 learning steps.\n",
      "Ep 8949| Scout AvgS: 453.78 (Eps:0.041 Steps:164321) Guard AvgS: 1311.53 (Eps:0.050 Steps:492980)Guard Target network updated at 493000 learning steps.\n",
      "Ep 8965| Scout AvgS: 438.36 (Eps:0.041 Steps:164642) Guard AvgS: 1386.00 (Eps:0.050 Steps:493942)Guard Target network updated at 494000 learning steps.\n",
      "Ep 8981| Scout AvgS: 435.65 (Eps:0.041 Steps:164991) Guard AvgS: 1380.14 (Eps:0.050 Steps:494989)Guard Target network updated at 495000 learning steps.\n",
      "Scout Target network updated at 165000 learning steps.\n",
      "Ep 8995| Scout AvgS: 448.88 (Eps:0.041 Steps:165307) Guard AvgS: 1354.11 (Eps:0.050 Steps:495937)Guard Target network updated at 496000 learning steps.\n",
      "Ep 9000| Scout AvgS: 451.33 (Eps:0.041 Steps:165432) Guard AvgS: 1340.17 (Eps:0.050 Steps:496312)\n",
      "Scout model saved: scout_learning.pth\n",
      "Guard model saved: guard_learning.pth\n",
      "Ep 9012| Scout AvgS: 441.25 (Eps:0.041 Steps:165651) Guard AvgS: 1295.31 (Eps:0.050 Steps:496970)Guard Target network updated at 497000 learning steps.\n",
      "Ep 9031| Scout AvgS: 434.37 (Eps:0.041 Steps:165990) Guard AvgS: 1235.14 (Eps:0.050 Steps:497986)Guard Target network updated at 498000 learning steps.\n",
      "Scout Target network updated at 166000 learning steps.\n",
      "Ep 9047| Scout AvgS: 454.01 (Eps:0.041 Steps:166323) Guard AvgS: 1266.41 (Eps:0.050 Steps:498987)Guard Target network updated at 499000 learning steps.\n",
      "Ep 9063| Scout AvgS: 472.64 (Eps:0.041 Steps:166639) Guard AvgS: 1262.00 (Eps:0.050 Steps:499933)Guard Target network updated at 500000 learning steps.\n",
      "Ep 9080| Scout AvgS: 505.39 (Eps:0.041 Steps:166988) Guard AvgS: 1303.38 (Eps:0.050 Steps:500981)Guard Target network updated at 501000 learning steps.\n",
      "Scout Target network updated at 167000 learning steps.\n",
      "Ep 9095| Scout AvgS: 499.79 (Eps:0.041 Steps:167311) Guard AvgS: 1350.25 (Eps:0.050 Steps:501951)Guard Target network updated at 502000 learning steps.\n",
      "Ep 9100| Scout AvgS: 499.50 (Eps:0.041 Steps:167407) Guard AvgS: 1365.12 (Eps:0.050 Steps:502237)\n",
      "Scout model saved: scout_learning.pth\n",
      "Guard model saved: guard_learning.pth\n",
      "Ep 9113| Scout AvgS: 509.43 (Eps:0.041 Steps:167650) Guard AvgS: 1407.47 (Eps:0.050 Steps:502967)Guard Target network updated at 503000 learning steps.\n",
      "Ep 9131| Scout AvgS: 515.88 (Eps:0.040 Steps:167987) Guard AvgS: 1437.40 (Eps:0.050 Steps:503979)Guard Target network updated at 504000 learning steps.\n",
      "Scout Target network updated at 168000 learning steps.\n",
      "Ep 9148| Scout AvgS: 484.04 (Eps:0.040 Steps:168318) Guard AvgS: 1428.27 (Eps:0.050 Steps:504970)Guard Target network updated at 505000 learning steps.\n",
      "Ep 9163| Scout AvgS: 465.38 (Eps:0.040 Steps:168661) Guard AvgS: 1438.75 (Eps:0.050 Steps:505999)Guard Target network updated at 506000 learning steps.\n",
      "Ep 9180| Scout AvgS: 452.79 (Eps:0.040 Steps:168994) Guard AvgS: 1405.98 (Eps:0.050 Steps:506998)Guard Target network updated at 507000 learning steps.\n",
      "Scout Target network updated at 169000 learning steps.\n",
      "Ep 9197| Scout AvgS: 449.62 (Eps:0.040 Steps:169323) Guard AvgS: 1298.97 (Eps:0.050 Steps:507985)Guard Target network updated at 508000 learning steps.\n",
      "Ep 9200| Scout AvgS: 448.27 (Eps:0.040 Steps:169394) Guard AvgS: 1319.15 (Eps:0.050 Steps:508199)\n",
      "Scout model saved: scout_learning.pth\n",
      "Guard model saved: guard_learning.pth\n",
      "Ep 9210| Scout AvgS: 430.62 (Eps:0.040 Steps:169644) Guard AvgS: 1245.84 (Eps:0.050 Steps:508949)Guard Target network updated at 509000 learning steps.\n",
      "Ep 9227| Scout AvgS: 415.72 (Eps:0.040 Steps:169981) Guard AvgS: 1270.13 (Eps:0.050 Steps:509959)Guard Target network updated at 510000 learning steps.\n",
      "Scout Target network updated at 170000 learning steps.\n",
      "Ep 9246| Scout AvgS: 412.05 (Eps:0.040 Steps:170305) Guard AvgS: 1203.64 (Eps:0.050 Steps:510933)Guard Target network updated at 511000 learning steps.\n",
      "Ep 9264| Scout AvgS: 385.67 (Eps:0.040 Steps:170658) Guard AvgS: 1147.58 (Eps:0.050 Steps:511991)Guard Target network updated at 512000 learning steps.\n",
      "Ep 9282| Scout AvgS: 352.80 (Eps:0.040 Steps:170975) Guard AvgS: 1174.46 (Eps:0.050 Steps:512941)Guard Target network updated at 513000 learning steps.\n",
      "Scout Target network updated at 171000 learning steps.\n",
      "Ep 9298| Scout AvgS: 360.90 (Eps:0.040 Steps:171303) Guard AvgS: 1237.17 (Eps:0.050 Steps:513925)Guard Target network updated at 514000 learning steps.\n",
      "Ep 9300| Scout AvgS: 362.04 (Eps:0.040 Steps:171335) Guard AvgS: 1216.52 (Eps:0.050 Steps:514021)\n",
      "Scout model saved: scout_learning.pth\n",
      "Guard model saved: guard_learning.pth\n",
      "Ep 9319| Scout AvgS: 370.76 (Eps:0.040 Steps:171657) Guard AvgS: 1250.29 (Eps:0.050 Steps:514987)Guard Target network updated at 515000 learning steps.\n",
      "Ep 9334| Scout AvgS: 403.41 (Eps:0.040 Steps:171979) Guard AvgS: 1260.16 (Eps:0.050 Steps:515953)Guard Target network updated at 516000 learning steps.\n",
      "Scout Target network updated at 172000 learning steps.\n",
      "Ep 9351| Scout AvgS: 406.32 (Eps:0.040 Steps:172318) Guard AvgS: 1280.51 (Eps:0.050 Steps:516972)Guard Target network updated at 517000 learning steps.\n",
      "Ep 9366| Scout AvgS: 440.72 (Eps:0.040 Steps:172636) Guard AvgS: 1344.11 (Eps:0.050 Steps:517926)Guard Target network updated at 518000 learning steps.\n",
      "Ep 9381| Scout AvgS: 453.92 (Eps:0.039 Steps:172989) Guard AvgS: 1302.62 (Eps:0.050 Steps:518983)Guard Target network updated at 519000 learning steps.\n",
      "Scout Target network updated at 173000 learning steps.\n",
      "Ep 9400| Scout AvgS: 441.88 (Eps:0.039 Steps:173326) Guard AvgS: 1255.70 (Eps:0.050 Steps:519994)\n",
      "Scout model saved: scout_learning.pth\n",
      "Guard model saved: guard_learning.pth\n",
      "Guard Target network updated at 520000 learning steps.\n",
      "Ep 9416| Scout AvgS: 444.18 (Eps:0.039 Steps:173654) Guard AvgS: 1242.39 (Eps:0.050 Steps:520978)Guard Target network updated at 521000 learning steps.\n",
      "Ep 9432| Scout AvgS: 417.25 (Eps:0.039 Steps:173972) Guard AvgS: 1237.19 (Eps:0.050 Steps:521932)Guard Target network updated at 522000 learning steps.\n",
      "Ep 9433| Scout AvgS: 399.06 (Eps:0.039 Steps:173997) Guard AvgS: 1237.19 (Eps:0.050 Steps:522007)Scout Target network updated at 174000 learning steps.\n",
      "Ep 9450| Scout AvgS: 405.66 (Eps:0.039 Steps:174322) Guard AvgS: 1250.29 (Eps:0.050 Steps:522982)Guard Target network updated at 523000 learning steps.\n",
      "Ep 9465| Scout AvgS: 406.89 (Eps:0.039 Steps:174645) Guard AvgS: 1224.82 (Eps:0.050 Steps:523952)Guard Target network updated at 524000 learning steps.\n",
      "Ep 9482| Scout AvgS: 414.03 (Eps:0.039 Steps:174991) Guard AvgS: 1266.79 (Eps:0.050 Steps:524991)Guard Target network updated at 525000 learning steps.\n",
      "Scout Target network updated at 175000 learning steps.\n",
      "Ep 9496| Scout AvgS: 441.32 (Eps:0.039 Steps:175308) Guard AvgS: 1290.09 (Eps:0.050 Steps:525942)Guard Target network updated at 526000 learning steps.\n",
      "Ep 9500| Scout AvgS: 445.03 (Eps:0.039 Steps:175398) Guard AvgS: 1294.25 (Eps:0.050 Steps:526210)\n",
      "Scout model saved: scout_learning.pth\n",
      "Guard model saved: guard_learning.pth\n",
      "Ep 9515| Scout AvgS: 488.52 (Eps:0.039 Steps:175659) Guard AvgS: 1277.06 (Eps:0.050 Steps:526994)Guard Target network updated at 527000 learning steps.\n",
      "Ep 9531| Scout AvgS: 528.08 (Eps:0.039 Steps:175988) Guard AvgS: 1336.36 (Eps:0.050 Steps:527981)Guard Target network updated at 528000 learning steps.\n",
      "Scout Target network updated at 176000 learning steps.\n",
      "Ep 9546| Scout AvgS: 554.32 (Eps:0.039 Steps:176321) Guard AvgS: 1408.64 (Eps:0.050 Steps:528981)Guard Target network updated at 529000 learning steps.\n",
      "Ep 9562| Scout AvgS: 537.04 (Eps:0.039 Steps:176660) Guard AvgS: 1417.56 (Eps:0.050 Steps:529996)Guard Target network updated at 530000 learning steps.\n",
      "Ep 9579| Scout AvgS: 519.57 (Eps:0.039 Steps:176987) Guard AvgS: 1403.72 (Eps:0.050 Steps:530979)Guard Target network updated at 531000 learning steps.\n",
      "Scout Target network updated at 177000 learning steps.\n",
      "Ep 9596| Scout AvgS: 511.39 (Eps:0.039 Steps:177327) Guard AvgS: 1384.62 (Eps:0.050 Steps:531997)Guard Target network updated at 532000 learning steps.\n",
      "Ep 9600| Scout AvgS: 510.74 (Eps:0.039 Steps:177398) Guard AvgS: 1373.32 (Eps:0.050 Steps:532210)\n",
      "Scout model saved: scout_learning.pth\n",
      "Guard model saved: guard_learning.pth\n",
      "Ep 9613| Scout AvgS: 488.38 (Eps:0.039 Steps:177638) Guard AvgS: 1390.27 (Eps:0.050 Steps:532932)Guard Target network updated at 533000 learning steps.\n",
      "Ep 9628| Scout AvgS: 460.17 (Eps:0.039 Steps:177978) Guard AvgS: 1366.99 (Eps:0.050 Steps:533950)Guard Target network updated at 534000 learning steps.\n",
      "Scout Target network updated at 178000 learning steps.\n",
      "Ep 9646| Scout AvgS: 429.73 (Eps:0.038 Steps:178305) Guard AvgS: 1266.56 (Eps:0.050 Steps:534931)Guard Target network updated at 535000 learning steps.\n",
      "Ep 9663| Scout AvgS: 420.48 (Eps:0.038 Steps:178652) Guard AvgS: 1213.89 (Eps:0.050 Steps:535972)Guard Target network updated at 536000 learning steps.\n",
      "Ep 9679| Scout AvgS: 446.54 (Eps:0.038 Steps:178970) Guard AvgS: 1156.93 (Eps:0.050 Steps:536926)Guard Target network updated at 537000 learning steps.\n",
      "Ep 9680| Scout AvgS: 446.43 (Eps:0.038 Steps:178995) Guard AvgS: 1161.92 (Eps:0.050 Steps:537001)Scout Target network updated at 179000 learning steps.\n",
      "Ep 9694| Scout AvgS: 430.18 (Eps:0.038 Steps:179326) Guard AvgS: 1189.80 (Eps:0.050 Steps:537996)Guard Target network updated at 538000 learning steps.\n",
      "Ep 9700| Scout AvgS: 424.78 (Eps:0.038 Steps:179434) Guard AvgS: 1212.53 (Eps:0.050 Steps:538320)\n",
      "Scout model saved: scout_learning.pth\n",
      "Guard model saved: guard_learning.pth\n",
      "Ep 9709| Scout AvgS: 444.36 (Eps:0.038 Steps:179640) Guard AvgS: 1231.61 (Eps:0.050 Steps:538937)Guard Target network updated at 539000 learning steps.\n",
      "Ep 9727| Scout AvgS: 424.98 (Eps:0.038 Steps:179985) Guard AvgS: 1266.18 (Eps:0.050 Steps:539972)Guard Target network updated at 540000 learning steps.\n",
      "Scout Target network updated at 180000 learning steps.\n",
      "Ep 9741| Scout AvgS: 435.87 (Eps:0.038 Steps:180312) Guard AvgS: 1311.26 (Eps:0.050 Steps:540952)Guard Target network updated at 541000 learning steps.\n",
      "Ep 9757| Scout AvgS: 449.30 (Eps:0.038 Steps:180640) Guard AvgS: 1352.07 (Eps:0.050 Steps:541937)Guard Target network updated at 542000 learning steps.\n",
      "Ep 9773| Scout AvgS: 445.02 (Eps:0.038 Steps:180973) Guard AvgS: 1430.08 (Eps:0.050 Steps:542937)Guard Target network updated at 543000 learning steps.\n",
      "Ep 9774| Scout AvgS: 445.02 (Eps:0.038 Steps:180998) Guard AvgS: 1424.89 (Eps:0.050 Steps:543012)Scout Target network updated at 181000 learning steps.\n",
      "Ep 9788| Scout AvgS: 431.67 (Eps:0.038 Steps:181326) Guard AvgS: 1435.22 (Eps:0.050 Steps:543994)Guard Target network updated at 544000 learning steps.\n",
      "Ep 9800| Scout AvgS: 458.60 (Eps:0.038 Steps:181585) Guard AvgS: 1420.71 (Eps:0.050 Steps:544771)\n",
      "Scout model saved: scout_learning.pth\n",
      "Guard model saved: guard_learning.pth\n",
      "Ep 9805| Scout AvgS: 424.51 (Eps:0.038 Steps:181644) Guard AvgS: 1397.85 (Eps:0.050 Steps:544949)Guard Target network updated at 545000 learning steps.\n",
      "Ep 9820| Scout AvgS: 432.70 (Eps:0.038 Steps:181982) Guard AvgS: 1375.11 (Eps:0.050 Steps:545964)Guard Target network updated at 546000 learning steps.\n",
      "Scout Target network updated at 182000 learning steps.\n",
      "Ep 9834| Scout AvgS: 441.79 (Eps:0.038 Steps:182318) Guard AvgS: 1401.62 (Eps:0.050 Steps:546970)Guard Target network updated at 547000 learning steps.\n",
      "Ep 9851| Scout AvgS: 421.95 (Eps:0.038 Steps:182640) Guard AvgS: 1322.34 (Eps:0.050 Steps:547937)Guard Target network updated at 548000 learning steps.\n",
      "Ep 9867| Scout AvgS: 423.47 (Eps:0.038 Steps:182976) Guard AvgS: 1348.23 (Eps:0.050 Steps:548945)Guard Target network updated at 549000 learning steps.\n",
      "Scout Target network updated at 183000 learning steps.\n",
      "Ep 9885| Scout AvgS: 401.39 (Eps:0.038 Steps:183316) Guard AvgS: 1367.85 (Eps:0.050 Steps:549965)Guard Target network updated at 550000 learning steps.\n",
      "Ep 9900| Scout AvgS: 382.06 (Eps:0.037 Steps:183656) Guard AvgS: 1388.88 (Eps:0.050 Steps:550986)\n",
      "Scout model saved: scout_learning.pth\n",
      "Guard model saved: guard_learning.pth\n",
      "Guard Target network updated at 551000 learning steps.\n",
      "Ep 9916| Scout AvgS: 402.00 (Eps:0.037 Steps:183991) Guard AvgS: 1397.14 (Eps:0.050 Steps:551991)Guard Target network updated at 552000 learning steps.\n",
      "Scout Target network updated at 184000 learning steps.\n",
      "Ep 9931| Scout AvgS: 415.07 (Eps:0.037 Steps:184316) Guard AvgS: 1355.89 (Eps:0.050 Steps:552966)Guard Target network updated at 553000 learning steps.\n",
      "Ep 9946| Scout AvgS: 431.74 (Eps:0.037 Steps:184658) Guard AvgS: 1422.00 (Eps:0.050 Steps:553990)Guard Target network updated at 554000 learning steps.\n",
      "Ep 9964| Scout AvgS: 410.10 (Eps:0.037 Steps:184983) Guard AvgS: 1425.84 (Eps:0.050 Steps:554965)Guard Target network updated at 555000 learning steps.\n",
      "Scout Target network updated at 185000 learning steps.\n",
      "Ep 9980| Scout AvgS: 452.33 (Eps:0.037 Steps:185311) Guard AvgS: 1373.75 (Eps:0.050 Steps:555949)Guard Target network updated at 556000 learning steps.\n",
      "Ep 9996| Scout AvgS: 479.90 (Eps:0.037 Steps:185650) Guard AvgS: 1330.50 (Eps:0.050 Steps:556967)Guard Target network updated at 557000 learning steps.\n",
      "Ep 10000| Scout AvgS: 486.12 (Eps:0.037 Steps:185750) Guard AvgS: 1323.12 (Eps:0.050 Steps:557267)\n",
      "Scout model saved: scout_learning.pth\n",
      "Guard model saved: guard_learning.pth\n",
      "Ep 10011| Scout AvgS: 480.32 (Eps:0.037 Steps:185985) Guard AvgS: 1253.04 (Eps:0.050 Steps:557972)Guard Target network updated at 558000 learning steps.\n",
      "Scout Target network updated at 186000 learning steps.\n",
      "Ep 10026| Scout AvgS: 489.02 (Eps:0.037 Steps:186320) Guard AvgS: 1249.62 (Eps:0.050 Steps:558978)Guard Target network updated at 559000 learning steps.\n",
      "Ep 10042| Scout AvgS: 472.57 (Eps:0.037 Steps:186649) Guard AvgS: 1255.07 (Eps:0.050 Steps:559965)Guard Target network updated at 560000 learning steps.\n",
      "Ep 10060| Scout AvgS: 488.19 (Eps:0.037 Steps:186973) Guard AvgS: 1237.95 (Eps:0.050 Steps:560935)Guard Target network updated at 561000 learning steps.\n",
      "Ep 10061| Scout AvgS: 485.99 (Eps:0.037 Steps:186998) Guard AvgS: 1237.87 (Eps:0.050 Steps:561010)Scout Target network updated at 187000 learning steps.\n",
      "Ep 10075| Scout AvgS: 474.37 (Eps:0.037 Steps:187327) Guard AvgS: 1217.85 (Eps:0.050 Steps:561999)Guard Target network updated at 562000 learning steps.\n",
      "Ep 10093| Scout AvgS: 446.12 (Eps:0.037 Steps:187653) Guard AvgS: 1204.47 (Eps:0.050 Steps:562975)Guard Target network updated at 563000 learning steps.\n",
      "Ep 10100| Scout AvgS: 450.24 (Eps:0.037 Steps:187828) Guard AvgS: 1249.99 (Eps:0.050 Steps:563500)\n",
      "Scout model saved: scout_learning.pth\n",
      "Guard model saved: guard_learning.pth\n",
      "Ep 10107| Scout AvgS: 437.86 (Eps:0.037 Steps:187986) Guard AvgS: 1277.36 (Eps:0.050 Steps:563975)Guard Target network updated at 564000 learning steps.\n",
      "Scout Target network updated at 188000 learning steps.\n",
      "Ep 10123| Scout AvgS: 458.40 (Eps:0.037 Steps:188304) Guard AvgS: 1280.19 (Eps:0.050 Steps:564929)Guard Target network updated at 565000 learning steps.\n",
      "Ep 10140| Scout AvgS: 461.99 (Eps:0.037 Steps:188654) Guard AvgS: 1261.56 (Eps:0.050 Steps:565978)Guard Target network updated at 566000 learning steps.\n",
      "Ep 10154| Scout AvgS: 448.84 (Eps:0.037 Steps:188985) Guard AvgS: 1312.52 (Eps:0.050 Steps:566972)Guard Target network updated at 567000 learning steps.\n",
      "Scout Target network updated at 189000 learning steps.\n",
      "Ep 10172| Scout AvgS: 415.37 (Eps:0.036 Steps:189321) Guard AvgS: 1333.43 (Eps:0.050 Steps:567981)Guard Target network updated at 568000 learning steps.\n",
      "Ep 10186| Scout AvgS: 404.84 (Eps:0.036 Steps:189652) Guard AvgS: 1386.62 (Eps:0.050 Steps:568974)Guard Target network updated at 569000 learning steps.\n",
      "Ep 10200| Scout AvgS: 422.64 (Eps:0.036 Steps:189987) Guard AvgS: 1420.78 (Eps:0.050 Steps:569977)\n",
      "Scout model saved: scout_learning.pth\n",
      "Guard model saved: guard_learning.pth\n",
      "Guard Target network updated at 570000 learning steps.\n",
      "Scout Target network updated at 190000 learning steps.\n",
      "Ep 10217| Scout AvgS: 444.58 (Eps:0.036 Steps:190317) Guard AvgS: 1414.58 (Eps:0.050 Steps:570967)Guard Target network updated at 571000 learning steps.\n",
      "Ep 10231| Scout AvgS: 457.92 (Eps:0.036 Steps:190641) Guard AvgS: 1457.09 (Eps:0.050 Steps:571939)Guard Target network updated at 572000 learning steps.\n",
      "Ep 10245| Scout AvgS: 469.18 (Eps:0.036 Steps:190984) Guard AvgS: 1501.77 (Eps:0.050 Steps:572968)Guard Target network updated at 573000 learning steps.\n",
      "Scout Target network updated at 191000 learning steps.\n",
      "Ep 10259| Scout AvgS: 499.29 (Eps:0.036 Steps:191318) Guard AvgS: 1485.58 (Eps:0.050 Steps:573971)Guard Target network updated at 574000 learning steps.\n",
      "Ep 10276| Scout AvgS: 511.48 (Eps:0.036 Steps:191654) Guard AvgS: 1465.95 (Eps:0.050 Steps:574980)Guard Target network updated at 575000 learning steps.\n",
      "Ep 10291| Scout AvgS: 512.24 (Eps:0.036 Steps:191984) Guard AvgS: 1450.84 (Eps:0.050 Steps:575968)Guard Target network updated at 576000 learning steps.\n",
      "Scout Target network updated at 192000 learning steps.\n",
      "Ep 10300| Scout AvgS: 497.74 (Eps:0.036 Steps:192165) Guard AvgS: 1348.22 (Eps:0.050 Steps:576512)\n",
      "Scout model saved: scout_learning.pth\n",
      "Guard model saved: guard_learning.pth\n",
      "Ep 10308| Scout AvgS: 500.68 (Eps:0.036 Steps:192315) Guard AvgS: 1289.17 (Eps:0.050 Steps:576962)Guard Target network updated at 577000 learning steps.\n",
      "Ep 10322| Scout AvgS: 482.50 (Eps:0.036 Steps:192638) Guard AvgS: 1327.60 (Eps:0.050 Steps:577930)Guard Target network updated at 578000 learning steps.\n",
      "Ep 10337| Scout AvgS: 460.95 (Eps:0.036 Steps:192976) Guard AvgS: 1357.38 (Eps:0.050 Steps:578944)Guard Target network updated at 579000 learning steps.\n",
      "Scout Target network updated at 193000 learning steps.\n",
      "Ep 10353| Scout AvgS: 473.97 (Eps:0.036 Steps:193322) Guard AvgS: 1295.29 (Eps:0.050 Steps:579982)Guard Target network updated at 580000 learning steps.\n",
      "Ep 10367| Scout AvgS: 479.92 (Eps:0.036 Steps:193639) Guard AvgS: 1287.88 (Eps:0.050 Steps:580934)Guard Target network updated at 581000 learning steps.\n",
      "Ep 10383| Scout AvgS: 462.81 (Eps:0.036 Steps:193975) Guard AvgS: 1364.54 (Eps:0.050 Steps:581942)Guard Target network updated at 582000 learning steps.\n",
      "Scout Target network updated at 194000 learning steps.\n",
      "Ep 10398| Scout AvgS: 461.94 (Eps:0.036 Steps:194309) Guard AvgS: 1400.98 (Eps:0.050 Steps:582944)Guard Target network updated at 583000 learning steps.\n",
      "Ep 10400| Scout AvgS: 461.50 (Eps:0.036 Steps:194359) Guard AvgS: 1419.74 (Eps:0.050 Steps:583094)\n",
      "Scout model saved: scout_learning.pth\n",
      "Guard model saved: guard_learning.pth\n",
      "Ep 10414| Scout AvgS: 445.18 (Eps:0.036 Steps:194655) Guard AvgS: 1434.47 (Eps:0.050 Steps:583981)Guard Target network updated at 584000 learning steps.\n",
      "Ep 10429| Scout AvgS: 455.98 (Eps:0.036 Steps:194978) Guard AvgS: 1424.85 (Eps:0.050 Steps:584952)Guard Target network updated at 585000 learning steps.\n",
      "Scout Target network updated at 195000 learning steps.\n",
      "Ep 10444| Scout AvgS: 457.04 (Eps:0.035 Steps:195319) Guard AvgS: 1385.14 (Eps:0.050 Steps:585973)Guard Target network updated at 586000 learning steps.\n",
      "Ep 10460| Scout AvgS: 448.60 (Eps:0.035 Steps:195651) Guard AvgS: 1348.56 (Eps:0.050 Steps:586970)Guard Target network updated at 587000 learning steps.\n",
      "Ep 10475| Scout AvgS: 470.54 (Eps:0.035 Steps:195994) Guard AvgS: 1362.63 (Eps:0.050 Steps:587998)Guard Target network updated at 588000 learning steps.\n",
      "Scout Target network updated at 196000 learning steps.\n",
      "Ep 10489| Scout AvgS: 497.45 (Eps:0.035 Steps:196315) Guard AvgS: 1323.69 (Eps:0.050 Steps:588961)Guard Target network updated at 589000 learning steps.\n",
      "Ep 10500| Scout AvgS: 494.14 (Eps:0.035 Steps:196573) Guard AvgS: 1355.17 (Eps:0.050 Steps:589735)\n",
      "Scout model saved: scout_learning.pth\n",
      "Guard model saved: guard_learning.pth\n",
      "Ep 10503| Scout AvgS: 491.02 (Eps:0.035 Steps:196648) Guard AvgS: 1374.90 (Eps:0.050 Steps:589960)Guard Target network updated at 590000 learning steps.\n",
      "Ep 10516| Scout AvgS: 517.06 (Eps:0.035 Steps:196972) Guard AvgS: 1438.10 (Eps:0.050 Steps:590933)Guard Target network updated at 591000 learning steps.\n",
      "Ep 10517| Scout AvgS: 524.01 (Eps:0.035 Steps:196997) Guard AvgS: 1436.15 (Eps:0.050 Steps:591008)Scout Target network updated at 197000 learning steps.\n",
      "Ep 10531| Scout AvgS: 500.85 (Eps:0.035 Steps:197313) Guard AvgS: 1472.01 (Eps:0.050 Steps:591957)Guard Target network updated at 592000 learning steps.\n",
      "Ep 10545| Scout AvgS: 500.75 (Eps:0.035 Steps:197646) Guard AvgS: 1492.28 (Eps:0.050 Steps:592954)Guard Target network updated at 593000 learning steps.\n",
      "Ep 10560| Scout AvgS: 504.20 (Eps:0.035 Steps:197994) Guard AvgS: 1525.31 (Eps:0.050 Steps:593998)Guard Target network updated at 594000 learning steps.\n",
      "Scout Target network updated at 198000 learning steps.\n",
      "Ep 10573| Scout AvgS: 511.20 (Eps:0.035 Steps:198314) Guard AvgS: 1537.84 (Eps:0.050 Steps:594958)Guard Target network updated at 595000 learning steps.\n",
      "Ep 10589| Scout AvgS: 514.91 (Eps:0.035 Steps:198639) Guard AvgS: 1591.68 (Eps:0.050 Steps:595933)Guard Target network updated at 596000 learning steps.\n",
      "Ep 10600| Scout AvgS: 505.40 (Eps:0.035 Steps:198865) Guard AvgS: 1586.94 (Eps:0.050 Steps:596613)\n",
      "Scout model saved: scout_learning.pth\n",
      "Guard model saved: guard_learning.pth\n",
      "Ep 10606| Scout AvgS: 490.37 (Eps:0.035 Steps:198986) Guard AvgS: 1549.28 (Eps:0.050 Steps:596975)Guard Target network updated at 597000 learning steps.\n",
      "Scout Target network updated at 199000 learning steps.\n",
      "Ep 10620| Scout AvgS: 493.94 (Eps:0.035 Steps:199326) Guard AvgS: 1462.37 (Eps:0.050 Steps:597994)Guard Target network updated at 598000 learning steps.\n",
      "Ep 10633| Scout AvgS: 521.17 (Eps:0.035 Steps:199648) Guard AvgS: 1464.10 (Eps:0.050 Steps:598960)Guard Target network updated at 599000 learning steps.\n",
      "Ep 10648| Scout AvgS: 511.96 (Eps:0.035 Steps:199972) Guard AvgS: 1413.06 (Eps:0.050 Steps:599933)Guard Target network updated at 600000 learning steps.\n",
      "Ep 10649| Scout AvgS: 520.57 (Eps:0.035 Steps:199997) Guard AvgS: 1412.67 (Eps:0.050 Steps:600008)Scout Target network updated at 200000 learning steps.\n",
      "Ep 10664| Scout AvgS: 487.97 (Eps:0.035 Steps:200317) Guard AvgS: 1389.90 (Eps:0.050 Steps:600968)Guard Target network updated at 601000 learning steps.\n",
      "Ep 10678| Scout AvgS: 489.20 (Eps:0.035 Steps:200644) Guard AvgS: 1372.37 (Eps:0.050 Steps:601948)Guard Target network updated at 602000 learning steps.\n",
      "Ep 10693| Scout AvgS: 476.20 (Eps:0.035 Steps:200986) Guard AvgS: 1359.14 (Eps:0.050 Steps:602975)Guard Target network updated at 603000 learning steps.\n",
      "Ep 10694| Scout AvgS: 476.45 (Eps:0.035 Steps:200999) Guard AvgS: 1348.08 (Eps:0.050 Steps:603014)Scout Target network updated at 201000 learning steps.\n",
      "Ep 10700| Scout AvgS: 490.84 (Eps:0.035 Steps:201149) Guard AvgS: 1344.75 (Eps:0.050 Steps:603464)\n",
      "Scout model saved: scout_learning.pth\n",
      "Guard model saved: guard_learning.pth\n",
      "Ep 10707| Scout AvgS: 503.54 (Eps:0.035 Steps:201322) Guard AvgS: 1378.36 (Eps:0.050 Steps:603982)Guard Target network updated at 604000 learning steps.\n",
      "Ep 10720| Scout AvgS: 502.15 (Eps:0.035 Steps:201647) Guard AvgS: 1455.40 (Eps:0.050 Steps:604957)Guard Target network updated at 605000 learning steps.\n",
      "Ep 10734| Scout AvgS: 474.36 (Eps:0.034 Steps:201984) Guard AvgS: 1408.03 (Eps:0.050 Steps:605970)Guard Target network updated at 606000 learning steps.\n",
      "Scout Target network updated at 202000 learning steps.\n",
      "Ep 10748| Scout AvgS: 457.72 (Eps:0.034 Steps:202307) Guard AvgS: 1409.16 (Eps:0.050 Steps:606939)Guard Target network updated at 607000 learning steps.\n",
      "Ep 10762| Scout AvgS: 481.40 (Eps:0.034 Steps:202648) Guard AvgS: 1453.51 (Eps:0.050 Steps:607961)Guard Target network updated at 608000 learning steps.\n",
      "Ep 10778| Scout AvgS: 475.25 (Eps:0.034 Steps:202993) Guard AvgS: 1436.50 (Eps:0.050 Steps:608996)Guard Target network updated at 609000 learning steps.\n",
      "Ep 10779| Scout AvgS: 476.67 (Eps:0.034 Steps:202999) Guard AvgS: 1415.14 (Eps:0.050 Steps:609014)Scout Target network updated at 203000 learning steps.\n",
      "Ep 10792| Scout AvgS: 474.70 (Eps:0.034 Steps:203324) Guard AvgS: 1468.97 (Eps:0.050 Steps:609989)Guard Target network updated at 610000 learning steps.\n",
      "Ep 10800| Scout AvgS: 499.54 (Eps:0.034 Steps:203524) Guard AvgS: 1515.95 (Eps:0.050 Steps:610589)\n",
      "Scout model saved: scout_learning.pth\n",
      "Guard model saved: guard_learning.pth\n",
      "Ep 10805| Scout AvgS: 511.16 (Eps:0.034 Steps:203649) Guard AvgS: 1528.53 (Eps:0.050 Steps:610964)Guard Target network updated at 611000 learning steps.\n",
      "Ep 10820| Scout AvgS: 483.92 (Eps:0.034 Steps:203985) Guard AvgS: 1471.43 (Eps:0.050 Steps:611972)Guard Target network updated at 612000 learning steps.\n",
      "Scout Target network updated at 204000 learning steps.\n",
      "Ep 10835| Scout AvgS: 460.71 (Eps:0.034 Steps:204317) Guard AvgS: 1446.80 (Eps:0.050 Steps:612967)Guard Target network updated at 613000 learning steps.\n",
      "Ep 10849| Scout AvgS: 495.51 (Eps:0.034 Steps:204649) Guard AvgS: 1490.93 (Eps:0.050 Steps:613965)Guard Target network updated at 614000 learning steps.\n",
      "Ep 10863| Scout AvgS: 469.45 (Eps:0.034 Steps:204991) Guard AvgS: 1492.04 (Eps:0.050 Steps:614989)Guard Target network updated at 615000 learning steps.\n",
      "Scout Target network updated at 205000 learning steps.\n",
      "Ep 10876| Scout AvgS: 484.21 (Eps:0.034 Steps:205303) Guard AvgS: 1486.61 (Eps:0.050 Steps:615925)Guard Target network updated at 616000 learning steps.\n",
      "Ep 10891| Scout AvgS: 483.73 (Eps:0.034 Steps:205644) Guard AvgS: 1454.08 (Eps:0.050 Steps:616950)Guard Target network updated at 617000 learning steps.\n",
      "Ep 10900| Scout AvgS: 481.43 (Eps:0.034 Steps:205869) Guard AvgS: 1454.09 (Eps:0.050 Steps:617625)\n",
      "Scout model saved: scout_learning.pth\n",
      "Guard model saved: guard_learning.pth\n",
      "Ep 10905| Scout AvgS: 487.34 (Eps:0.034 Steps:205976) Guard AvgS: 1427.98 (Eps:0.050 Steps:617946)Guard Target network updated at 618000 learning steps.\n",
      "Scout Target network updated at 206000 learning steps.\n",
      "Ep 10920| Scout AvgS: 519.44 (Eps:0.034 Steps:206324) Guard AvgS: 1508.28 (Eps:0.050 Steps:618988)Guard Target network updated at 619000 learning steps.\n",
      "Ep 10936| Scout AvgS: 557.48 (Eps:0.034 Steps:206648) Guard AvgS: 1493.70 (Eps:0.050 Steps:619960)Guard Target network updated at 620000 learning steps.\n",
      "Ep 10951| Scout AvgS: 520.21 (Eps:0.034 Steps:206990) Guard AvgS: 1459.17 (Eps:0.050 Steps:620988)Guard Target network updated at 621000 learning steps.\n",
      "Scout Target network updated at 207000 learning steps.\n",
      "Ep 10964| Scout AvgS: 543.40 (Eps:0.034 Steps:207315) Guard AvgS: 1434.71 (Eps:0.050 Steps:621963)Guard Target network updated at 622000 learning steps.\n",
      "Ep 10977| Scout AvgS: 522.76 (Eps:0.034 Steps:207640) Guard AvgS: 1396.13 (Eps:0.050 Steps:622938)Guard Target network updated at 623000 learning steps.\n",
      "Ep 10991| Scout AvgS: 534.20 (Eps:0.034 Steps:207990) Guard AvgS: 1421.38 (Eps:0.050 Steps:623988)Guard Target network updated at 624000 learning steps.\n",
      "Scout Target network updated at 208000 learning steps.\n",
      "Ep 11000| Scout AvgS: 503.80 (Eps:0.034 Steps:208215) Guard AvgS: 1336.93 (Eps:0.050 Steps:624663)\n",
      "Scout model saved: scout_learning.pth\n",
      "Guard model saved: guard_learning.pth\n",
      "Ep 11004| Scout AvgS: 490.09 (Eps:0.034 Steps:208315) Guard AvgS: 1340.06 (Eps:0.050 Steps:624963)Guard Target network updated at 625000 learning steps.\n",
      "Ep 11018| Scout AvgS: 440.77 (Eps:0.034 Steps:208638) Guard AvgS: 1289.05 (Eps:0.050 Steps:625930)Guard Target network updated at 626000 learning steps.\n",
      "Ep 11033| Scout AvgS: 439.88 (Eps:0.033 Steps:208983) Guard AvgS: 1356.56 (Eps:0.050 Steps:626965)Guard Target network updated at 627000 learning steps.\n",
      "Scout Target network updated at 209000 learning steps.\n",
      "Ep 11047| Scout AvgS: 449.78 (Eps:0.033 Steps:209311) Guard AvgS: 1395.24 (Eps:0.050 Steps:627950)Guard Target network updated at 628000 learning steps.\n",
      "Ep 11061| Scout AvgS: 421.83 (Eps:0.033 Steps:209652) Guard AvgS: 1411.62 (Eps:0.050 Steps:628973)Guard Target network updated at 629000 learning steps.\n",
      "Ep 11074| Scout AvgS: 433.94 (Eps:0.033 Steps:209977) Guard AvgS: 1435.16 (Eps:0.050 Steps:629948)Guard Target network updated at 630000 learning steps.\n",
      "Scout Target network updated at 210000 learning steps.\n",
      "Ep 11088| Scout AvgS: 417.19 (Eps:0.033 Steps:210327) Guard AvgS: 1443.83 (Eps:0.050 Steps:630998)Guard Target network updated at 631000 learning steps.\n",
      "Ep 11100| Scout AvgS: 439.19 (Eps:0.033 Steps:210627) Guard AvgS: 1523.62 (Eps:0.050 Steps:631898)\n",
      "Scout model saved: scout_learning.pth\n",
      "Guard model saved: guard_learning.pth\n",
      "Ep 11101| Scout AvgS: 442.19 (Eps:0.033 Steps:210652) Guard AvgS: 1523.53 (Eps:0.050 Steps:631973)Guard Target network updated at 632000 learning steps.\n",
      "Ep 11105| Scout AvgS: 445.97 (Eps:0.033 Steps:210752) Guard AvgS: 1536.18 (Eps:0.050 Steps:632273)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "# import imageio # Removed\n",
    "from collections import deque, namedtuple\n",
    "import time\n",
    "\n",
    "from til_environment.gridworld import RewardNames # Ensure this import works\n",
    "\n",
    "# import functools # Not used directly, can be removed if CustomWrapper doesn't need it explicitly\n",
    "from pettingzoo.utils.env import ActionType, AECEnv, AgentID, ObsType\n",
    "from pettingzoo.utils.wrappers.base import BaseWrapper\n",
    "\n",
    "# --- Configuration ---\n",
    "MAP_SIZE_X = 16\n",
    "MAP_SIZE_Y = 16\n",
    "MAX_STEPS_PER_EPISODE = 100\n",
    "\n",
    "VIEWCONE_CHANNELS = 8\n",
    "VIEWCONE_HEIGHT = 7\n",
    "VIEWCONE_WIDTH = 5\n",
    "OTHER_FEATURES_SIZE = 4 + 2 + 1 + 1\n",
    "\n",
    "CNN_OUTPUT_CHANNELS_1 = 16\n",
    "CNN_OUTPUT_CHANNELS_2 = 32\n",
    "KERNEL_SIZE_1 = (3, 3); STRIDE_1 = 1\n",
    "KERNEL_SIZE_2 = (3, 3); STRIDE_2 = 1\n",
    "MLP_HIDDEN_LAYER_1_SIZE = 128\n",
    "MLP_HIDDEN_LAYER_2_SIZE = 128\n",
    "OUTPUT_ACTIONS = 5\n",
    "DROPOUT_RATE = 0.2\n",
    "\n",
    "BUFFER_SIZE = int(1e5)\n",
    "BATCH_SIZE = 32\n",
    "GAMMA = 0.99\n",
    "LEARNING_RATE = 1e-4\n",
    "\n",
    "# Epsilon for Scout\n",
    "SCOUT_EPSILON_START = 0.1\n",
    "SCOUT_EPSILON_END = 0.01\n",
    "SCOUT_EPSILON_DECAY = 0.9999\n",
    "MIN_EPSILON_FRAMES_SCOUT = int(2e3)\n",
    "\n",
    "# Epsilon for Guards\n",
    "GUARD_EPSILON_START = 0.5\n",
    "GUARD_EPSILON_END = 0.05\n",
    "GUARD_EPSILON_DECAY = 0.9995\n",
    "MIN_EPSILON_FRAMES_GUARD = int(5e3)\n",
    "\n",
    "TARGET_UPDATE_EVERY = 1000\n",
    "UPDATE_EVERY = 4\n",
    "\n",
    "PER_ALPHA = 0.6; PER_BETA_START = 0.4; PER_BETA_FRAMES = int(1e5); PER_EPSILON = 1e-6\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "CUSTOM_REWARDS_DICT = {\n",
    "    RewardNames.SCOUT_MISSION: 100.0, RewardNames.SCOUT_RECON: 10.0,\n",
    "    RewardNames.SCOUT_TRUNCATION: 50.0, RewardNames.SCOUT_CAPTURED: -100.0,\n",
    "    RewardNames.GUARD_WINS: 50.0, RewardNames.GUARD_CAPTURES: 100.0,\n",
    "    RewardNames.GUARD_TRUNCATION: 20.0, RewardNames.WALL_COLLISION: -10.0,\n",
    "    RewardNames.AGENT_COLLIDER: -2.0, RewardNames.AGENT_COLLIDEE: -1.0,\n",
    "    RewardNames.STATIONARY_PENALTY: -0.5, RewardNames.SCOUT_STEP: -0.1,\n",
    "    RewardNames.GUARD_STEP: -0.05,\n",
    "}\n",
    "# EXPLORATION_BONUS = 0.1 # Not currently used in the loop, can be removed or re-added if needed\n",
    "\n",
    "INITIAL_SCOUT_MODEL_PATH = \"my_wargame_cnn_agent_35500.pth\"\n",
    "SCOUT_MODEL_SAVE_PATH = \"scout_learning.pth\"\n",
    "GUARD_MODEL_SAVE_PATH = \"guard_learning.pth\"\n",
    "\n",
    "\n",
    "class CustomWrapper(BaseWrapper[AgentID, ObsType, ActionType]):\n",
    "    def __init__(self, env: AECEnv[AgentID, ObsType, ActionType]):\n",
    "        super().__init__(env)\n",
    "\n",
    "class SumTree:\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity; self.tree = np.zeros(2 * capacity - 1); self.data = np.zeros(capacity, dtype=object)\n",
    "        self.data_pointer = 0; self.n_entries = 0\n",
    "    def add(self, priority, data):\n",
    "        tree_idx = self.data_pointer + self.capacity - 1; self.data[self.data_pointer] = data; self.update(tree_idx, priority)\n",
    "        self.data_pointer = (self.data_pointer + 1) % self.capacity\n",
    "        if self.n_entries < self.capacity: self.n_entries += 1\n",
    "    def update(self, tree_idx, priority):\n",
    "        change = priority - self.tree[tree_idx]; self.tree[tree_idx] = priority\n",
    "        while tree_idx != 0: tree_idx = (tree_idx - 1) // 2; self.tree[tree_idx] += change\n",
    "    def get_leaf(self, value):\n",
    "        parent_idx = 0\n",
    "        while True:\n",
    "            l_child = 2*parent_idx+1; r_child = l_child+1\n",
    "            if l_child >= len(self.tree): leaf_idx=parent_idx; break\n",
    "            if value <= self.tree[l_child]: parent_idx=l_child\n",
    "            else: value -= self.tree[l_child]; parent_idx=r_child\n",
    "        return leaf_idx, self.tree[leaf_idx], self.data[leaf_idx - self.capacity + 1]\n",
    "    @property\n",
    "    def total_priority(self): return self.tree[0]\n",
    "\n",
    "Experience = namedtuple(\"Experience\", [\"state_viewcone\", \"state_other\", \"action\", \"reward\", \"next_state_viewcone\", \"next_state_other\", \"done\"])\n",
    "class PrioritizedReplayBuffer:\n",
    "    def __init__(self, capacity, alpha=PER_ALPHA):\n",
    "        self.tree = SumTree(capacity); self.alpha = alpha; self.max_priority = 1.0\n",
    "    def add(self, s_vc, s_o, act, r, next_s_vc, next_s_o, d):\n",
    "        self.tree.add(self.max_priority, Experience(s_vc,s_o,act,r,next_s_vc,next_s_o,d))\n",
    "    def sample(self, batch_size, beta=PER_BETA_START):\n",
    "        b_idx, b_data, w = np.empty(batch_size,dtype=np.int32), np.empty(batch_size,dtype=object), np.empty(batch_size,dtype=np.float32)\n",
    "        pri_seg = self.tree.total_priority/batch_size if self.tree.n_entries > 0 else 0\n",
    "        if self.tree.n_entries < batch_size : return (torch.empty(0),torch.empty(0),torch.empty(0),torch.empty(0),torch.empty(0),torch.empty(0),torch.empty(0)), np.array([]), torch.empty(0) # Ensure enough samples\n",
    "        for i in range(batch_size):\n",
    "            val = np.random.uniform(pri_seg*i, pri_seg*(i+1))\n",
    "            idx, pri, data = self.tree.get_leaf(val)\n",
    "            probs = pri/self.tree.total_priority if self.tree.total_priority > 0 else 0\n",
    "            w[i] = np.power(self.tree.n_entries * probs + 1e-8, -beta); b_idx[i],b_data[i] = idx,data\n",
    "        w /= (w.max() if w.max() > 0 else 1.0)\n",
    "        s_vc,s_o,act,r,next_s_vc,next_s_o,d = zip(*[e for e in b_data if e is not None])\n",
    "        if not s_vc : return (torch.empty(0),torch.empty(0),torch.empty(0),torch.empty(0),torch.empty(0),torch.empty(0),torch.empty(0)), np.array([]), torch.empty(0)\n",
    "        s_vc_t = torch.from_numpy(np.array(s_vc)).float().to(DEVICE); s_o_t = torch.from_numpy(np.array(s_o)).float().to(DEVICE)\n",
    "        act_t = torch.from_numpy(np.vstack(act)).long().to(DEVICE); r_t = torch.from_numpy(np.vstack(r)).float().to(DEVICE)\n",
    "        next_s_vc_t = torch.from_numpy(np.array(next_s_vc)).float().to(DEVICE); next_s_o_t = torch.from_numpy(np.array(next_s_o)).float().to(DEVICE)\n",
    "        d_t = torch.from_numpy(np.vstack(d).astype(np.uint8)).float().to(DEVICE)\n",
    "        return (s_vc_t,s_o_t,act_t,r_t,next_s_vc_t,next_s_o_t,d_t), b_idx, torch.from_numpy(w).float().to(DEVICE)\n",
    "    def update_priorities(self, b_indices, td_errs):\n",
    "        if len(b_indices)==0: return\n",
    "        prios = np.abs(td_errs)+PER_EPSILON; prios = np.power(prios,self.alpha)\n",
    "        for idx,p in zip(b_indices,prios): self.tree.update(idx,p)\n",
    "        if prios.size>0: self.max_priority=max(self.max_priority,np.max(prios))\n",
    "    def __len__(self): return self.tree.n_entries\n",
    "\n",
    "class CNNDQN(nn.Module):\n",
    "    def __init__(self, v_c, v_h, v_w, o_f_s, mlp_h1, mlp_h2, n_a, dr):\n",
    "        super(CNNDQN,self).__init__(); self.conv1=nn.Conv2d(v_c,CNN_OUTPUT_CHANNELS_1,KERNEL_SIZE_1,STRIDE_1,padding=1); self.relu_conv1=nn.ReLU()\n",
    "        h1=(v_h+2*1-KERNEL_SIZE_1[0])//STRIDE_1+1; w1=(v_w+2*1-KERNEL_SIZE_1[1])//STRIDE_1+1\n",
    "        self.conv2=nn.Conv2d(CNN_OUTPUT_CHANNELS_1,CNN_OUTPUT_CHANNELS_2,KERNEL_SIZE_2,STRIDE_2,padding=1); self.relu_conv2=nn.ReLU()\n",
    "        h2=(h1+2*1-KERNEL_SIZE_2[0])//STRIDE_2+1; w2=(w1+2*1-KERNEL_SIZE_2[1])//STRIDE_2+1\n",
    "        self.cnn_flat_size=CNN_OUTPUT_CHANNELS_2*h2*w2\n",
    "        self.fc1_mlp=nn.Linear(self.cnn_flat_size+o_f_s,mlp_h1); self.relu_fc1=nn.ReLU(); self.dropout1=nn.Dropout(dr)\n",
    "        self.fc2_mlp=nn.Linear(mlp_h1,mlp_h2); self.relu_fc2=nn.ReLU(); self.dropout2=nn.Dropout(dr)\n",
    "        self.fc_output=nn.Linear(mlp_h2,n_a)\n",
    "    def forward(self, vc_in, of_in):\n",
    "        x=self.relu_conv1(self.conv1(vc_in)); x=self.relu_conv2(self.conv2(x)); x_flat=x.view(-1,self.cnn_flat_size)\n",
    "        comb=torch.cat((x_flat,of_in),dim=1); x=self.relu_fc1(self.fc1_mlp(comb)); x=self.dropout1(x)\n",
    "        x=self.relu_fc2(self.fc2_mlp(x)); x=self.dropout2(x); return self.fc_output(x)\n",
    "\n",
    "class TrainableRLAgent:\n",
    "    def __init__(self, agent_role_name, model_load_path=None, model_save_path=\"trained_model.pth\"):\n",
    "        self.device=DEVICE; self.agent_role_name = agent_role_name\n",
    "        print(f\"Agent Role: {self.agent_role_name} | Using device: {self.device}\")\n",
    "        self.policy_net = CNNDQN(VIEWCONE_CHANNELS,VIEWCONE_HEIGHT,VIEWCONE_WIDTH,OTHER_FEATURES_SIZE,MLP_HIDDEN_LAYER_1_SIZE,MLP_HIDDEN_LAYER_2_SIZE,OUTPUT_ACTIONS,DROPOUT_RATE).to(self.device)\n",
    "        self.target_net = CNNDQN(VIEWCONE_CHANNELS,VIEWCONE_HEIGHT,VIEWCONE_WIDTH,OTHER_FEATURES_SIZE,MLP_HIDDEN_LAYER_1_SIZE,MLP_HIDDEN_LAYER_2_SIZE,OUTPUT_ACTIONS,DROPOUT_RATE).to(self.device)\n",
    "        if model_load_path and os.path.exists(model_load_path):\n",
    "            try: self.policy_net.load_state_dict(torch.load(model_load_path,map_location=self.device)); print(f\"Loaded {self.agent_role_name} policy_net from {model_load_path}\")\n",
    "            except Exception as e: print(f\"Error loading {self.agent_role_name} model: {e}. Init random.\"); self.policy_net.apply(self._init_w)\n",
    "        else:\n",
    "            if model_load_path: print(f\"{self.agent_role_name} model not found at {model_load_path}. Init random.\")\n",
    "            else: print(f\"No model_load_path for {self.agent_role_name}. Init random.\"); self.policy_net.apply(self._init_w)\n",
    "        self.target_net.load_state_dict(self.policy_net.state_dict()); self.target_net.eval()\n",
    "        self.optimizer=optim.Adam(self.policy_net.parameters(),lr=LEARNING_RATE); self.memory=PrioritizedReplayBuffer(BUFFER_SIZE,PER_ALPHA)\n",
    "        self.beta=PER_BETA_START; self.beta_inc=(1.0-PER_BETA_START)/PER_BETA_FRAMES if PER_BETA_FRAMES>0 else 0\n",
    "        self.t_step_episode=0; self.model_save_path=model_save_path; self.total_learning_steps=0\n",
    "    def _init_w(self,m):\n",
    "        if isinstance(m,(nn.Linear,nn.Conv2d)): nn.init.xavier_uniform_(m.weight); nn.init.constant_(m.bias,0) if m.bias is not None else None\n",
    "    def _unpack_vc_tile(self,val): return [float((val>>i)&1) for i in range(VIEWCONE_CHANNELS)]\n",
    "    def proc_obs(self,obs_d):\n",
    "        vc_raw=obs_d.get(\"viewcone\",np.zeros((VIEWCONE_HEIGHT,VIEWCONE_WIDTH),dtype=np.uint8))\n",
    "        if not isinstance(vc_raw,np.ndarray):vc_raw=np.array(vc_raw)\n",
    "        if vc_raw.shape!=(VIEWCONE_HEIGHT,VIEWCONE_WIDTH):\n",
    "            pad_vc=np.zeros((VIEWCONE_HEIGHT,VIEWCONE_WIDTH),dtype=np.uint8);h,w=vc_raw.shape;h_m,w_m=min(h,VIEWCONE_HEIGHT),min(w,VIEWCONE_WIDTH)\n",
    "            pad_vc[:h_m,:w_m]=vc_raw[:h_m,:w_m];vc_raw=pad_vc\n",
    "        vc_proc=np.zeros((VIEWCONE_CHANNELS,VIEWCONE_HEIGHT,VIEWCONE_WIDTH),dtype=np.float32)\n",
    "        for r in range(VIEWCONE_HEIGHT):\n",
    "            for c in range(VIEWCONE_WIDTH):\n",
    "                unp=self._unpack_vc_tile(vc_raw[r,c])\n",
    "                for ch in range(VIEWCONE_CHANNELS):vc_proc[ch,r,c]=unp[ch]\n",
    "        o_list=[];d=obs_d.get(\"direction\",0);d_oh=[0.]*4;d_oh[d%4]=1.;o_list.extend(d_oh)\n",
    "        l=obs_d.get(\"location\",[0,0]);nx=l[0]/MAP_SIZE_X;ny=l[1]/MAP_SIZE_Y;o_list.extend([nx,ny])\n",
    "        o_list.append(float(obs_d.get(\"scout\",0)));o_list.append(obs_d.get(\"step\",0)/MAX_STEPS_PER_EPISODE)\n",
    "        s_o_np=np.array(o_list,dtype=np.float32)\n",
    "        return vc_proc,s_o_np\n",
    "    def sel_act(self,s_vc,s_o,eps=0.):\n",
    "        if random.random()>eps:\n",
    "            vc_t=torch.from_numpy(s_vc).float().unsqueeze(0).to(self.device);o_t=torch.from_numpy(s_o).float().unsqueeze(0).to(self.device)\n",
    "            self.policy_net.eval()\n",
    "            with torch.no_grad():av=self.policy_net(vc_t,o_t)\n",
    "            self.policy_net.train()\n",
    "            return np.argmax(av.cpu().data.numpy())\n",
    "        return random.choice(np.arange(OUTPUT_ACTIONS))\n",
    "    def step(self,s_vc,s_o,act,rwd,next_s_vc,next_s_o,dn):\n",
    "        self.memory.add(s_vc,s_o,act,rwd,next_s_vc,next_s_o,dn); self.t_step_episode=(self.t_step_episode+1)%UPDATE_EVERY\n",
    "        if self.t_step_episode==0 and len(self.memory)>BATCH_SIZE:\n",
    "            exp,idx,w=self.memory.sample(BATCH_SIZE,self.beta)\n",
    "            if exp[0].nelement()>0:self.learn(exp,idx,w,GAMMA)\n",
    "            self.beta=min(1.,self.beta+self.beta_inc);self.total_learning_steps+=1\n",
    "            if self.total_learning_steps%TARGET_UPDATE_EVERY==0:self.update_target_net()\n",
    "    def learn(self,exp,idx,is_w,gam):\n",
    "        s_vc,s_o,act,rwd,next_s_vc,next_s_o,dn=exp\n",
    "        if s_vc.nelement()==0:return\n",
    "        q_next_pol_act=self.policy_net(next_s_vc,next_s_o).detach().max(1)[1].unsqueeze(1)\n",
    "        q_targets_next=self.target_net(next_s_vc,next_s_o).detach().gather(1,q_next_pol_act)\n",
    "        q_targets=rwd+(gam*q_targets_next*(1-dn));q_exp=self.policy_net(s_vc,s_o).gather(1,act)\n",
    "        td_errs=(q_targets-q_exp).abs().cpu().detach().numpy().flatten();self.memory.update_priorities(idx,td_errs)\n",
    "        loss=(is_w*nn.MSELoss(reduction='none')(q_exp,q_targets)).mean()\n",
    "        self.optimizer.zero_grad();loss.backward();torch.nn.utils.clip_grad_norm_(self.policy_net.parameters(),1.)\n",
    "        self.optimizer.step()\n",
    "    def update_target_net(self):\n",
    "        self.target_net.load_state_dict(self.policy_net.state_dict())\n",
    "        print(f\"{self.agent_role_name} Target network updated at {self.total_learning_steps} learning steps.\")\n",
    "    def save_model(self):\n",
    "        if self.model_save_path:torch.save(self.policy_net.state_dict(),self.model_save_path);print(f\"{self.agent_role_name} model saved: {self.model_save_path}\")\n",
    "\n",
    "def train_scout_and_guards(env_module, num_episodes=2000, novice_track=False,\n",
    "                           initial_scout_path=INITIAL_SCOUT_MODEL_PATH,\n",
    "                           initial_guard_path=GUARD_MODEL_SAVE_PATH,\n",
    "                           save_scout_to=SCOUT_MODEL_SAVE_PATH,\n",
    "                           save_guard_to=GUARD_MODEL_SAVE_PATH): # Removed render_mode, video_folder\n",
    "    \n",
    "    # render_mode is None for faster training\n",
    "    env = env_module.env(env_wrappers=[CustomWrapper], render_mode=None, novice=novice_track, rewards_dict=CUSTOM_REWARDS_DICT)\n",
    "    # if render_mode==\"rgb_array\" and video_folder: os.makedirs(video_folder,exist_ok=True) # Removed\n",
    "\n",
    "    scout_trainer = TrainableRLAgent(agent_role_name=\"Scout\", model_load_path=initial_scout_path, model_save_path=save_scout_to)\n",
    "    \n",
    "    effective_guard_load_path = initial_guard_path\n",
    "    if not os.path.exists(effective_guard_load_path):\n",
    "        print(f\"Guard model at '{initial_guard_path}' not found. Initializing guards from scout model: '{initial_scout_path}'\")\n",
    "        effective_guard_load_path = initial_scout_path \n",
    "        if not os.path.exists(effective_guard_load_path):\n",
    "            print(f\"CRITICAL: Scout model '{initial_scout_path}' also not found for guard init. Guards start random.\")\n",
    "            effective_guard_load_path = None\n",
    "    guard_trainer = TrainableRLAgent(agent_role_name=\"Guard\", model_load_path=effective_guard_load_path, model_save_path=save_guard_to)\n",
    "\n",
    "    eps_scout, eps_guard = SCOUT_EPSILON_START, GUARD_EPSILON_START\n",
    "    scout_scores_q, guard_scores_q = deque(maxlen=100), deque(maxlen=100)\n",
    "    pending_exps = {} \n",
    "\n",
    "    for i_episode in range(1, num_episodes + 1):\n",
    "        env.reset(); pending_exps.clear()\n",
    "        ep_rewards = {ag_id:0 for ag_id in env.possible_agents}\n",
    "        # ep_frames = []; video_this_ep = (render_mode==\"rgb_array\" and video_folder and i_episode%100==0) # Removed\n",
    "\n",
    "        for pet_id in env.agent_iter():\n",
    "            obs_raw, reward, term, trunc, info = env.last()\n",
    "            done = term or trunc\n",
    "            if pet_id in ep_rewards: ep_rewards[pet_id] += reward\n",
    "            # if video_this_ep: # Removed\n",
    "            #     try: ep_frames.append(env.render())\n",
    "            #     except Exception as e: pass \n",
    "\n",
    "            current_agent_is_scout = False \n",
    "            agent_obj_for_turn = guard_trainer \n",
    "            current_epsilon_for_turn = eps_guard \n",
    "\n",
    "            if obs_raw is not None: \n",
    "                obs_d_temp = {k:v.tolist() if isinstance(v,np.ndarray) else v for k,v in obs_raw.items()}\n",
    "                current_agent_is_scout = obs_d_temp.get(\"scout\",0)==1\n",
    "                if current_agent_is_scout:\n",
    "                    agent_obj_for_turn = scout_trainer\n",
    "                    current_epsilon_for_turn = eps_scout\n",
    "            \n",
    "            if pet_id in pending_exps:\n",
    "                prev_s_vc, prev_s_o, prev_act, prev_was_scout = pending_exps.pop(pet_id)\n",
    "                learning_agent = scout_trainer if prev_was_scout else guard_trainer\n",
    "                \n",
    "                next_s_vc_np, next_s_o_np = None, None\n",
    "                if not done and obs_raw is not None:\n",
    "                    next_s_vc_np, next_s_o_np = learning_agent.proc_obs(obs_d_temp)\n",
    "                else:\n",
    "                    next_s_vc_np,next_s_o_np = np.zeros_like(prev_s_vc),np.zeros_like(prev_s_o)\n",
    "                \n",
    "                final_rwd = reward \n",
    "                learning_agent.step(prev_s_vc, prev_s_o, prev_act, final_rwd, next_s_vc_np, next_s_o_np, done)\n",
    "\n",
    "            act_to_take = None\n",
    "            if done: pass \n",
    "            elif obs_raw is None: act_to_take = env.action_space(pet_id).sample() if env.action_space(pet_id) else None\n",
    "            else: \n",
    "                s_vc, s_o = agent_obj_for_turn.proc_obs(obs_d_temp)\n",
    "                act_to_take = agent_obj_for_turn.sel_act(s_vc, s_o, current_epsilon_for_turn)\n",
    "                pending_exps[pet_id] = (s_vc, s_o, act_to_take, current_agent_is_scout)\n",
    "            env.step(act_to_take)\n",
    "\n",
    "        scout_ep_score = sum(r for ag_id,r in ep_rewards.items() if env.possible_agents.index(ag_id)==0) \n",
    "        guard_ep_score = sum(r for ag_id,r in ep_rewards.items() if env.possible_agents.index(ag_id)!=0)\n",
    "        scout_scores_q.append(scout_ep_score); guard_scores_q.append(guard_ep_score)\n",
    "\n",
    "        if scout_trainer.total_learning_steps > MIN_EPSILON_FRAMES_SCOUT: eps_scout = max(SCOUT_EPSILON_END, SCOUT_EPSILON_DECAY*eps_scout)\n",
    "        if guard_trainer.total_learning_steps > MIN_EPSILON_FRAMES_GUARD: eps_guard = max(GUARD_EPSILON_END, GUARD_EPSILON_DECAY*eps_guard)\n",
    "        \n",
    "        # if video_this_ep and ep_frames: # Removed\n",
    "        #     try: imageio.mimsave(os.path.join(video_folder,f\"ep_{i_episode:04d}.mp4\"),ep_frames,fps=10)\n",
    "        #     except Exception as e: pass \n",
    "        \n",
    "        avg_s_scr=f\"{np.mean(scout_scores_q):.2f}\" if scout_scores_q else \"N/A\"\n",
    "        avg_g_scr=f\"{np.mean(guard_scores_q):.2f}\" if guard_scores_q else \"N/A\"\n",
    "        print(f\"\\rEp {i_episode}| Scout AvgS: {avg_s_scr} (Eps:{eps_scout:.3f} Steps:{scout_trainer.total_learning_steps}) Guard AvgS: {avg_g_scr} (Eps:{eps_guard:.3f} Steps:{guard_trainer.total_learning_steps})\",end=\"\")\n",
    "        if i_episode%100==0:\n",
    "            print(f\"\\rEp {i_episode}| Scout AvgS: {avg_s_scr} (Eps:{eps_scout:.3f} Steps:{scout_trainer.total_learning_steps}) Guard AvgS: {avg_g_scr} (Eps:{eps_guard:.3f} Steps:{guard_trainer.total_learning_steps})\")\n",
    "            scout_trainer.save_model(); guard_trainer.save_model()\n",
    "            \n",
    "    env.close(); print(\"\\nTraining Done.\"); scout_trainer.save_model(); guard_trainer.save_model()\n",
    "    # return scout_scores_q, guard_scores_q # Removed return for plotting\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    t_start=time.time()\n",
    "    try:\n",
    "        from til_environment import gridworld\n",
    "        print(\"Imported til_environment.gridworld\")\n",
    "        train_scout_and_guards( # Modified to not expect return values for plotting\n",
    "            gridworld, num_episodes=50000, novice_track=False, \n",
    "            initial_scout_path=INITIAL_SCOUT_MODEL_PATH, \n",
    "            initial_guard_path=GUARD_MODEL_SAVE_PATH,    \n",
    "            save_scout_to=SCOUT_MODEL_SAVE_PATH,\n",
    "            save_guard_to=GUARD_MODEL_SAVE_PATH\n",
    "            # render_mode and video_folder args removed from call\n",
    "        )\n",
    "        # if s_scores and g_scores: # Removed plotting block\n",
    "        #     import matplotlib.pyplot as plt\n",
    "        #     ...\n",
    "    except ImportError: print(\"Could not import 'til_environment.gridworld'.\")\n",
    "    except Exception as e: print(f\"Error: {e}\"); import traceback; traceback.print_exc()\n",
    "    print(f\"Total script time: {(time.time()-t_start)/60:.2f} minutes\")"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "env",
   "name": "workbench-notebooks.m129",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m129"
  },
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
